# AI Creator - 云端服务设计

> 基于 fastapi_best_architecture 的云端服务实现 | 更新: 2025-12-26

## 1. 架构概述

### 1.1 技术栈

```yaml
核心框架:
  - FastAPI: Web框架
  - SQLAlchemy 2.0: ORM (异步支持)
  - Pydantic v2: 数据验证
  - Celery: 异步任务队列
  - Redis: 缓存、会话、消息队列

存储:
  - PostgreSQL: 核心业务数据
  - Redis: 缓存、会话
  - MinIO/S3: 媒体文件存储
  - Meilisearch: 全文搜索

浏览器服务:
  - Playwright: 浏览器自动化
  - Docker/K8s: 容器化部署
  - 浏览器池: 多实例管理

AI基础设施:
  - LiteLLM: 多模型网关 (100+ 供应商支持)
  - Claude API: 主力LLM
  - LangGraph: Agent工作流
  - ComfyUI API: 图像生成
```

### 1.2 项目结构 (基于 fastapi_best_architecture)

```text
cloud-backend/
├── backend/                        # 后端主目录
│   ├── __init__.py
│   ├── main.py                     # FastAPI入口
│   ├── run.py                      # 启动脚本
│   ├── cli.py                      # CLI命令行工具
│   │
│   ├── core/                       # 核心配置
│   │   ├── __init__.py
│   │   ├── conf.py                 # 全局配置 (pydantic-settings)
│   │   ├── path_conf.py            # 路径配置
│   │   └── registrar.py            # 应用注册器
│   │
│   ├── database/                   # 数据库连接
│   │   ├── __init__.py
│   │   ├── db.py                   # SQLAlchemy 异步引擎
│   │   └── redis.py                # Redis 连接
│   │
│   ├── middleware/                 # 中间件
│   │   ├── __init__.py
│   │   ├── jwt_auth_middleware.py  # JWT认证
│   │   ├── access_middleware.py    # 访问控制
│   │   ├── opera_log_middleware.py # 操作日志
│   │   ├── state_middleware.py     # 状态管理
│   │   └── i18n_middleware.py      # 国际化
│   │
│   ├── common/                     # 公共模块
│   │   ├── __init__.py
│   │   ├── exception/              # 异常处理
│   │   ├── response/               # 响应封装
│   │   ├── security/               # 安全相关
│   │   ├── socketio/               # Socket.IO
│   │   ├── prometheus/             # Prometheus监控
│   │   ├── model.py                # 基础模型
│   │   ├── schema.py               # 基础Schema
│   │   ├── pagination.py           # 分页
│   │   ├── enums.py                # 枚举定义
│   │   ├── log.py                  # 日志配置
│   │   ├── i18n.py                 # 国际化
│   │   ├── context.py              # 上下文
│   │   ├── dataclasses.py          # 数据类
│   │   └── queue.py                # 队列
│   │
│   ├── app/                        # 业务应用
│   │   ├── __init__.py
│   │   ├── router.py               # 路由汇总
│   │   │
│   │   ├── admin/                  # 管理模块 (用户/角色/权限)
│   │   │   ├── __init__.py
│   │   │   ├── api/
│   │   │   │   ├── router.py
│   │   │   │   └── v1/
│   │   │   │       ├── auth/       # 认证接口
│   │   │   │       ├── sys/        # 系统管理接口
│   │   │   │       ├── log/        # 日志接口
│   │   │   │       └── monitor/    # 监控接口
│   │   │   ├── crud/               # CRUD操作
│   │   │   │   ├── crud_user.py
│   │   │   │   ├── crud_role.py
│   │   │   │   ├── crud_menu.py
│   │   │   │   └── ...
│   │   │   ├── model/              # 数据模型
│   │   │   │   ├── user.py
│   │   │   │   ├── role.py
│   │   │   │   ├── menu.py
│   │   │   │   ├── dept.py
│   │   │   │   └── m2m.py          # 多对多关联表
│   │   │   ├── schema/             # Pydantic Schema
│   │   │   │   ├── user.py
│   │   │   │   ├── role.py
│   │   │   │   ├── token.py
│   │   │   │   └── ...
│   │   │   ├── service/            # 业务服务
│   │   │   │   ├── auth_service.py
│   │   │   │   ├── user_service.py
│   │   │   │   ├── role_service.py
│   │   │   │   └── ...
│   │   │   ├── utils/              # 模块工具
│   │   │   └── tests/              # 测试
│   │   │
│   │   └── task/                   # Celery任务模块
│   │       ├── __init__.py
│   │       ├── database.py         # 任务数据库
│   │       ├── enums.py            # 任务枚举
│   │       ├── api/v1/             # 任务API
│   │       ├── crud/               # 任务CRUD
│   │       ├── model/              # 任务模型
│   │       ├── schema/             # 任务Schema
│   │       ├── service/            # 任务服务
│   │       ├── tasks/              # Celery任务定义
│   │       │   ├── base.py
│   │       │   ├── beat.py         # 定时任务
│   │       │   ├── tasks.py
│   │       │   └── db_log/         # 日志任务
│   │       └── utils/
│   │
│   ├── plugin/                     # 插件系统
│   │   ├── __init__.py
│   │   ├── tools.py                # 插件工具
│   │   ├── code_generator/         # 代码生成器插件
│   │   ├── config/                 # 配置管理插件
│   │   ├── dict/                   # 字典管理插件
│   │   ├── email/                  # 邮件插件
│   │   ├── notice/                 # 通知插件
│   │   └── oauth2/                 # OAuth2插件
│   │       ├── api/v1/
│   │       ├── crud/
│   │       ├── model/
│   │       ├── schema/
│   │       └── service/
│   │
│   ├── utils/                      # 全局工具
│   │   ├── __init__.py
│   │   └── ...                     # 各类工具函数
│   │
│   ├── locale/                     # 国际化资源
│   ├── static/                     # 静态文件
│   ├── scripts/                    # 脚本
│   ├── sql/                        # SQL文件
│   │
│   └── alembic/                    # 数据库迁移
│       └── versions/
│
├── deploy/                         # 部署配置
├── .github/                        # GitHub配置
├── docker-compose.yml              # Docker编排
├── Dockerfile                      # Docker镜像
├── pyproject.toml                  # 项目配置
├── requirements.txt                # 依赖
└── README.md
```

### 1.3 模块分层架构

每个业务模块 (admin, task, 插件) 遵循统一的分层结构：

```text
module/
├── api/                # API层 - 路由和请求处理
│   ├── router.py
│   └── v1/
│       └── xxx.py
├── crud/               # CRUD层 - 数据库操作
│   └── crud_xxx.py
├── model/              # Model层 - SQLAlchemy ORM模型
│   └── xxx.py
├── schema/             # Schema层 - Pydantic数据验证
│   └── xxx.py
├── service/            # Service层 - 业务逻辑
│   └── xxx_service.py
├── utils/              # 模块工具
└── tests/              # 测试
```

---

## 2. 核心配置

### 2.1 配置管理 (基于 pydantic-settings)

```python
# backend/core/conf.py
from functools import lru_cache
from typing import Literal
from pydantic import model_validator
from pydantic_settings import BaseSettings, SettingsConfigDict
from backend.core.path_conf import BASE_PATH

class Settings(BaseSettings):
    """全局配置"""

    model_config = SettingsConfigDict(
        env_file=f'{BASE_PATH}/.env',
        env_file_encoding='utf-8',
        extra='ignore',
        case_sensitive=True,
    )

    # 环境
    ENVIRONMENT: Literal['dev', 'prod']

    # FastAPI
    FASTAPI_API_V1_PATH: str = '/api/v1'
    FASTAPI_TITLE: str = 'AI Creator'
    FASTAPI_DESCRIPTION: str = 'AI Creator Cloud Backend'
    FASTAPI_DOCS_URL: str = '/docs'
    FASTAPI_OPENAPI_URL: str | None = '/openapi'

    # 数据库
    DATABASE_TYPE: Literal['mysql', 'postgresql']
    DATABASE_HOST: str
    DATABASE_PORT: int
    DATABASE_USER: str
    DATABASE_PASSWORD: str
    DATABASE_SCHEMA: str = 'ai_creator'
    DATABASE_ECHO: bool | Literal['debug'] = False
    DATABASE_PK_MODE: Literal['autoincrement', 'snowflake'] = 'autoincrement'

    # Redis
    REDIS_HOST: str
    REDIS_PORT: int
    REDIS_PASSWORD: str
    REDIS_DATABASE: int
    REDIS_TIMEOUT: int = 5

    # Token/JWT
    TOKEN_SECRET_KEY: str
    TOKEN_ALGORITHM: str = 'HS256'
    TOKEN_EXPIRE_SECONDS: int = 60 * 60 * 24      # 1天
    TOKEN_REFRESH_EXPIRE_SECONDS: int = 60 * 60 * 24 * 7  # 7天
    TOKEN_REDIS_PREFIX: str = 'ai_creator:token'

    # 用户安全
    USER_LOCK_THRESHOLD: int = 5
    USER_LOCK_SECONDS: int = 60 * 5
    USER_PASSWORD_MIN_LENGTH: int = 6
    USER_PASSWORD_MAX_LENGTH: int = 32

    # 登录
    LOGIN_CAPTCHA_ENABLED: bool = True
    LOGIN_CAPTCHA_EXPIRE_SECONDS: int = 60 * 5

    # CORS
    CORS_ALLOWED_ORIGINS: list[str] = [
        'http://127.0.0.1:8000',
        'http://localhost:5173',
    ]

    # Celery
    CELERY_BROKER: Literal['rabbitmq', 'redis'] = 'redis'
    CELERY_BROKER_REDIS_DATABASE: int
    CELERY_RABBITMQ_HOST: str
    CELERY_RABBITMQ_PORT: int
    CELERY_RABBITMQ_USERNAME: str
    CELERY_RABBITMQ_PASSWORD: str

    # AI服务 (扩展配置)
    ANTHROPIC_API_KEY: str | None = None
    OPENAI_API_KEY: str | None = None
    LITELLM_PROXY_URL: str | None = None

    # 存储
    S3_ENDPOINT: str | None = None
    S3_ACCESS_KEY: str | None = None
    S3_SECRET_KEY: str | None = None
    S3_BUCKET: str = 'ai-creator'

    # 浏览器池
    BROWSER_POOL_SIZE: int = 10
    BROWSER_WORKER_REPLICAS: int = 3

    # 国际化
    I18N_DEFAULT_LANGUAGE: str = 'zh-CN'

    # 时间配置
    DATETIME_TIMEZONE: str = 'Asia/Shanghai'

    @model_validator(mode='before')
    @classmethod
    def check_env(cls, values):
        """检查环境变量"""
        if values.get('ENVIRONMENT') == 'prod':
            values['FASTAPI_OPENAPI_URL'] = None
            values['CELERY_BROKER'] = 'rabbitmq'
        return values


@lru_cache
def get_settings() -> Settings:
    """获取全局配置单例"""
    return Settings()


settings = get_settings()
```

### 2.2 数据库连接

```python
# backend/database/db.py
from collections.abc import AsyncGenerator
from typing import Annotated
from uuid import uuid4

from fastapi import Depends
from sqlalchemy import URL
from sqlalchemy.ext.asyncio import (
    AsyncEngine,
    AsyncSession,
    async_sessionmaker,
    create_async_engine,
)

from backend.common.enums import DataBaseType
from backend.common.model import MappedBase
from backend.core.conf import settings


def create_database_url(*, unittest: bool = False) -> URL:
    """创建数据库链接"""
    url = URL.create(
        drivername='mysql+asyncmy' if DataBaseType.mysql == settings.DATABASE_TYPE else 'postgresql+asyncpg',
        username=settings.DATABASE_USER,
        password=settings.DATABASE_PASSWORD,
        host=settings.DATABASE_HOST,
        port=settings.DATABASE_PORT,
        database=settings.DATABASE_SCHEMA if not unittest else f'{settings.DATABASE_SCHEMA}_test',
    )
    return url


def create_async_engine_and_session(url: str | URL) -> tuple[AsyncEngine, async_sessionmaker[AsyncSession]]:
    """创建数据库引擎和 Session"""
    engine = create_async_engine(
        url,
        echo=settings.DATABASE_ECHO,
        future=True,
        pool_size=10,
        max_overflow=20,
        pool_timeout=30,
        pool_recycle=3600,
        pool_pre_ping=True,
    )
    db_session = async_sessionmaker(
        bind=engine,
        class_=AsyncSession,
        autoflush=False,
        expire_on_commit=False,
    )
    return engine, db_session


async def get_db() -> AsyncGenerator[AsyncSession, None]:
    """获取数据库会话"""
    async with async_db_session() as session:
        yield session


async def get_db_transaction() -> AsyncGenerator[AsyncSession, None]:
    """获取带有事务的数据库会话"""
    async with async_db_session.begin() as session:
        yield session


# SQLA 数据库链接
SQLALCHEMY_DATABASE_URL = create_database_url()
async_engine, async_db_session = create_async_engine_and_session(SQLALCHEMY_DATABASE_URL)

# Session Annotated
CurrentSession = Annotated[AsyncSession, Depends(get_db)]
CurrentSessionTransaction = Annotated[AsyncSession, Depends(get_db_transaction)]
```

### 2.3 模型配置系统

```python
# app/core/model_config.py
from enum import Enum
from typing import Optional, List
from pydantic import BaseModel
from datetime import datetime

class ModelType(str, Enum):
    """模型类型"""
    TEXT = "text"           # 文本生成
    REASONING = "reasoning"  # 推理模型
    VISION = "vision"        # 视觉理解
    IMAGE = "image"          # 图像生成
    VIDEO = "video"          # 视频生成
    EMBEDDING = "embedding"  # 向量嵌入
    TTS = "tts"             # 语音合成
    STT = "stt"             # 语音识别

class ModelProvider(str, Enum):
    """模型供应商"""
    # 国际
    OPENAI = "openai"
    ANTHROPIC = "anthropic"
    GOOGLE = "google"
    MISTRAL = "mistral"
    XAI = "xai"
    COHERE = "cohere"
    # 国内
    ALIBABA = "alibaba"      # 通义千问
    BAIDU = "baidu"          # 文心一言
    ZHIPU = "zhipu"          # 智谱AI
    MOONSHOT = "moonshot"    # 月之暗面
    DEEPSEEK = "deepseek"
    XUNFEI = "xunfei"        # 讯飞星火
    BYTEDANCE = "bytedance"  # 豆包

class ModelConfig(BaseModel):
    """单个模型配置"""
    model_id: str                    # 模型ID (如 gpt-4o, claude-3-5-sonnet)
    provider: ModelProvider          # 供应商
    model_type: ModelType            # 模型类型
    display_name: str                # 显示名称
    priority: int = 100              # 优先级 (越小越优先)
    enabled: bool = True             # 是否启用

    # 能力参数
    max_tokens: int = 4096           # 最大输出tokens
    supports_streaming: bool = True  # 支持流式
    supports_tools: bool = True      # 支持工具调用
    supports_vision: bool = False    # 支持图像输入

    # 成本配置 (美元/1K tokens)
    input_cost_per_1k: float = 0.0
    output_cost_per_1k: float = 0.0

    # 限制
    rpm_limit: int = 60              # 每分钟请求数限制
    tpm_limit: int = 100000          # 每分钟token数限制

class ModelGroupConfig(BaseModel):
    """模型组配置 (按类型分组，支持故障转移)"""
    group_id: str                    # 组ID
    model_type: ModelType            # 模型类型
    models: List[ModelConfig]        # 模型列表 (按priority排序)
    fallback_enabled: bool = True    # 启用故障转移
    retry_count: int = 3             # 重试次数
    timeout_seconds: int = 30        # 超时时间

class SystemModelConfig(BaseModel):
    """系统模型配置 (云端存储)"""
    version: str                     # 配置版本
    updated_at: datetime
    groups: List[ModelGroupConfig]   # 模型组列表
    api_keys: dict                   # {provider: encrypted_key} 加密存储
```

### 2.4 LLM模型网关

```python
# app/core/llm_gateway.py
import litellm
from litellm import acompletion
from typing import Optional, List, AsyncGenerator
from dataclasses import dataclass
import asyncio
import logging

from .model_config import ModelConfig, ModelGroupConfig, ModelType
from .circuit_breaker import CircuitBreaker
from .usage_tracker import UsageTracker

logger = logging.getLogger(__name__)

@dataclass
class LLMResponse:
    """LLM响应"""
    content: str
    model: str
    provider: str
    usage: dict
    cost: float
    latency_ms: int

class LLMGateway:
    """
    统一LLM网关
    - 支持100+模型供应商 (通过LiteLLM)
    - 自动故障转移
    - 成本追踪
    - 熔断机制
    """

    def __init__(
        self,
        config: "SystemModelConfig",
        usage_tracker: UsageTracker,
    ):
        self.config = config
        self.usage_tracker = usage_tracker
        self.circuit_breakers: dict[str, CircuitBreaker] = {}
        self._setup_litellm()

    def _setup_litellm(self):
        """配置LiteLLM"""
        for provider, api_key in self.config.api_keys.items():
            # 根据provider设置对应的环境变量
            litellm.api_key = api_key
        litellm.success_callback = [self._on_success]
        litellm.failure_callback = [self._on_failure]
        litellm.request_timeout = 30

    def _get_circuit_breaker(self, model_id: str) -> CircuitBreaker:
        """获取或创建熔断器"""
        if model_id not in self.circuit_breakers:
            self.circuit_breakers[model_id] = CircuitBreaker(
                failure_threshold=5,
                recovery_timeout=60,
            )
        return self.circuit_breakers[model_id]

    async def chat(
        self,
        messages: List[dict],
        model_type: ModelType = ModelType.TEXT,
        user_id: str = None,
        system: Optional[str] = None,
        max_tokens: int = 4096,
        temperature: float = 0.7,
        stream: bool = False,
    ) -> LLMResponse | AsyncGenerator:
        """
        发送对话请求，自动选择模型和故障转移
        """
        group = self._get_model_group(model_type)
        if not group:
            raise ValueError(f"No model group found for type: {model_type}")

        # 检查用户配额
        if user_id:
            quota_ok = await self.usage_tracker.check_quota(user_id)
            if not quota_ok:
                raise QuotaExceededError(f"User {user_id} quota exceeded")

        # 按优先级尝试模型
        last_error = None
        for model_config in sorted(group.models, key=lambda m: m.priority):
            if not model_config.enabled:
                continue

            breaker = self._get_circuit_breaker(model_config.model_id)
            if not breaker.can_execute():
                logger.warning(f"Circuit breaker open for {model_config.model_id}")
                continue

            try:
                litellm_model = self._get_litellm_model_name(model_config)
                full_messages = messages.copy()
                if system:
                    full_messages.insert(0, {"role": "system", "content": system})

                start_time = asyncio.get_event_loop().time()

                if stream:
                    return self._stream_response(
                        litellm_model, full_messages, model_config,
                        user_id, max_tokens, temperature
                    )

                response = await acompletion(
                    model=litellm_model,
                    messages=full_messages,
                    max_tokens=max_tokens,
                    temperature=temperature,
                )

                latency_ms = int((asyncio.get_event_loop().time() - start_time) * 1000)
                cost = self._calculate_cost(response.usage, model_config)

                if user_id:
                    await self.usage_tracker.record_usage(
                        user_id=user_id,
                        model_id=model_config.model_id,
                        input_tokens=response.usage.prompt_tokens,
                        output_tokens=response.usage.completion_tokens,
                        cost=cost,
                    )

                breaker.record_success()

                return LLMResponse(
                    content=response.choices[0].message.content,
                    model=model_config.model_id,
                    provider=model_config.provider.value,
                    usage={
                        "input_tokens": response.usage.prompt_tokens,
                        "output_tokens": response.usage.completion_tokens,
                    },
                    cost=cost,
                    latency_ms=latency_ms,
                )

            except Exception as e:
                last_error = e
                logger.error(f"Model {model_config.model_id} failed: {e}")
                breaker.record_failure()
                if not group.fallback_enabled:
                    raise
                continue

        raise AllModelsFailedError(f"All models failed. Last error: {last_error}")

    async def _stream_response(
        self,
        model: str,
        messages: List[dict],
        model_config: ModelConfig,
        user_id: str,
        max_tokens: int,
        temperature: float,
    ) -> AsyncGenerator[str, None]:
        """流式响应"""
        total_tokens = 0
        response = await acompletion(
            model=model,
            messages=messages,
            max_tokens=max_tokens,
            temperature=temperature,
            stream=True,
        )

        async for chunk in response:
            if chunk.choices[0].delta.content:
                total_tokens += 1
                yield chunk.choices[0].delta.content

        if user_id:
            cost = total_tokens * model_config.output_cost_per_1k / 1000
            await self.usage_tracker.record_usage(
                user_id=user_id,
                model_id=model_config.model_id,
                input_tokens=0,
                output_tokens=total_tokens,
                cost=cost,
            )

    def _get_litellm_model_name(self, config: ModelConfig) -> str:
        """获取LiteLLM格式的模型名称"""
        provider_prefix = {
            "openai": "",
            "anthropic": "anthropic/",
            "google": "gemini/",
            "alibaba": "dashscope/",
            "zhipu": "zhipu/",
            "deepseek": "deepseek/",
            "moonshot": "moonshot/",
        }
        prefix = provider_prefix.get(config.provider.value, "")
        return f"{prefix}{config.model_id}"

    def _get_model_group(self, model_type: ModelType) -> Optional[ModelGroupConfig]:
        """获取模型组"""
        for group in self.config.groups:
            if group.model_type == model_type:
                return group
        return None

    def _calculate_cost(self, usage, config: ModelConfig) -> float:
        """计算成本"""
        input_cost = usage.prompt_tokens * config.input_cost_per_1k / 1000
        output_cost = usage.completion_tokens * config.output_cost_per_1k / 1000
        return input_cost + output_cost

class QuotaExceededError(Exception):
    """配额超限异常"""
    pass

class AllModelsFailedError(Exception):
    """所有模型失败异常"""
    pass
```

### 2.5 熔断器实现

```python
# app/core/circuit_breaker.py
from datetime import datetime, timedelta
from enum import Enum
from typing import Optional
import threading

class CircuitState(Enum):
    CLOSED = "closed"        # 正常状态
    OPEN = "open"            # 熔断状态
    HALF_OPEN = "half_open"  # 半开状态 (尝试恢复)

class CircuitBreaker:
    """
    熔断器
    - 连续失败达到阈值后熔断
    - 熔断后等待恢复时间
    - 半开状态尝试单个请求
    """

    def __init__(
        self,
        failure_threshold: int = 5,
        recovery_timeout: int = 60,
        half_open_max_calls: int = 1,
    ):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.half_open_max_calls = half_open_max_calls

        self.state = CircuitState.CLOSED
        self.failure_count = 0
        self.success_count = 0
        self.last_failure_time: Optional[datetime] = None
        self.half_open_calls = 0
        self._lock = threading.Lock()

    def can_execute(self) -> bool:
        """检查是否可以执行请求"""
        with self._lock:
            if self.state == CircuitState.CLOSED:
                return True

            if self.state == CircuitState.OPEN:
                if self._should_attempt_reset():
                    self.state = CircuitState.HALF_OPEN
                    self.half_open_calls = 0
                    return True
                return False

            if self.state == CircuitState.HALF_OPEN:
                if self.half_open_calls < self.half_open_max_calls:
                    self.half_open_calls += 1
                    return True
                return False

        return False

    def record_success(self):
        """记录成功"""
        with self._lock:
            if self.state == CircuitState.HALF_OPEN:
                self.success_count += 1
                if self.success_count >= self.half_open_max_calls:
                    self._reset()
            else:
                self.failure_count = 0

    def record_failure(self):
        """记录失败"""
        with self._lock:
            self.failure_count += 1
            self.last_failure_time = datetime.utcnow()

            if self.state == CircuitState.HALF_OPEN:
                self.state = CircuitState.OPEN
            elif self.failure_count >= self.failure_threshold:
                self.state = CircuitState.OPEN

    def _should_attempt_reset(self) -> bool:
        """检查是否应该尝试恢复"""
        if self.last_failure_time is None:
            return True
        return datetime.utcnow() - self.last_failure_time > timedelta(
            seconds=self.recovery_timeout
        )

    def _reset(self):
        """重置熔断器"""
        self.state = CircuitState.CLOSED
        self.failure_count = 0
        self.success_count = 0
        self.half_open_calls = 0

    def get_status(self) -> dict:
        """获取熔断器状态"""
        return {
            "state": self.state.value,
            "failure_count": self.failure_count,
            "last_failure_time": (
                self.last_failure_time.isoformat()
                if self.last_failure_time else None
            ),
        }
```

### 2.6 用量追踪与配额管理

```python
# app/core/usage_tracker.py
from datetime import datetime
from typing import Optional
from dataclasses import dataclass
from decimal import Decimal
import redis.asyncio as redis
from sqlalchemy.ext.asyncio import AsyncSession

@dataclass
class UsageSummary:
    tokens: int
    cost: float

@dataclass
class UserQuota:
    max_tokens_per_month: Optional[int] = None
    max_tokens_per_day: Optional[int] = None
    max_cost_per_month: Optional[float] = None
    max_cost_per_day: Optional[float] = None

class UsageTracker:
    """
    用量追踪器
    - 记录每个用户的token使用量和费用
    - 实时配额检查
    - 支持熔断 (超限自动禁用)
    """

    def __init__(
        self,
        redis_client: redis.Redis,
        db_session: AsyncSession,
    ):
        self.redis = redis_client
        self.db = db_session

    async def check_quota(self, user_id: str) -> bool:
        """检查用户配额，返回True表示可以继续使用"""
        quota = await self._get_user_quota(user_id)
        if not quota:
            return True

        usage = await self._get_current_usage(user_id)

        if quota.max_tokens_per_month and usage.tokens >= quota.max_tokens_per_month:
            return False

        if quota.max_cost_per_month and usage.cost >= quota.max_cost_per_month:
            return False

        if quota.max_tokens_per_day:
            daily_usage = await self._get_daily_usage(user_id)
            if daily_usage.tokens >= quota.max_tokens_per_day:
                return False

        return True

    async def record_usage(
        self,
        user_id: str,
        model_id: str,
        input_tokens: int,
        output_tokens: int,
        cost: float,
    ):
        """记录使用量"""
        now = datetime.utcnow()
        total_tokens = input_tokens + output_tokens

        # 更新Redis缓存 (实时统计)
        month_key = f"usage:{user_id}:{now.strftime('%Y-%m')}"
        day_key = f"usage:{user_id}:{now.strftime('%Y-%m-%d')}"

        pipe = self.redis.pipeline()
        pipe.hincrby(month_key, "tokens", total_tokens)
        pipe.hincrbyfloat(month_key, "cost", cost)
        pipe.hincrby(day_key, "tokens", total_tokens)
        pipe.hincrbyfloat(day_key, "cost", cost)
        pipe.expire(month_key, 86400 * 35)  # 35天过期
        pipe.expire(day_key, 86400 * 2)     # 2天过期
        await pipe.execute()

        # 异步写入数据库 (持久化)
        await self._save_usage_record(
            user_id=user_id,
            model_id=model_id,
            input_tokens=input_tokens,
            output_tokens=output_tokens,
            cost=Decimal(str(cost)),
            timestamp=now,
        )

    async def get_usage_summary(
        self,
        user_id: str,
        start_date: datetime,
        end_date: datetime,
    ) -> dict:
        """获取用量汇总"""
        records = await self._query_usage_records(user_id, start_date, end_date)

        by_model = {}
        total_tokens = 0
        total_cost = Decimal("0")

        for record in records:
            model_id = record.model_id
            if model_id not in by_model:
                by_model[model_id] = {"tokens": 0, "cost": Decimal("0"), "calls": 0}

            by_model[model_id]["tokens"] += record.input_tokens + record.output_tokens
            by_model[model_id]["cost"] += record.cost
            by_model[model_id]["calls"] += 1

            total_tokens += record.input_tokens + record.output_tokens
            total_cost += record.cost

        return {
            "period": {
                "start": start_date.isoformat(),
                "end": end_date.isoformat(),
            },
            "total_tokens": total_tokens,
            "total_cost": float(total_cost),
            "by_model": {
                k: {**v, "cost": float(v["cost"])} for k, v in by_model.items()
            },
        }

    async def _get_user_quota(self, user_id: str) -> Optional[UserQuota]:
        """获取用户配额配置"""
        # 从数据库或缓存获取
        pass

    async def _get_current_usage(self, user_id: str) -> UsageSummary:
        """获取当月使用量"""
        now = datetime.utcnow()
        month_key = f"usage:{user_id}:{now.strftime('%Y-%m')}"
        data = await self.redis.hgetall(month_key)
        return UsageSummary(
            tokens=int(data.get(b"tokens", 0)),
            cost=float(data.get(b"cost", 0)),
        )

    async def _get_daily_usage(self, user_id: str) -> UsageSummary:
        """获取当日使用量"""
        now = datetime.utcnow()
        day_key = f"usage:{user_id}:{now.strftime('%Y-%m-%d')}"
        data = await self.redis.hgetall(day_key)
        return UsageSummary(
            tokens=int(data.get(b"tokens", 0)),
            cost=float(data.get(b"cost", 0)),
        )

    async def _save_usage_record(self, **kwargs):
        """保存使用记录到数据库"""
        pass

    async def _query_usage_records(self, user_id, start_date, end_date):
        """查询使用记录"""
        pass
```

### 2.7 模型管理API

```python
# app/api/v1/models.py
from fastapi import APIRouter, Depends, HTTPException
from datetime import datetime, timedelta

router = APIRouter()

@router.get("/config")
async def get_model_config():
    """
    获取模型配置 (客户端调用)
    返回可用模型列表，不包含API密钥
    """
    config = await get_system_config()

    return {
        "version": config.version,
        "updated_at": config.updated_at.isoformat(),
        "groups": [
            {
                "group_id": g.group_id,
                "model_type": g.model_type.value,
                "models": [
                    {
                        "model_id": m.model_id,
                        "provider": m.provider.value,
                        "display_name": m.display_name,
                        "supports_streaming": m.supports_streaming,
                        "supports_vision": m.supports_vision,
                        "max_tokens": m.max_tokens,
                    }
                    for m in g.models if m.enabled
                ]
            }
            for g in config.groups
        ]
    }

@router.get("/usage")
async def get_usage(
    user_id: str = Depends(get_current_user_id),
    period: str = "month",
):
    """获取用户用量统计"""
    tracker = get_usage_tracker()

    now = datetime.utcnow()
    if period == "day":
        start = now.replace(hour=0, minute=0, second=0, microsecond=0)
    elif period == "week":
        start = now - timedelta(days=7)
    else:
        start = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)

    return await tracker.get_usage_summary(user_id, start, now)

@router.get("/quota")
async def get_quota(user_id: str = Depends(get_current_user_id)):
    """获取用户配额"""
    quota = await get_user_quota(user_id)
    usage = await get_current_usage(user_id)

    return {
        "quota": {
            "max_tokens_per_month": quota.max_tokens_per_month,
            "max_cost_per_month": quota.max_cost_per_month,
        },
        "used": {
            "tokens": usage.tokens,
            "cost": usage.cost,
        },
        "remaining": {
            "tokens": max(0, (quota.max_tokens_per_month or float('inf')) - usage.tokens),
            "cost": max(0, (quota.max_cost_per_month or float('inf')) - usage.cost),
        }
    }

# 管理员API
@router.put("/config", dependencies=[Depends(admin_required)])
async def update_model_config(config: "SystemModelConfig"):
    """更新模型配置 (管理员)"""
    await save_system_config(config)
    return {"success": True}

@router.get("/status", dependencies=[Depends(admin_required)])
async def get_model_status():
    """获取模型状态 (管理员)"""
    gateway = get_llm_gateway()
    return {
        "circuit_breakers": {
            model_id: breaker.get_status()
            for model_id, breaker in gateway.circuit_breakers.items()
        }
    }
```

### 2.8 桌面端调用方式

> 更新: 2025-12-28 | 云端 LLM 网关已完成开发，桌面端通过统一接口调用

#### 2.8.1 调用架构

```text
┌─────────────────────────────────────────────────────────────────────────┐
│                     桌面端 LLM 调用架构                                    │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  ┌─────────────┐     ┌─────────────────┐     ┌─────────────────────┐   │
│  │  桌面端 UI   │────▶│  Python Sidecar │────▶│  云端 LLM 网关      │   │
│  │  (Tauri)    │     │  (LocalExecutor) │     │  (已完成)           │   │
│  └─────────────┘     └─────────────────┘     └─────────────────────┘   │
│                              │                        │                │
│                              │                        │                │
│                              ▼                        ▼                │
│                      ┌─────────────────┐     ┌─────────────────────┐   │
│                      │  agent-core     │     │ OpenAI/Anthropic    │   │
│                      │  (LLM统一接口)  │     │ 兼容 API 接口       │   │
│                      └─────────────────┘     └─────────────────────┘   │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

#### 2.8.2 API Token 获取与认证

桌面端用户需要获取 API Token 才能调用云端 LLM 网关。

**Token 格式**: `sk-cf-{user_id_hash}_{random_suffix}`

**获取流程**:

1. 用户在桌面端登录 (OAuth2/手机号)
2. 调用 `/api/v1/auth/token` 获取 API Token
3. Token 存储在本地配置文件 (`~/.ai-creator/llm-config.json`)
4. 后续请求携带 `Authorization: Bearer sk-cf-xxx`

```python
# 云端 Token 生成接口
@router.post("/token")
async def generate_api_token(
    user_id: str = Depends(get_current_user_id),
    db: AsyncSession = Depends(get_db),
):
    """
    生成桌面端 API Token

    - Token 绑定用户ID，用于用量追踪和配额控制
    - 支持 Token 刷新和撤销
    """
    import hashlib
    import secrets

    # 生成 Token
    user_hash = hashlib.sha256(user_id.encode()).hexdigest()[:8]
    random_suffix = secrets.token_hex(16)
    api_token = f"sk-cf-{user_hash}_{random_suffix}"

    # 存储 Token (关联用户)
    await db.execute(
        insert(APITokens).values(
            user_id=user_id,
            token_hash=hashlib.sha256(api_token.encode()).hexdigest(),
            created_at=datetime.utcnow(),
            expires_at=datetime.utcnow() + timedelta(days=365),
        )
    )
    await db.commit()

    return {
        "api_token": api_token,
        "expires_at": (datetime.utcnow() + timedelta(days=365)).isoformat(),
    }
```

#### 2.8.3 OpenAI 兼容接口

云端提供 OpenAI 兼容的 API 接口，桌面端直接调用：

```python
# 云端 OpenAI 兼容接口
@router.post("/v1/chat/completions")
async def chat_completions(
    request: ChatCompletionRequest,
    authorization: str = Header(...),
    db: AsyncSession = Depends(get_db),
):
    """
    OpenAI 兼容的聊天接口

    - 验证 API Token
    - 检查用户配额
    - 调用 LLMGateway
    - 记录用量
    """
    # 1. 验证 Token
    user_id = await verify_api_token(authorization, db)

    # 2. 检查配额
    usage_tracker = get_usage_tracker()
    if not await usage_tracker.check_quota(user_id):
        raise HTTPException(status_code=429, detail="Quota exceeded")

    # 3. 调用 LLMGateway
    gateway = get_llm_gateway()
    response = await gateway.chat(
        messages=request.messages,
        model_type=ModelType.TEXT,
        user_id=user_id,
        system=request.messages[0].get("content") if request.messages[0].get("role") == "system" else None,
        max_tokens=request.max_tokens or 4096,
        temperature=request.temperature or 0.7,
        stream=request.stream or False,
    )

    # 4. 返回 OpenAI 格式响应
    if request.stream:
        return StreamingResponse(
            _stream_sse(response),
            media_type="text/event-stream",
        )

    return {
        "id": f"chatcmpl-{uuid.uuid4().hex[:8]}",
        "object": "chat.completion",
        "created": int(datetime.utcnow().timestamp()),
        "model": response.model,
        "choices": [{
            "index": 0,
            "message": {
                "role": "assistant",
                "content": response.content,
            },
            "finish_reason": "stop",
        }],
        "usage": {
            "prompt_tokens": response.usage["input_tokens"],
            "completion_tokens": response.usage["output_tokens"],
            "total_tokens": response.usage["input_tokens"] + response.usage["output_tokens"],
        },
    }
```

#### 2.8.4 桌面端配置文件

> 用户登录后自动生成，无需手动配置

桌面端配置自动存储在 `~/.ai-creator/llm-config.json`:

```json
// 自动生成，用户无需手动创建
{
  "production": {
    "api_token": "sk-cf-xxxxxxxxxxxxxx"
  }
}
```

#### 2.8.5 Token 分发流程

```text
┌─────────────────────────────────────────────────────────────────────────┐
│                     Token 自动分发流程                                    │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  1. 用户在桌面端登录 (OAuth2/手机号/邮箱)                                 │
│                          │                                              │
│                          ▼                                              │
│  2. 云端验证用户身份，返回用户 JWT Token                                  │
│                          │                                              │
│                          ▼                                              │
│  3. 桌面端调用 /api/v1/auth/llm-token 获取 LLM API Token                │
│                          │                                              │
│                          ▼                                              │
│  4. 云端为该用户生成/返回独立的 API Token (sk-cf-xxx)                     │
│                          │                                              │
│                          ▼                                              │
│  5. 桌面端自动保存 Token 到本地配置文件                                   │
│                          │                                              │
│                          ▼                                              │
│  6. 后续 LLM 调用自动携带 Token，无需用户干预                             │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

**特点**:
- 用户无需手动配置任何 LLM 相关设置
- 每个用户拥有独立的 API Token
- Token 用于用量追踪和配额控制
- 登出时自动清除本地 Token

详细接口设计参见 [Agent-Runtime 文档 10.LLM统一接口设计](./05-Agent-Runtime.md#10-llm-统一接口设计)

### 2.9 数据库模型 (SQLAlchemy ORM)

```python
# backend/app/llm/model/provider.py
from sqlalchemy import Column, String, Boolean, Integer, Float, Text, JSON, Enum as SQLEnum
from sqlalchemy.dialects.postgresql import UUID
from sqlalchemy.orm import relationship
from backend.common.model import MappedBase
from enum import Enum
import uuid

class ModelTypeEnum(str, Enum):
    """模型类型枚举"""
    TEXT = "text"
    REASONING = "reasoning"
    VISION = "vision"
    IMAGE = "image"
    VIDEO = "video"
    EMBEDDING = "embedding"
    TTS = "tts"
    STT = "stt"


class ModelProviderDB(MappedBase):
    """模型供应商表"""
    __tablename__ = "model_providers"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)

    # 基本信息
    provider_id = Column(String(50), unique=True, nullable=False, index=True)  # openai, anthropic, alibaba
    display_name = Column(String(100), nullable=False)  # OpenAI, Anthropic, 阿里云
    description = Column(Text, nullable=True)

    # API配置
    api_base_url = Column(String(500), nullable=True)  # 自定义API地址
    api_key_encrypted = Column(Text, nullable=True)     # AES-256加密的API Key

    # 状态
    enabled = Column(Boolean, default=True)
    is_domestic = Column(Boolean, default=False)  # 是否国内供应商

    # 限制配置
    global_rpm_limit = Column(Integer, default=1000)   # 供应商级别RPM限制
    global_tpm_limit = Column(Integer, default=1000000)  # 供应商级别TPM限制

    # 关联
    models = relationship("ModelConfigDB", back_populates="provider", lazy="selectin")


class ModelConfigDB(MappedBase):
    """模型配置表"""
    __tablename__ = "model_configs"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)

    # 关联供应商
    provider_id = Column(UUID(as_uuid=True), ForeignKey("model_providers.id"), nullable=False)

    # 基本信息
    model_id = Column(String(100), unique=True, nullable=False, index=True)  # gpt-4o, claude-3-5-sonnet
    display_name = Column(String(100), nullable=False)
    model_type = Column(SQLEnum(ModelTypeEnum), nullable=False)

    # 能力参数
    max_tokens = Column(Integer, default=4096)
    max_context_length = Column(Integer, default=128000)
    supports_streaming = Column(Boolean, default=True)
    supports_tools = Column(Boolean, default=True)
    supports_vision = Column(Boolean, default=False)

    # 成本配置 (美元/1K tokens)
    input_cost_per_1k = Column(Float, default=0.0)
    output_cost_per_1k = Column(Float, default=0.0)

    # 限制配置
    rpm_limit = Column(Integer, default=60)      # 每分钟请求数
    tpm_limit = Column(Integer, default=100000)  # 每分钟token数

    # 优先级和状态
    priority = Column(Integer, default=100)  # 越小越优先
    enabled = Column(Boolean, default=True)

    # 关联
    provider = relationship("ModelProviderDB", back_populates="models")


class ModelGroupDB(MappedBase):
    """模型组表 (按类型分组，支持故障转移)"""
    __tablename__ = "model_groups"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)

    group_id = Column(String(50), unique=True, nullable=False, index=True)
    model_type = Column(SQLEnum(ModelTypeEnum), nullable=False)
    display_name = Column(String(100), nullable=False)

    # 模型列表 (JSON: [model_id1, model_id2, ...])
    model_ids = Column(JSON, default=list)

    # 故障转移配置
    fallback_enabled = Column(Boolean, default=True)
    retry_count = Column(Integer, default=3)
    timeout_seconds = Column(Integer, default=30)

    enabled = Column(Boolean, default=True)
```

### 2.9 用户 API Key 管理

```python
# backend/app/llm/model/api_key.py
from sqlalchemy import Column, String, Boolean, Integer, Float, DateTime, ForeignKey, Text, JSON, Enum as SQLEnum
from sqlalchemy.dialects.postgresql import UUID
from sqlalchemy.orm import relationship
from backend.common.model import MappedBase
from datetime import datetime
from enum import Enum
import uuid
import secrets


class ApiKeyStatus(str, Enum):
    """API Key状态"""
    ACTIVE = "active"
    DISABLED = "disabled"
    EXPIRED = "expired"
    REVOKED = "revoked"


class UserApiKey(MappedBase):
    """用户API Key表"""
    __tablename__ = "user_api_keys"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)

    # 关联用户
    user_id = Column(UUID(as_uuid=True), ForeignKey("sys_user.id"), nullable=False, index=True)

    # Key信息
    key_name = Column(String(100), nullable=False, default="Default Key")
    key_prefix = Column(String(10), nullable=False)  # ak-xxxx (用于显示)
    key_hash = Column(String(128), nullable=False, unique=True)  # SHA-256哈希
    key_encrypted = Column(Text, nullable=False)  # AES加密的完整Key (仅首次返回)

    # 状态
    status = Column(SQLEnum(ApiKeyStatus), default=ApiKeyStatus.ACTIVE)

    # 有效期
    created_at = Column(DateTime, default=datetime.utcnow)
    expires_at = Column(DateTime, nullable=True)  # NULL表示永不过期
    last_used_at = Column(DateTime, nullable=True)

    # 限制配置 (覆盖用户默认配额)
    custom_daily_tokens = Column(Integer, nullable=True)   # 自定义日限额
    custom_monthly_tokens = Column(Integer, nullable=True) # 自定义月限额
    custom_rpm_limit = Column(Integer, nullable=True)      # 自定义RPM限制

    # 允许的模型 (NULL表示全部)
    allowed_models = Column(JSON, nullable=True)  # ["gpt-4o", "claude-3-5-sonnet"]

    # 元数据
    metadata = Column(JSON, default=dict)  # 用户自定义元数据

    # 关联
    user = relationship("User", back_populates="api_keys")
    usage_records = relationship("UsageRecord", back_populates="api_key")

    @staticmethod
    def generate_api_key() -> tuple[str, str, str]:
        """
        生成API Key
        返回: (完整key, 前缀, 哈希)
        """
        import hashlib

        # 生成32字节随机token
        token = secrets.token_hex(32)
        full_key = f"sk-cf-{token}"  # sk-cf- 前缀标识创流
        prefix = f"sk-cf-{token[:8]}..."
        key_hash = hashlib.sha256(full_key.encode()).hexdigest()

        return full_key, prefix, key_hash


class RateLimitConfig(MappedBase):
    """速率限制配置表"""
    __tablename__ = "rate_limit_configs"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)

    # 配置名称 (如: free_tier, basic_tier, pro_tier)
    config_name = Column(String(50), unique=True, nullable=False)
    display_name = Column(String(100), nullable=False)

    # Token限制
    daily_token_limit = Column(Integer, nullable=True)    # 日限额
    weekly_token_limit = Column(Integer, nullable=True)   # 周限额
    monthly_token_limit = Column(Integer, nullable=True)  # 月限额

    # 费用限制 (美元)
    daily_cost_limit = Column(Float, nullable=True)
    weekly_cost_limit = Column(Float, nullable=True)
    monthly_cost_limit = Column(Float, nullable=True)

    # 速率限制
    rpm_limit = Column(Integer, default=60)    # 每分钟请求数
    tpm_limit = Column(Integer, default=40000) # 每分钟token数

    # 并发限制
    max_concurrent_requests = Column(Integer, default=5)

    # 模型访问限制
    allowed_model_types = Column(JSON, nullable=True)  # ["text", "vision"]
    blocked_models = Column(JSON, nullable=True)       # ["gpt-4-turbo"]

    is_default = Column(Boolean, default=False)


class UsageRecord(MappedBase):
    """使用记录表"""
    __tablename__ = "usage_records"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)

    # 关联
    user_id = Column(UUID(as_uuid=True), ForeignKey("sys_user.id"), nullable=False, index=True)
    api_key_id = Column(UUID(as_uuid=True), ForeignKey("user_api_keys.id"), nullable=True)

    # 请求信息
    model_id = Column(String(100), nullable=False, index=True)
    request_id = Column(String(100), nullable=True, unique=True)

    # Token统计
    input_tokens = Column(Integer, default=0)
    output_tokens = Column(Integer, default=0)
    total_tokens = Column(Integer, default=0)

    # 费用 (美元)
    cost = Column(Float, default=0.0)

    # 性能指标
    latency_ms = Column(Integer, nullable=True)

    # 请求状态
    success = Column(Boolean, default=True)
    error_code = Column(String(50), nullable=True)
    error_message = Column(Text, nullable=True)

    # 时间戳
    created_at = Column(DateTime, default=datetime.utcnow, index=True)

    # 关联
    api_key = relationship("UserApiKey", back_populates="usage_records")

    __table_args__ = (
        Index('idx_usage_user_date', 'user_id', 'created_at'),
        Index('idx_usage_model_date', 'model_id', 'created_at'),
    )
```

### 2.10 API Key 服务层

```python
# backend/app/llm/service/api_key_service.py
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, update, and_, func
from datetime import datetime, timedelta
from typing import Optional
import hashlib

from backend.app.llm.model.api_key import UserApiKey, ApiKeyStatus, RateLimitConfig, UsageRecord
from backend.common.security.crypto import AESCrypto


class ApiKeyService:
    """API Key管理服务"""

    def __init__(self, db: AsyncSession):
        self.db = db
        self.crypto = AESCrypto()

    async def create_api_key(
        self,
        user_id: str,
        key_name: str = "Default Key",
        expires_days: Optional[int] = None,
        custom_limits: Optional[dict] = None,
    ) -> dict:
        """
        为用户创建API Key
        注意: 完整Key只在创建时返回一次
        """
        # 生成Key
        full_key, prefix, key_hash = UserApiKey.generate_api_key()

        # 加密存储
        encrypted_key = self.crypto.encrypt(full_key)

        # 计算过期时间
        expires_at = None
        if expires_days:
            expires_at = datetime.utcnow() + timedelta(days=expires_days)

        # 创建记录
        api_key = UserApiKey(
            user_id=user_id,
            key_name=key_name,
            key_prefix=prefix,
            key_hash=key_hash,
            key_encrypted=encrypted_key,
            expires_at=expires_at,
            custom_daily_tokens=custom_limits.get("daily_tokens") if custom_limits else None,
            custom_monthly_tokens=custom_limits.get("monthly_tokens") if custom_limits else None,
            custom_rpm_limit=custom_limits.get("rpm_limit") if custom_limits else None,
        )

        self.db.add(api_key)
        await self.db.commit()
        await self.db.refresh(api_key)

        return {
            "id": str(api_key.id),
            "key": full_key,  # 仅此一次返回完整Key
            "key_prefix": prefix,
            "key_name": key_name,
            "expires_at": expires_at.isoformat() if expires_at else None,
            "created_at": api_key.created_at.isoformat(),
        }

    async def validate_api_key(self, api_key: str) -> Optional[UserApiKey]:
        """验证API Key并返回记录"""
        key_hash = hashlib.sha256(api_key.encode()).hexdigest()

        result = await self.db.execute(
            select(UserApiKey).where(
                and_(
                    UserApiKey.key_hash == key_hash,
                    UserApiKey.status == ApiKeyStatus.ACTIVE,
                )
            )
        )
        key_record = result.scalar_one_or_none()

        if not key_record:
            return None

        # 检查过期
        if key_record.expires_at and key_record.expires_at < datetime.utcnow():
            key_record.status = ApiKeyStatus.EXPIRED
            await self.db.commit()
            return None

        # 更新最后使用时间
        key_record.last_used_at = datetime.utcnow()
        await self.db.commit()

        return key_record

    async def list_user_api_keys(self, user_id: str) -> list[dict]:
        """列出用户的所有API Key"""
        result = await self.db.execute(
            select(UserApiKey).where(UserApiKey.user_id == user_id)
            .order_by(UserApiKey.created_at.desc())
        )
        keys = result.scalars().all()

        return [
            {
                "id": str(k.id),
                "key_name": k.key_name,
                "key_prefix": k.key_prefix,
                "status": k.status.value,
                "created_at": k.created_at.isoformat(),
                "expires_at": k.expires_at.isoformat() if k.expires_at else None,
                "last_used_at": k.last_used_at.isoformat() if k.last_used_at else None,
            }
            for k in keys
        ]

    async def revoke_api_key(self, user_id: str, key_id: str) -> bool:
        """撤销API Key"""
        result = await self.db.execute(
            update(UserApiKey)
            .where(
                and_(
                    UserApiKey.id == key_id,
                    UserApiKey.user_id == user_id,
                )
            )
            .values(status=ApiKeyStatus.REVOKED)
        )
        await self.db.commit()
        return result.rowcount > 0

    async def regenerate_api_key(self, user_id: str, key_id: str) -> dict:
        """重新生成API Key (保留配置)"""
        # 获取原有Key配置
        result = await self.db.execute(
            select(UserApiKey).where(
                and_(
                    UserApiKey.id == key_id,
                    UserApiKey.user_id == user_id,
                )
            )
        )
        old_key = result.scalar_one_or_none()

        if not old_key:
            raise ValueError("API Key not found")

        # 撤销旧Key
        old_key.status = ApiKeyStatus.REVOKED

        # 创建新Key (继承配置)
        return await self.create_api_key(
            user_id=user_id,
            key_name=old_key.key_name,
            custom_limits={
                "daily_tokens": old_key.custom_daily_tokens,
                "monthly_tokens": old_key.custom_monthly_tokens,
                "rpm_limit": old_key.custom_rpm_limit,
            }
        )

    async def auto_create_for_new_user(self, user_id: str) -> dict:
        """新用户注册时自动创建API Key"""
        return await self.create_api_key(
            user_id=user_id,
            key_name="Default Key",
            expires_days=None,  # 永不过期
        )
```

### 2.11 增强型速率限制服务

```python
# backend/app/llm/service/rate_limiter_service.py
from datetime import datetime, timedelta
from typing import Optional, Literal
from dataclasses import dataclass
import redis.asyncio as redis
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, and_

from backend.app.llm.model.api_key import UserApiKey, RateLimitConfig, UsageRecord


@dataclass
class RateLimitResult:
    """速率限制检查结果"""
    allowed: bool
    limit_type: Optional[str] = None  # rpm, tpm, daily, weekly, monthly
    current_usage: int = 0
    limit_value: int = 0
    reset_at: Optional[datetime] = None
    retry_after_seconds: int = 0


class EnhancedRateLimiter:
    """
    增强型速率限制器
    - 支持日/周/月限制
    - 支持RPM/TPM限制
    - Redis缓存加速
    """

    def __init__(self, redis_client: redis.Redis, db: AsyncSession):
        self.redis = redis_client
        self.db = db

    async def check_all_limits(
        self,
        user_id: str,
        api_key: UserApiKey,
        estimated_tokens: int = 1000,
    ) -> RateLimitResult:
        """
        检查所有限制
        返回第一个触发的限制或允许
        """
        # 获取用户的限制配置
        config = await self._get_rate_limit_config(user_id)

        # 1. 检查RPM (每分钟请求数)
        rpm_result = await self._check_rpm(user_id, api_key, config)
        if not rpm_result.allowed:
            return rpm_result

        # 2. 检查TPM (每分钟Token数)
        tpm_result = await self._check_tpm(user_id, api_key, config, estimated_tokens)
        if not tpm_result.allowed:
            return tpm_result

        # 3. 检查日限额
        daily_result = await self._check_period_limit(
            user_id, api_key, config, "day"
        )
        if not daily_result.allowed:
            return daily_result

        # 4. 检查周限额
        weekly_result = await self._check_period_limit(
            user_id, api_key, config, "week"
        )
        if not weekly_result.allowed:
            return weekly_result

        # 5. 检查月限额
        monthly_result = await self._check_period_limit(
            user_id, api_key, config, "month"
        )
        if not monthly_result.allowed:
            return monthly_result

        return RateLimitResult(allowed=True)

    async def _check_rpm(
        self,
        user_id: str,
        api_key: UserApiKey,
        config: RateLimitConfig,
    ) -> RateLimitResult:
        """检查每分钟请求数"""
        rpm_limit = api_key.custom_rpm_limit or config.rpm_limit

        now = datetime.utcnow()
        minute_key = f"ratelimit:rpm:{user_id}:{now.strftime('%Y%m%d%H%M')}"

        current = int(await self.redis.get(minute_key) or 0)

        if current >= rpm_limit:
            return RateLimitResult(
                allowed=False,
                limit_type="rpm",
                current_usage=current,
                limit_value=rpm_limit,
                reset_at=now.replace(second=0, microsecond=0) + timedelta(minutes=1),
                retry_after_seconds=60 - now.second,
            )

        return RateLimitResult(allowed=True, current_usage=current, limit_value=rpm_limit)

    async def _check_tpm(
        self,
        user_id: str,
        api_key: UserApiKey,
        config: RateLimitConfig,
        estimated_tokens: int,
    ) -> RateLimitResult:
        """检查每分钟Token数"""
        tpm_limit = config.tpm_limit

        now = datetime.utcnow()
        minute_key = f"ratelimit:tpm:{user_id}:{now.strftime('%Y%m%d%H%M')}"

        current = int(await self.redis.get(minute_key) or 0)

        if current + estimated_tokens > tpm_limit:
            return RateLimitResult(
                allowed=False,
                limit_type="tpm",
                current_usage=current,
                limit_value=tpm_limit,
                reset_at=now.replace(second=0, microsecond=0) + timedelta(minutes=1),
                retry_after_seconds=60 - now.second,
            )

        return RateLimitResult(allowed=True, current_usage=current, limit_value=tpm_limit)

    async def _check_period_limit(
        self,
        user_id: str,
        api_key: UserApiKey,
        config: RateLimitConfig,
        period: Literal["day", "week", "month"],
    ) -> RateLimitResult:
        """检查周期性限额 (日/周/月)"""
        now = datetime.utcnow()

        # 确定限额值
        if period == "day":
            limit = api_key.custom_daily_tokens or config.daily_token_limit
            start = now.replace(hour=0, minute=0, second=0, microsecond=0)
            reset_at = start + timedelta(days=1)
        elif period == "week":
            limit = config.weekly_token_limit
            start = now - timedelta(days=now.weekday())
            start = start.replace(hour=0, minute=0, second=0, microsecond=0)
            reset_at = start + timedelta(days=7)
        else:  # month
            limit = api_key.custom_monthly_tokens or config.monthly_token_limit
            start = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
            if now.month == 12:
                reset_at = start.replace(year=now.year + 1, month=1)
            else:
                reset_at = start.replace(month=now.month + 1)

        if not limit:
            return RateLimitResult(allowed=True)

        # 查询当前使用量 (优先从Redis缓存)
        cache_key = f"ratelimit:tokens:{user_id}:{period}:{start.strftime('%Y%m%d')}"
        current = await self.redis.get(cache_key)

        if current is None:
            # 从数据库查询
            result = await self.db.execute(
                select(func.sum(UsageRecord.total_tokens))
                .where(
                    and_(
                        UsageRecord.user_id == user_id,
                        UsageRecord.created_at >= start,
                        UsageRecord.success == True,
                    )
                )
            )
            current = result.scalar() or 0
            # 缓存到Redis (TTL到周期结束)
            ttl = int((reset_at - now).total_seconds())
            await self.redis.setex(cache_key, ttl, current)
        else:
            current = int(current)

        if current >= limit:
            return RateLimitResult(
                allowed=False,
                limit_type=f"{period}ly_tokens",
                current_usage=current,
                limit_value=limit,
                reset_at=reset_at,
                retry_after_seconds=int((reset_at - now).total_seconds()),
            )

        return RateLimitResult(
            allowed=True,
            current_usage=current,
            limit_value=limit,
            reset_at=reset_at,
        )

    async def record_usage(
        self,
        user_id: str,
        tokens: int,
    ):
        """记录使用量 (更新Redis缓存)"""
        now = datetime.utcnow()

        # 更新分钟级计数
        minute_key = f"ratelimit:rpm:{user_id}:{now.strftime('%Y%m%d%H%M')}"
        tpm_key = f"ratelimit:tpm:{user_id}:{now.strftime('%Y%m%d%H%M')}"

        pipe = self.redis.pipeline()
        pipe.incr(minute_key)
        pipe.expire(minute_key, 120)
        pipe.incrby(tpm_key, tokens)
        pipe.expire(tpm_key, 120)

        # 更新周期计数
        for period, date_fmt in [("day", "%Y%m%d"), ("week", "%Y%W"), ("month", "%Y%m")]:
            cache_key = f"ratelimit:tokens:{user_id}:{period}:{now.strftime(date_fmt)}"
            pipe.incrby(cache_key, tokens)

        await pipe.execute()

    async def _get_rate_limit_config(self, user_id: str) -> RateLimitConfig:
        """获取用户的限制配置"""
        # TODO: 根据用户订阅级别获取配置
        result = await self.db.execute(
            select(RateLimitConfig).where(RateLimitConfig.is_default == True)
        )
        return result.scalar_one_or_none() or RateLimitConfig(
            config_name="default",
            display_name="Default",
            daily_token_limit=100000,
            monthly_token_limit=1000000,
            rpm_limit=60,
            tpm_limit=40000,
        )

    async def get_usage_summary(
        self,
        user_id: str,
        period: Literal["day", "week", "month"] = "month",
    ) -> dict:
        """获取使用量汇总"""
        now = datetime.utcnow()
        config = await self._get_rate_limit_config(user_id)

        if period == "day":
            start = now.replace(hour=0, minute=0, second=0, microsecond=0)
            limit = config.daily_token_limit
        elif period == "week":
            start = now - timedelta(days=now.weekday())
            start = start.replace(hour=0, minute=0, second=0, microsecond=0)
            limit = config.weekly_token_limit
        else:
            start = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
            limit = config.monthly_token_limit

        # 查询汇总
        result = await self.db.execute(
            select(
                func.sum(UsageRecord.total_tokens).label("total_tokens"),
                func.sum(UsageRecord.cost).label("total_cost"),
                func.count(UsageRecord.id).label("request_count"),
            )
            .where(
                and_(
                    UsageRecord.user_id == user_id,
                    UsageRecord.created_at >= start,
                )
            )
        )
        row = result.one()

        return {
            "period": period,
            "start_date": start.isoformat(),
            "end_date": now.isoformat(),
            "total_tokens": row.total_tokens or 0,
            "total_cost": float(row.total_cost or 0),
            "request_count": row.request_count or 0,
            "limit": limit,
            "remaining": max(0, (limit or float('inf')) - (row.total_tokens or 0)),
            "usage_percentage": round((row.total_tokens or 0) / limit * 100, 2) if limit else 0,
        }
```

### 2.12 双格式API代理 (OpenAI + Anthropic 兼容)

```python
# backend/app/llm/api/v1/proxy.py
from fastapi import APIRouter, Request, HTTPException, Depends, Header
from fastapi.responses import StreamingResponse
from typing import Optional, Literal
from pydantic import BaseModel, Field
from datetime import datetime
import json

from backend.database.db import CurrentSession
from backend.app.llm.service.api_key_service import ApiKeyService
from backend.app.llm.service.rate_limiter_service import EnhancedRateLimiter
from backend.app.llm.service.llm_gateway import LLMGateway

router = APIRouter()


# ============ OpenAI 兼容格式 ============

class OpenAIMessage(BaseModel):
    role: Literal["system", "user", "assistant"]
    content: str


class OpenAIChatRequest(BaseModel):
    """OpenAI Chat Completions 格式请求"""
    model: str
    messages: list[OpenAIMessage]
    temperature: float = 0.7
    max_tokens: Optional[int] = 4096
    stream: bool = False
    top_p: Optional[float] = None
    frequency_penalty: Optional[float] = None
    presence_penalty: Optional[float] = None
    user: Optional[str] = None


class OpenAIUsage(BaseModel):
    prompt_tokens: int
    completion_tokens: int
    total_tokens: int


class OpenAIChoice(BaseModel):
    index: int
    message: OpenAIMessage
    finish_reason: str


class OpenAIChatResponse(BaseModel):
    """OpenAI Chat Completions 格式响应"""
    id: str
    object: str = "chat.completion"
    created: int
    model: str
    choices: list[OpenAIChoice]
    usage: OpenAIUsage


@router.post("/v1/chat/completions", response_model=OpenAIChatResponse)
async def openai_chat_completions(
    request: OpenAIChatRequest,
    authorization: str = Header(...),
    db: CurrentSession = None,
):
    """
    OpenAI 兼容的 Chat Completions API
    使用方式: 将 base_url 设置为本服务地址即可
    """
    # 验证API Key
    api_key = authorization.replace("Bearer ", "")
    key_service = ApiKeyService(db)
    key_record = await key_service.validate_api_key(api_key)

    if not key_record:
        raise HTTPException(status_code=401, detail="Invalid API key")

    # 检查速率限制
    rate_limiter = EnhancedRateLimiter(redis_client, db)
    limit_result = await rate_limiter.check_all_limits(
        user_id=str(key_record.user_id),
        api_key=key_record,
        estimated_tokens=request.max_tokens or 1000,
    )

    if not limit_result.allowed:
        raise HTTPException(
            status_code=429,
            detail={
                "error": "rate_limit_exceeded",
                "limit_type": limit_result.limit_type,
                "current": limit_result.current_usage,
                "limit": limit_result.limit_value,
                "retry_after": limit_result.retry_after_seconds,
            }
        )

    # 调用LLM网关
    gateway = LLMGateway(db)

    messages = [{"role": m.role, "content": m.content} for m in request.messages]

    if request.stream:
        return StreamingResponse(
            _stream_openai_response(gateway, request, key_record),
            media_type="text/event-stream",
        )

    response = await gateway.chat(
        messages=messages,
        model_id=request.model,
        user_id=str(key_record.user_id),
        max_tokens=request.max_tokens,
        temperature=request.temperature,
    )

    # 记录使用量
    await rate_limiter.record_usage(
        user_id=str(key_record.user_id),
        tokens=response.usage["input_tokens"] + response.usage["output_tokens"],
    )

    return OpenAIChatResponse(
        id=f"chatcmpl-{datetime.utcnow().timestamp()}",
        created=int(datetime.utcnow().timestamp()),
        model=response.model,
        choices=[
            OpenAIChoice(
                index=0,
                message=OpenAIMessage(role="assistant", content=response.content),
                finish_reason="stop",
            )
        ],
        usage=OpenAIUsage(
            prompt_tokens=response.usage["input_tokens"],
            completion_tokens=response.usage["output_tokens"],
            total_tokens=response.usage["input_tokens"] + response.usage["output_tokens"],
        ),
    )


async def _stream_openai_response(gateway, request, key_record):
    """流式响应生成器 (OpenAI格式)"""
    messages = [{"role": m.role, "content": m.content} for m in request.messages]

    async for chunk in gateway.chat_stream(
        messages=messages,
        model_id=request.model,
        user_id=str(key_record.user_id),
        max_tokens=request.max_tokens,
        temperature=request.temperature,
    ):
        data = {
            "id": f"chatcmpl-{datetime.utcnow().timestamp()}",
            "object": "chat.completion.chunk",
            "created": int(datetime.utcnow().timestamp()),
            "model": request.model,
            "choices": [{
                "index": 0,
                "delta": {"content": chunk},
                "finish_reason": None,
            }]
        }
        yield f"data: {json.dumps(data)}\n\n"

    yield "data: [DONE]\n\n"


# ============ Anthropic 兼容格式 ============

class AnthropicMessage(BaseModel):
    role: Literal["user", "assistant"]
    content: str


class AnthropicRequest(BaseModel):
    """Anthropic Messages API 格式请求"""
    model: str
    messages: list[AnthropicMessage]
    max_tokens: int = 4096
    system: Optional[str] = None
    temperature: Optional[float] = 0.7
    stream: bool = False


class AnthropicContentBlock(BaseModel):
    type: str = "text"
    text: str


class AnthropicUsage(BaseModel):
    input_tokens: int
    output_tokens: int


class AnthropicResponse(BaseModel):
    """Anthropic Messages API 格式响应"""
    id: str
    type: str = "message"
    role: str = "assistant"
    model: str
    content: list[AnthropicContentBlock]
    stop_reason: str
    usage: AnthropicUsage


@router.post("/v1/messages", response_model=AnthropicResponse)
async def anthropic_messages(
    request: AnthropicRequest,
    x_api_key: str = Header(..., alias="x-api-key"),
    db: CurrentSession = None,
):
    """
    Anthropic 兼容的 Messages API
    使用方式: 将 base_url 设置为本服务地址即可
    """
    # 验证API Key
    key_service = ApiKeyService(db)
    key_record = await key_service.validate_api_key(x_api_key)

    if not key_record:
        raise HTTPException(status_code=401, detail="Invalid API key")

    # 检查速率限制
    rate_limiter = EnhancedRateLimiter(redis_client, db)
    limit_result = await rate_limiter.check_all_limits(
        user_id=str(key_record.user_id),
        api_key=key_record,
        estimated_tokens=request.max_tokens,
    )

    if not limit_result.allowed:
        raise HTTPException(
            status_code=429,
            detail={
                "type": "rate_limit_error",
                "message": f"Rate limit exceeded: {limit_result.limit_type}",
            }
        )

    # 调用LLM网关
    gateway = LLMGateway(db)

    messages = [{"role": m.role, "content": m.content} for m in request.messages]

    if request.stream:
        return StreamingResponse(
            _stream_anthropic_response(gateway, request, key_record),
            media_type="text/event-stream",
        )

    response = await gateway.chat(
        messages=messages,
        model_id=request.model,
        user_id=str(key_record.user_id),
        system=request.system,
        max_tokens=request.max_tokens,
        temperature=request.temperature,
    )

    # 记录使用量
    await rate_limiter.record_usage(
        user_id=str(key_record.user_id),
        tokens=response.usage["input_tokens"] + response.usage["output_tokens"],
    )

    return AnthropicResponse(
        id=f"msg_{datetime.utcnow().timestamp()}",
        model=response.model,
        content=[AnthropicContentBlock(text=response.content)],
        stop_reason="end_turn",
        usage=AnthropicUsage(
            input_tokens=response.usage["input_tokens"],
            output_tokens=response.usage["output_tokens"],
        ),
    )


async def _stream_anthropic_response(gateway, request, key_record):
    """流式响应生成器 (Anthropic格式)"""
    messages = [{"role": m.role, "content": m.content} for m in request.messages]

    # 发送消息开始事件
    yield f"event: message_start\ndata: {json.dumps({'type': 'message_start'})}\n\n"
    yield f"event: content_block_start\ndata: {json.dumps({'type': 'content_block_start', 'index': 0})}\n\n"

    async for chunk in gateway.chat_stream(
        messages=messages,
        model_id=request.model,
        user_id=str(key_record.user_id),
        system=request.system,
        max_tokens=request.max_tokens,
        temperature=request.temperature,
    ):
        data = {
            "type": "content_block_delta",
            "index": 0,
            "delta": {"type": "text_delta", "text": chunk}
        }
        yield f"event: content_block_delta\ndata: {json.dumps(data)}\n\n"

    yield f"event: content_block_stop\ndata: {json.dumps({'type': 'content_block_stop', 'index': 0})}\n\n"
    yield f"event: message_stop\ndata: {json.dumps({'type': 'message_stop'})}\n\n"
```

### 2.13 用量统计与管理API

```python
# backend/app/llm/api/v1/usage.py
from fastapi import APIRouter, Depends, HTTPException, Query
from datetime import datetime, timedelta
from typing import Literal, Optional
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, and_

from backend.database.db import CurrentSession
from backend.common.security.jwt import DependsJwtAuth, get_current_user_id
from backend.app.llm.model.api_key import UsageRecord, UserApiKey
from backend.app.llm.service.api_key_service import ApiKeyService
from backend.app.llm.service.rate_limiter_service import EnhancedRateLimiter

router = APIRouter()


# ============ API Key 管理接口 ============

@router.post("/api-keys", dependencies=[DependsJwtAuth])
async def create_api_key(
    key_name: str = "Default Key",
    expires_days: Optional[int] = None,
    user_id: str = Depends(get_current_user_id),
    db: CurrentSession = None,
):
    """
    创建新的API Key
    注意: 完整Key只在创建时返回一次，请妥善保存
    """
    service = ApiKeyService(db)
    return await service.create_api_key(
        user_id=user_id,
        key_name=key_name,
        expires_days=expires_days,
    )


@router.get("/api-keys", dependencies=[DependsJwtAuth])
async def list_api_keys(
    user_id: str = Depends(get_current_user_id),
    db: CurrentSession = None,
):
    """列出当前用户的所有API Key"""
    service = ApiKeyService(db)
    return await service.list_user_api_keys(user_id)


@router.delete("/api-keys/{key_id}", dependencies=[DependsJwtAuth])
async def revoke_api_key(
    key_id: str,
    user_id: str = Depends(get_current_user_id),
    db: CurrentSession = None,
):
    """撤销API Key"""
    service = ApiKeyService(db)
    success = await service.revoke_api_key(user_id, key_id)
    if not success:
        raise HTTPException(status_code=404, detail="API Key not found")
    return {"success": True, "message": "API Key revoked"}


@router.post("/api-keys/{key_id}/regenerate", dependencies=[DependsJwtAuth])
async def regenerate_api_key(
    key_id: str,
    user_id: str = Depends(get_current_user_id),
    db: CurrentSession = None,
):
    """重新生成API Key (撤销旧Key，生成新Key)"""
    service = ApiKeyService(db)
    return await service.regenerate_api_key(user_id, key_id)


# ============ 用量统计接口 ============

@router.get("/usage/summary", dependencies=[DependsJwtAuth])
async def get_usage_summary(
    period: Literal["day", "week", "month"] = "month",
    user_id: str = Depends(get_current_user_id),
    db: CurrentSession = None,
):
    """
    获取用量汇总
    - period: day(今日), week(本周), month(本月)
    """
    rate_limiter = EnhancedRateLimiter(redis_client, db)
    return await rate_limiter.get_usage_summary(user_id, period)


@router.get("/usage/by-model", dependencies=[DependsJwtAuth])
async def get_usage_by_model(
    start_date: Optional[datetime] = None,
    end_date: Optional[datetime] = None,
    user_id: str = Depends(get_current_user_id),
    db: CurrentSession = None,
):
    """
    按模型统计用量
    返回各模型的调用次数、token消耗、费用
    """
    if not start_date:
        start_date = datetime.utcnow().replace(day=1, hour=0, minute=0, second=0, microsecond=0)
    if not end_date:
        end_date = datetime.utcnow()

    result = await db.execute(
        select(
            UsageRecord.model_id,
            func.count(UsageRecord.id).label("request_count"),
            func.sum(UsageRecord.input_tokens).label("input_tokens"),
            func.sum(UsageRecord.output_tokens).label("output_tokens"),
            func.sum(UsageRecord.total_tokens).label("total_tokens"),
            func.sum(UsageRecord.cost).label("total_cost"),
            func.avg(UsageRecord.latency_ms).label("avg_latency_ms"),
        )
        .where(
            and_(
                UsageRecord.user_id == user_id,
                UsageRecord.created_at >= start_date,
                UsageRecord.created_at <= end_date,
            )
        )
        .group_by(UsageRecord.model_id)
        .order_by(func.sum(UsageRecord.total_tokens).desc())
    )
    rows = result.all()

    return {
        "period": {
            "start": start_date.isoformat(),
            "end": end_date.isoformat(),
        },
        "by_model": [
            {
                "model_id": row.model_id,
                "request_count": row.request_count,
                "input_tokens": row.input_tokens or 0,
                "output_tokens": row.output_tokens or 0,
                "total_tokens": row.total_tokens or 0,
                "total_cost": float(row.total_cost or 0),
                "avg_latency_ms": int(row.avg_latency_ms or 0),
            }
            for row in rows
        ]
    }


@router.get("/usage/history", dependencies=[DependsJwtAuth])
async def get_usage_history(
    start_date: Optional[datetime] = None,
    end_date: Optional[datetime] = None,
    model_id: Optional[str] = None,
    limit: int = Query(default=100, le=1000),
    offset: int = 0,
    user_id: str = Depends(get_current_user_id),
    db: CurrentSession = None,
):
    """
    获取详细使用记录
    支持按模型和时间范围筛选
    """
    if not start_date:
        start_date = datetime.utcnow() - timedelta(days=30)
    if not end_date:
        end_date = datetime.utcnow()

    query = select(UsageRecord).where(
        and_(
            UsageRecord.user_id == user_id,
            UsageRecord.created_at >= start_date,
            UsageRecord.created_at <= end_date,
        )
    )

    if model_id:
        query = query.where(UsageRecord.model_id == model_id)

    query = query.order_by(UsageRecord.created_at.desc()).offset(offset).limit(limit)

    result = await db.execute(query)
    records = result.scalars().all()

    return {
        "total": len(records),
        "offset": offset,
        "limit": limit,
        "records": [
            {
                "id": str(r.id),
                "model_id": r.model_id,
                "input_tokens": r.input_tokens,
                "output_tokens": r.output_tokens,
                "total_tokens": r.total_tokens,
                "cost": float(r.cost),
                "latency_ms": r.latency_ms,
                "success": r.success,
                "error_code": r.error_code,
                "created_at": r.created_at.isoformat(),
            }
            for r in records
        ]
    }


@router.get("/usage/daily-trend", dependencies=[DependsJwtAuth])
async def get_daily_trend(
    days: int = Query(default=30, le=90),
    user_id: str = Depends(get_current_user_id),
    db: CurrentSession = None,
):
    """
    获取每日用量趋势
    返回最近N天的每日统计数据
    """
    start_date = datetime.utcnow() - timedelta(days=days)

    result = await db.execute(
        select(
            func.date(UsageRecord.created_at).label("date"),
            func.count(UsageRecord.id).label("request_count"),
            func.sum(UsageRecord.total_tokens).label("total_tokens"),
            func.sum(UsageRecord.cost).label("total_cost"),
        )
        .where(
            and_(
                UsageRecord.user_id == user_id,
                UsageRecord.created_at >= start_date,
            )
        )
        .group_by(func.date(UsageRecord.created_at))
        .order_by(func.date(UsageRecord.created_at))
    )
    rows = result.all()

    return {
        "days": days,
        "trend": [
            {
                "date": row.date.isoformat() if hasattr(row.date, 'isoformat') else str(row.date),
                "request_count": row.request_count,
                "total_tokens": row.total_tokens or 0,
                "total_cost": float(row.total_cost or 0),
            }
            for row in rows
        ]
    }


# ============ 配额查询接口 ============

@router.get("/quota", dependencies=[DependsJwtAuth])
async def get_quota_status(
    user_id: str = Depends(get_current_user_id),
    db: CurrentSession = None,
):
    """
    获取配额状态
    返回日/周/月的使用量和剩余配额
    """
    rate_limiter = EnhancedRateLimiter(redis_client, db)

    daily = await rate_limiter.get_usage_summary(user_id, "day")
    weekly = await rate_limiter.get_usage_summary(user_id, "week")
    monthly = await rate_limiter.get_usage_summary(user_id, "month")

    return {
        "daily": {
            "used": daily["total_tokens"],
            "limit": daily["limit"],
            "remaining": daily["remaining"],
            "percentage": daily["usage_percentage"],
        },
        "weekly": {
            "used": weekly["total_tokens"],
            "limit": weekly["limit"],
            "remaining": weekly["remaining"],
            "percentage": weekly["usage_percentage"],
        },
        "monthly": {
            "used": monthly["total_tokens"],
            "limit": monthly["limit"],
            "remaining": monthly["remaining"],
            "percentage": monthly["usage_percentage"],
        },
    }
```

### 2.14 模型配置管理API (管理员)

```python
# backend/app/llm/api/v1/admin.py
from fastapi import APIRouter, Depends, HTTPException
from typing import Optional
from pydantic import BaseModel

from backend.database.db import CurrentSession
from backend.common.security.jwt import DependsJwtAuth
from backend.common.security.rbac import admin_required
from backend.app.llm.model.provider import ModelProviderDB, ModelConfigDB, ModelGroupDB

router = APIRouter()


class CreateProviderRequest(BaseModel):
    provider_id: str
    display_name: str
    api_base_url: Optional[str] = None
    api_key: str  # 将被加密存储
    is_domestic: bool = False
    global_rpm_limit: int = 1000
    global_tpm_limit: int = 1000000


class CreateModelRequest(BaseModel):
    provider_id: str
    model_id: str
    display_name: str
    model_type: str
    max_tokens: int = 4096
    max_context_length: int = 128000
    supports_streaming: bool = True
    supports_tools: bool = True
    supports_vision: bool = False
    input_cost_per_1k: float = 0.0
    output_cost_per_1k: float = 0.0
    rpm_limit: int = 60
    tpm_limit: int = 100000
    priority: int = 100


# ============ 供应商管理 ============

@router.post("/providers", dependencies=[Depends(admin_required)])
async def create_provider(
    request: CreateProviderRequest,
    db: CurrentSession = None,
):
    """创建模型供应商"""
    from backend.common.security.crypto import AESCrypto
    crypto = AESCrypto()

    provider = ModelProviderDB(
        provider_id=request.provider_id,
        display_name=request.display_name,
        api_base_url=request.api_base_url,
        api_key_encrypted=crypto.encrypt(request.api_key),
        is_domestic=request.is_domestic,
        global_rpm_limit=request.global_rpm_limit,
        global_tpm_limit=request.global_tpm_limit,
    )

    db.add(provider)
    await db.commit()
    await db.refresh(provider)

    return {"id": str(provider.id), "provider_id": provider.provider_id}


@router.get("/providers", dependencies=[Depends(admin_required)])
async def list_providers(db: CurrentSession = None):
    """列出所有供应商"""
    from sqlalchemy import select

    result = await db.execute(select(ModelProviderDB))
    providers = result.scalars().all()

    return [
        {
            "id": str(p.id),
            "provider_id": p.provider_id,
            "display_name": p.display_name,
            "is_domestic": p.is_domestic,
            "enabled": p.enabled,
            "model_count": len(p.models),
        }
        for p in providers
    ]


@router.put("/providers/{provider_id}/toggle", dependencies=[Depends(admin_required)])
async def toggle_provider(
    provider_id: str,
    enabled: bool,
    db: CurrentSession = None,
):
    """启用/禁用供应商"""
    from sqlalchemy import select, update

    await db.execute(
        update(ModelProviderDB)
        .where(ModelProviderDB.provider_id == provider_id)
        .values(enabled=enabled)
    )
    await db.commit()
    return {"success": True}


# ============ 模型配置管理 ============

@router.post("/models", dependencies=[Depends(admin_required)])
async def create_model(
    request: CreateModelRequest,
    db: CurrentSession = None,
):
    """创建模型配置"""
    from sqlalchemy import select
    from backend.app.llm.model.provider import ModelTypeEnum

    # 获取供应商
    result = await db.execute(
        select(ModelProviderDB).where(ModelProviderDB.provider_id == request.provider_id)
    )
    provider = result.scalar_one_or_none()
    if not provider:
        raise HTTPException(status_code=404, detail="Provider not found")

    model = ModelConfigDB(
        provider_id=provider.id,
        model_id=request.model_id,
        display_name=request.display_name,
        model_type=ModelTypeEnum(request.model_type),
        max_tokens=request.max_tokens,
        max_context_length=request.max_context_length,
        supports_streaming=request.supports_streaming,
        supports_tools=request.supports_tools,
        supports_vision=request.supports_vision,
        input_cost_per_1k=request.input_cost_per_1k,
        output_cost_per_1k=request.output_cost_per_1k,
        rpm_limit=request.rpm_limit,
        tpm_limit=request.tpm_limit,
        priority=request.priority,
    )

    db.add(model)
    await db.commit()
    await db.refresh(model)

    return {"id": str(model.id), "model_id": model.model_id}


@router.get("/models", dependencies=[Depends(admin_required)])
async def list_models(
    provider_id: Optional[str] = None,
    model_type: Optional[str] = None,
    db: CurrentSession = None,
):
    """列出所有模型配置"""
    from sqlalchemy import select

    query = select(ModelConfigDB)

    if provider_id:
        result = await db.execute(
            select(ModelProviderDB.id).where(ModelProviderDB.provider_id == provider_id)
        )
        pid = result.scalar_one_or_none()
        if pid:
            query = query.where(ModelConfigDB.provider_id == pid)

    if model_type:
        query = query.where(ModelConfigDB.model_type == model_type)

    result = await db.execute(query)
    models = result.scalars().all()

    return [
        {
            "id": str(m.id),
            "model_id": m.model_id,
            "display_name": m.display_name,
            "model_type": m.model_type.value,
            "provider": m.provider.provider_id,
            "enabled": m.enabled,
            "priority": m.priority,
            "input_cost": m.input_cost_per_1k,
            "output_cost": m.output_cost_per_1k,
        }
        for m in models
    ]


@router.put("/models/{model_id}/toggle", dependencies=[Depends(admin_required)])
async def toggle_model(
    model_id: str,
    enabled: bool,
    db: CurrentSession = None,
):
    """启用/禁用模型"""
    from sqlalchemy import update

    await db.execute(
        update(ModelConfigDB)
        .where(ModelConfigDB.model_id == model_id)
        .values(enabled=enabled)
    )
    await db.commit()
    return {"success": True}


@router.put("/models/{model_id}/priority", dependencies=[Depends(admin_required)])
async def update_model_priority(
    model_id: str,
    priority: int,
    db: CurrentSession = None,
):
    """更新模型优先级"""
    from sqlalchemy import update

    await db.execute(
        update(ModelConfigDB)
        .where(ModelConfigDB.model_id == model_id)
        .values(priority=priority)
    )
    await db.commit()
    return {"success": True}


# ============ 系统统计 ============

@router.get("/stats/overview", dependencies=[Depends(admin_required)])
async def get_system_stats(db: CurrentSession = None):
    """获取系统级统计数据"""
    from sqlalchemy import select, func
    from datetime import datetime, timedelta
    from backend.app.llm.model.api_key import UsageRecord, UserApiKey

    now = datetime.utcnow()
    today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
    month_start = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)

    # 今日统计
    today_result = await db.execute(
        select(
            func.count(UsageRecord.id).label("requests"),
            func.sum(UsageRecord.total_tokens).label("tokens"),
            func.sum(UsageRecord.cost).label("cost"),
        )
        .where(UsageRecord.created_at >= today_start)
    )
    today = today_result.one()

    # 本月统计
    month_result = await db.execute(
        select(
            func.count(UsageRecord.id).label("requests"),
            func.sum(UsageRecord.total_tokens).label("tokens"),
            func.sum(UsageRecord.cost).label("cost"),
        )
        .where(UsageRecord.created_at >= month_start)
    )
    month = month_result.one()

    # 活跃用户数
    active_users = await db.execute(
        select(func.count(func.distinct(UsageRecord.user_id)))
        .where(UsageRecord.created_at >= today_start)
    )

    # API Key总数
    api_keys = await db.execute(
        select(func.count(UserApiKey.id))
    )

    return {
        "today": {
            "requests": today.requests or 0,
            "tokens": today.tokens or 0,
            "cost": float(today.cost or 0),
        },
        "month": {
            "requests": month.requests or 0,
            "tokens": month.tokens or 0,
            "cost": float(month.cost or 0),
        },
        "active_users_today": active_users.scalar() or 0,
        "total_api_keys": api_keys.scalar() or 0,
    }
```

---

## 3. API层实现

### 3.1 路由汇总

```python
# backend/app/router.py
from fastapi import APIRouter

from backend.app.admin.api.router import v1 as admin_v1
from backend.app.task.api.router import v1 as task_v1

route = APIRouter()

route.include_router(admin_v1)
route.include_router(task_v1)
```

```python
# backend/app/admin/api/router.py
from fastapi import APIRouter

from backend.app.admin.api.v1.auth import router as auth_router
from backend.app.admin.api.v1.sys import router as sys_router
from backend.app.admin.api.v1.log import router as log_router
from backend.app.admin.api.v1.monitor import router as monitor_router
from backend.core.conf import settings

v1 = APIRouter(prefix=settings.FASTAPI_API_V1_PATH)

v1.include_router(auth_router, prefix="/auth", tags=["认证"])
v1.include_router(sys_router, prefix="/sys", tags=["系统管理"])
v1.include_router(log_router, prefix="/logs", tags=["日志"])
v1.include_router(monitor_router, prefix="/monitors", tags=["监控"])
```

### 3.2 Agent接口 (待扩展模块)

```python
# backend/app/agent/api/v1/agent.py (新增业务模块)
from fastapi import APIRouter, Depends, HTTPException

from backend.database.db import CurrentSession
from backend.app.agent.service.agent_service import AgentService
from backend.app.agent.schema.agent import (
    CreateArticleRequest,
    CreateArticleResponse,
    AgentTaskStatus,
)
from backend.common.security.jwt import DependsJwtAuth

router = APIRouter()


@router.post("/create-article", response_model=CreateArticleResponse, dependencies=[DependsJwtAuth])
async def create_article(
    request: CreateArticleRequest,
    db: CurrentSession,
):
    """AI创作文章"""
    service = AgentService(db)

    # 检查用户配额
    if not await service.check_quota(request.user_id, "create_article"):
        raise HTTPException(status_code=429, detail="已达到今日创作配额")

    result = await service.create_article(
        user_id=request.user_id,
        topic=request.topic,
        style=request.style,
        platform=request.platform,
        keywords=request.keywords,
    )

    return CreateArticleResponse(
        task_id=result.task_id,
        status=result.status,
        content=result.content,
        images=result.images,
    )


@router.get("/task/{task_id}", response_model=AgentTaskStatus, dependencies=[DependsJwtAuth])
async def get_task_status(
    task_id: str,
    db: CurrentSession,
):
    """获取Agent任务状态"""
    service = AgentService(db)
    return await service.get_task_status(task_id)
```

### 3.3 发布接口 (待扩展模块)

```python
# backend/app/publish/api/v1/publish.py (新增业务模块)
from fastapi import APIRouter, HTTPException, BackgroundTasks

from backend.database.db import CurrentSession
from backend.app.publish.service.publish_service import PublishService
from backend.app.publish.schema.publish import (
    PublishRequest,
    PublishResponse,
    PublishStatus,
    SchedulePublishRequest,
)
from backend.common.security.jwt import DependsJwtAuth

router = APIRouter()


@router.post("/{platform}", response_model=PublishResponse, dependencies=[DependsJwtAuth])
async def publish_content(
    platform: str,
    request: PublishRequest,
    background_tasks: BackgroundTasks,
    db: CurrentSession,
):
    """发布内容到指定平台"""
    service = PublishService(db)

    # 验证账号权限
    if not await service.verify_account_access(
        request.user_id,
        request.account_id,
        platform
    ):
        raise HTTPException(status_code=403, detail="无权访问此账号")

    # 创建发布任务
    task = await service.create_publish_task(
        user_id=request.user_id,
        platform=platform,
        account_id=request.account_id,
        content=request.content,
    )

    # 后台执行发布
    background_tasks.add_task(
        service.execute_publish,
        task_id=task.id,
    )

    return PublishResponse(
        task_id=task.id,
        status=PublishStatus.PENDING,
        message="发布任务已创建",
    )


@router.post("/schedule", response_model=PublishResponse, dependencies=[DependsJwtAuth])
async def schedule_publish(
    request: SchedulePublishRequest,
    db: CurrentSession,
):
    """创建定时发布任务"""
    service = PublishService(db)

    task = await service.schedule_publish(
        user_id=request.user_id,
        platform=request.platform,
        account_id=request.account_id,
        content=request.content,
        scheduled_at=request.scheduled_at,
    )

    return PublishResponse(
        task_id=task.id,
        status=PublishStatus.SCHEDULED,
        message=f"已安排在 {request.scheduled_at} 发布",
    )


@router.get("/status/{task_id}", response_model=PublishStatus, dependencies=[DependsJwtAuth])
async def get_publish_status(
    task_id: str,
    db: CurrentSession,
):
    """获取发布任务状态"""
    service = PublishService(db)
    return await service.get_status(task_id)
```

### 3.4 凭证同步接口 (待扩展模块)

```python
# backend/app/credential/api/v1/credential.py (新增业务模块)
from fastapi import APIRouter, HTTPException

from backend.database.db import CurrentSession
from backend.app.credential.service.credential_service import CredentialService
from backend.app.credential.schema.credential import (
    CredentialUploadRequest,
    CredentialDownloadResponse,
    SyncedAccountInfo,
)
from backend.common.security.jwt import DependsJwtAuth

router = APIRouter()


@router.post("/upload", dependencies=[DependsJwtAuth])
async def upload_credential(
    request: CredentialUploadRequest,
    db: CurrentSession,
):
    """上传加密凭证到云端"""
    service = CredentialService(db)

    # 验证加密数据格式
    if not request.encrypted_data.get("ciphertext"):
        raise HTTPException(status_code=400, detail="无效的加密数据格式")

    await service.upload_credential(
        user_id=request.user_id,
        platform=request.platform,
        account_id=request.account_id,
        encrypted_data=request.encrypted_data,
        device_id=request.device_id,
    )

    return {"success": True, "message": "凭证同步成功"}


@router.get("/download/{platform}/{account_id}", response_model=CredentialDownloadResponse, dependencies=[DependsJwtAuth])
async def download_credential(
    platform: str,
    account_id: str,
    user_id: str,
    db: CurrentSession,
):
    """下载加密凭证"""
    service = CredentialService(db)

    encrypted_data = await service.download_credential(
        user_id=user_id,
        platform=platform,
        account_id=account_id,
    )

    if not encrypted_data:
        raise HTTPException(status_code=404, detail="凭证不存在")

    return CredentialDownloadResponse(
        platform=platform,
        account_id=account_id,
        encrypted_data=encrypted_data,
    )


@router.get("/accounts", response_model=list[SyncedAccountInfo], dependencies=[DependsJwtAuth])
async def list_synced_accounts(
    user_id: str,
    db: CurrentSession,
):
    """列出已同步的账号"""
    service = CredentialService(db)
    return await service.list_synced_accounts(user_id)
```

---

## 4. Service层实现

### 4.1 发布服务 (待扩展模块)

```python
# backend/app/publish/service/publish_service.py (新增业务模块)
from datetime import datetime
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

from backend.app.publish.model.publication import Publication, PublishStatus
from backend.app.publish.crud.crud_publication import PublicationCRUD
from backend.app.browser.pool_manager import BrowserPoolManager


class PublishService:
    def __init__(self, db: AsyncSession):
        self.db = db
        self.crud = PublicationCRUD(db)
        self.browser_pool = BrowserPoolManager()

    async def verify_account_access(
        self,
        user_id: str,
        account_id: str,
        platform: str
    ) -> bool:
        """验证用户是否有权限访问该账号"""
        account = await self.crud.get_account(user_id, account_id, platform)
        return account is not None

    async def create_publish_task(
        self,
        user_id: str,
        platform: str,
        account_id: str,
        content: dict,
    ) -> Publication:
        """创建发布任务"""
        task = Publication(
            user_id=user_id,
            platform=platform,
            account_id=account_id,
            content=content,
            status=PublishStatus.PENDING,
        )
        self.db.add(task)
        await self.db.commit()
        await self.db.refresh(task)
        return task

    async def execute_publish(self, task_id: str) -> None:
        """执行发布任务"""
        task = await self.crud.get(task_id)
        if not task:
            return

        try:
            # 更新状态为进行中
            task.status = PublishStatus.PUBLISHING
            await self.db.commit()

            # 从浏览器池获取实例
            browser_context = await self.browser_pool.acquire(
                platform=task.platform,
                account_id=task.account_id,
                user_id=task.user_id,
            )

            try:
                # 执行发布
                result = await browser_context.publish(task.content)

                # 更新结果
                task.status = PublishStatus.PUBLISHED
                task.platform_post_id = result.post_id
                task.platform_post_url = result.post_url
                task.published_at = datetime.utcnow()

            finally:
                await self.browser_pool.release(browser_context)

        except Exception as e:
            task.status = PublishStatus.FAILED
            task.error_message = str(e)

        await self.db.commit()

    async def schedule_publish(
        self,
        user_id: str,
        platform: str,
        account_id: str,
        content: dict,
        scheduled_at: datetime,
    ) -> Publication:
        """创建定时发布任务"""
        from backend.app.task.tasks.publish.tasks import execute_scheduled_publish

        task = await self.create_publish_task(
            user_id=user_id,
            platform=platform,
            account_id=account_id,
            content=content,
        )

        task.status = PublishStatus.SCHEDULED
        task.scheduled_at = scheduled_at
        await self.db.commit()

        # 添加Celery定时任务
        execute_scheduled_publish.apply_async(
            args=[task.id],
            eta=scheduled_at,
        )

        return task
```

### 4.2 凭证服务 (待扩展模块)

```python
# backend/app/credential/service/credential_service.py (新增业务模块)
from datetime import datetime
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

from backend.app.credential.model.credential import EncryptedCredentialRecord
from backend.app.credential.schema.credential import SyncedAccountInfo


class CredentialService:
    """凭证同步服务 - 云端只存储双重加密数据，无法解密"""

    def __init__(self, db: AsyncSession):
        self.db = db

    async def upload_credential(
        self,
        user_id: str,
        platform: str,
        account_id: str,
        encrypted_data: dict,
        device_id: str,
    ) -> None:
        """上传加密凭证"""
        stmt = select(EncryptedCredentialRecord).where(
            EncryptedCredentialRecord.user_id == user_id,
            EncryptedCredentialRecord.platform == platform,
            EncryptedCredentialRecord.account_id == account_id,
        )
        result = await self.db.execute(stmt)
        existing = result.scalar_one_or_none()

        if existing:
            existing.encrypted_data = encrypted_data
            existing.last_updated_device = device_id
            existing.updated_at = datetime.utcnow()
        else:
            record = EncryptedCredentialRecord(
                user_id=user_id,
                platform=platform,
                account_id=account_id,
                encrypted_data=encrypted_data,
                created_device=device_id,
                last_updated_device=device_id,
            )
            self.db.add(record)

        await self.db.commit()

    async def download_credential(
        self,
        user_id: str,
        platform: str,
        account_id: str,
    ) -> dict | None:
        """下载加密凭证（仍然是加密状态）"""
        stmt = select(EncryptedCredentialRecord).where(
            EncryptedCredentialRecord.user_id == user_id,
            EncryptedCredentialRecord.platform == platform,
            EncryptedCredentialRecord.account_id == account_id,
        )
        result = await self.db.execute(stmt)
        record = result.scalar_one_or_none()

        return record.encrypted_data if record else None

    async def list_synced_accounts(self, user_id: str) -> list[SyncedAccountInfo]:
        """列出用户已同步的账号"""

        stmt = select(EncryptedCredentialRecord).where(
            EncryptedCredentialRecord.user_id == user_id
        )
        result = await self.db.execute(stmt)
        records = result.scalars().all()

        return [
            SyncedAccountInfo(
                platform=r.platform,
                account_id=r.account_id,
                synced_at=r.updated_at.isoformat(),
                device=r.last_updated_device,
            )
            for r in records
        ]

    async def decrypt_for_browser(
        self,
        user_id: str,
        platform: str,
        account_id: str,
        sync_key: str,
        user_password: str,
    ) -> dict:
        """
        为浏览器操作解密凭证
        注意：此操作在内存中完成，凭证用完即销毁
        """
        from ..agent.crypto import CredentialCrypto

        encrypted_data = await self.download_credential(
            user_id, platform, account_id
        )

        if not encrypted_data:
            raise ValueError("凭证不存在")

        # 解密（在内存中）
        credentials = CredentialCrypto.decrypt_from_sync(
            encrypted_data,
            sync_key,
            user_password,
        )

        return credentials
```

---

## 5. 浏览器池管理 (待扩展模块)

### 5.1 池管理器

```python
# backend/app/browser/pool_manager.py (新增业务模块)
import asyncio
from typing import Optional
from dataclasses import dataclass
from datetime import datetime

import redis.asyncio as redis

from backend.core.conf import settings
from backend.database.redis import redis_client


@dataclass
class BrowserInstance:
    id: str
    worker_id: str
    platform: str
    account_id: str
    user_id: str
    created_at: datetime
    last_used: datetime
    status: str  # idle, busy, error


class BrowserPoolManager:
    """浏览器池管理器 - 管理多个Worker的浏览器实例"""

    def __init__(self):
        self.redis = redis_client
        self.pool_size = settings.BROWSER_POOL_SIZE
        self.workers = settings.BROWSER_WORKER_REPLICAS

    async def acquire(
        self,
        platform: str,
        account_id: str,
        user_id: str,
        timeout: int = 60,
    ) -> "BrowserContext":
        """获取浏览器实例"""
        # 尝试复用现有实例
        existing = await self._find_existing_instance(
            platform, account_id, user_id
        )
        if existing:
            return await self._activate_instance(existing)

        # 创建新实例
        worker_id = await self._select_worker()
        instance = await self._create_instance(
            worker_id, platform, account_id, user_id
        )

        return await self._activate_instance(instance)

    async def release(self, context: "BrowserContext") -> None:
        """释放浏览器实例"""
        await self._update_instance_status(context.instance_id, "idle")

    async def _find_existing_instance(
        self,
        platform: str,
        account_id: str,
        user_id: str,
    ) -> Optional[BrowserInstance]:
        """查找可复用的实例"""
        key = f"browser:instance:{platform}:{account_id}:{user_id}"
        data = await self.redis.hgetall(key)

        if data and data.get(b"status") == b"idle":
            return BrowserInstance(
                id=data[b"id"].decode(),
                worker_id=data[b"worker_id"].decode(),
                platform=platform,
                account_id=account_id,
                user_id=user_id,
                created_at=datetime.fromisoformat(data[b"created_at"].decode()),
                last_used=datetime.fromisoformat(data[b"last_used"].decode()),
                status="idle",
            )

        return None

    async def _select_worker(self) -> str:
        """选择负载最低的Worker"""
        worker_loads = {}

        for i in range(self.workers):
            worker_id = f"browser-worker-{i}"
            load = await self.redis.get(f"worker:load:{worker_id}")
            worker_loads[worker_id] = int(load or 0)

        # 选择负载最低的
        return min(worker_loads, key=worker_loads.get)

    async def _create_instance(
        self,
        worker_id: str,
        platform: str,
        account_id: str,
        user_id: str,
    ) -> BrowserInstance:
        """创建新的浏览器实例"""
        import uuid

        instance_id = str(uuid.uuid4())
        now = datetime.utcnow()

        # 发送创建请求到Worker
        await self.redis.publish(
            f"worker:command:{worker_id}",
            f"create:{instance_id}:{platform}:{account_id}:{user_id}"
        )

        # 等待实例就绪
        for _ in range(30):  # 最多等待30秒
            status = await self.redis.get(f"instance:status:{instance_id}")
            if status == b"ready":
                break
            await asyncio.sleep(1)
        else:
            raise TimeoutError("浏览器实例创建超时")

        instance = BrowserInstance(
            id=instance_id,
            worker_id=worker_id,
            platform=platform,
            account_id=account_id,
            user_id=user_id,
            created_at=now,
            last_used=now,
            status="idle",
        )

        # 保存实例信息
        key = f"browser:instance:{platform}:{account_id}:{user_id}"
        await self.redis.hset(key, mapping={
            "id": instance.id,
            "worker_id": instance.worker_id,
            "created_at": instance.created_at.isoformat(),
            "last_used": instance.last_used.isoformat(),
            "status": instance.status,
        })

        return instance

    async def _activate_instance(self, instance: BrowserInstance) -> "BrowserContext":
        """激活实例并返回上下文"""
        await self._update_instance_status(instance.id, "busy")

        return BrowserContext(
            instance_id=instance.id,
            worker_id=instance.worker_id,
            platform=instance.platform,
            redis=self.redis,
        )

    async def _update_instance_status(self, instance_id: str, status: str) -> None:
        """更新实例状态"""
        # 通过Redis广播状态更新
        await self.redis.publish(
            "instance:status:update",
            f"{instance_id}:{status}"
        )
```

### 5.2 浏览器上下文

```python
# backend/app/browser/context.py (新增业务模块)
import asyncio
import json
from dataclasses import dataclass

import redis.asyncio as redis


@dataclass
class PublishResult:
    success: bool
    post_id: str | None
    post_url: str | None
    error: str | None


class BrowserContext:
    """浏览器上下文 - 代理Worker中的实际浏览器"""

    def __init__(
        self,
        instance_id: str,
        worker_id: str,
        platform: str,
        redis: redis.Redis,
    ):
        self.instance_id = instance_id
        self.worker_id = worker_id
        self.platform = platform
        self.redis = redis

    async def publish(self, content: dict) -> PublishResult:
        """执行发布操作"""
        command = {
            "action": "publish",
            "instance_id": self.instance_id,
            "platform": self.platform,
            "content": content,
        }

        await self.redis.publish(
            f"worker:command:{self.worker_id}",
            json.dumps(command)
        )

        result = await self._wait_for_result("publish")

        return PublishResult(
            success=result["success"],
            post_id=result.get("post_id"),
            post_url=result.get("post_url"),
            error=result.get("error"),
        )

    async def fetch_analytics(self, post_id: str) -> dict:
        """获取数据分析"""
        command = {
            "action": "fetch_analytics",
            "instance_id": self.instance_id,
            "platform": self.platform,
            "post_id": post_id,
        }

        await self.redis.publish(
            f"worker:command:{self.worker_id}",
            json.dumps(command)
        )

        return await self._wait_for_result("fetch_analytics")

    async def _wait_for_result(self, action: str, timeout: int = 300) -> dict:
        """等待操作结果"""
        result_key = f"result:{self.instance_id}:{action}"

        for _ in range(timeout):
            result = await self.redis.get(result_key)
            if result:
                await self.redis.delete(result_key)
                return json.loads(result)
            await asyncio.sleep(1)

        raise TimeoutError(f"操作超时: {action}")
```

### 5.3 Worker进程

```python
# backend/app/browser/worker.py (新增业务模块)
import asyncio
import json

from playwright.async_api import async_playwright
import redis.asyncio as redis

from backend.core.conf import settings
from backend.database.redis import redis_client


class BrowserWorker:
    """浏览器Worker - 运行在独立容器中"""

    def __init__(self, worker_id: str):
        self.worker_id = worker_id
        self.redis = redis_client
        self.instances: dict[str, dict] = {}
        self.playwright = None
        self.browser = None

    async def start(self):
        """启动Worker"""
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(
            headless=True,
            args=[
                '--disable-blink-features=AutomationControlled',
                '--no-sandbox',
                '--disable-dev-shm-usage',
            ]
        )

        # 订阅命令频道
        pubsub = self.redis.pubsub()
        await pubsub.subscribe(f"worker:command:{self.worker_id}")

        # 监听命令
        async for message in pubsub.listen():
            if message["type"] == "message":
                await self.handle_command(message["data"])

    async def handle_command(self, data: bytes):
        """处理命令"""
        try:
            if data.startswith(b"create:"):
                parts = data.decode().split(":")
                await self.create_instance(
                    instance_id=parts[1],
                    platform=parts[2],
                    account_id=parts[3],
                    user_id=parts[4],
                )
            else:
                command = json.loads(data)
                await self.execute_command(command)
        except Exception as e:
            print(f"命令处理错误: {e}")

    async def create_instance(
        self,
        instance_id: str,
        platform: str,
        account_id: str,
        user_id: str,
    ):
        """创建浏览器实例"""
        from backend.app.browser.platforms import get_adapter

        context = await self.browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) ...',
        )

        adapter = get_adapter(platform)

        credentials = await self._load_credentials(user_id, platform, account_id)
        if credentials:
            await context.add_cookies(credentials.get("cookies", []))

        page = await context.new_page()

        self.instances[instance_id] = {
            "context": context,
            "page": page,
            "adapter": adapter,
            "platform": platform,
        }

        # 标记就绪
        await self.redis.set(f"instance:status:{instance_id}", "ready")

    async def execute_command(self, command: dict):
        """执行浏览器操作"""
        instance_id = command["instance_id"]
        action = command["action"]

        instance = self.instances.get(instance_id)
        if not instance:
            return

        adapter = instance["adapter"]
        page = instance["page"]

        try:
            if action == "publish":
                result = await adapter.publish(page, command["content"])
            elif action == "fetch_analytics":
                result = await adapter.fetch_analytics(page, command["post_id"])
            else:
                result = {"error": f"未知操作: {action}"}

            # 保存结果
            await self.redis.set(
                f"result:{instance_id}:{action}",
                json.dumps(result),
                ex=300,  # 5分钟过期
            )
        except Exception as e:
            await self.redis.set(
                f"result:{instance_id}:{action}",
                json.dumps({"error": str(e)}),
                ex=300,
            )

    async def _load_credentials(
        self,
        user_id: str,
        platform: str,
        account_id: str,
    ) -> dict | None:
        """加载凭证（需要客户端提供解密密钥）"""
        # 这里的实现需要与客户端配合
        # 凭证解密在内存中完成，用完即销毁
        pass
```

---

## 6. Celery任务 (基于 backend/app/task 模块扩展)

### 6.1 发布任务 (待扩展)

```python
# backend/app/task/tasks/publish/tasks.py (新增任务)
import asyncio

from celery import shared_task

from backend.database.db import async_db_session
from backend.app.publish.service.publish_service import PublishService
from backend.app.browser.pool_manager import BrowserPoolManager


@shared_task(bind=True, max_retries=3)
def execute_scheduled_publish(self, task_id: str):
    """执行定时发布任务"""

    async def _execute():
        async with async_db_session() as db:
            service = PublishService(db)
            await service.execute_publish(task_id)

    asyncio.run(_execute())


@shared_task
def cleanup_expired_browser_instances():
    """清理过期的浏览器实例"""

    async def _cleanup():
        pool = BrowserPoolManager()
        await pool.cleanup_expired()

    asyncio.run(_cleanup())
```

### 6.2 数据分析任务 (待扩展)

```python
# backend/app/task/tasks/analytics/tasks.py (新增任务)
import asyncio

from celery import shared_task

from backend.database.db import async_db_session
from backend.app.analytics.service.analytics_service import AnalyticsService


@shared_task
def collect_platform_analytics(user_id: str, platform: str, post_ids: list[str]):
    """收集平台数据"""

    async def _collect():
        async with async_db_session() as db:
            service = AnalyticsService(db)
            for post_id in post_ids:
                await service.collect_analytics(user_id, platform, post_id)

    asyncio.run(_collect())


@shared_task
def generate_daily_report(user_id: str):
    """生成每日报告"""

    async def _generate():
        async with async_db_session() as db:
            service = AnalyticsService(db)
            await service.generate_daily_report(user_id)

    asyncio.run(_generate())
```

---

## 7. Docker部署 (基于 fastapi_best_architecture)

### 7.1 多阶段构建 Dockerfile

```dockerfile
# Dockerfile (项目根目录)
# 基于 uv 的多阶段构建

ARG SERVER_TYPE=fba_server

# === Python环境构建阶段 ===
FROM ghcr.io/astral-sh/uv:python3.10-bookworm-slim AS builder

RUN apt-get update && apt-get install -y --no-install-recommends gcc python3-dev

COPY . /fba
WORKDIR /fba

# uv 环境配置
ENV UV_COMPILE_BYTECODE=1 \
    UV_NO_CACHE=1 \
    UV_LINK_MODE=copy \
    UV_PROJECT_ENVIRONMENT=/usr/local

RUN --mount=type=cache,target=/root/.cache/uv \
    uv sync --frozen --no-default-groups --group server

# === 运行时基础镜像 ===
FROM python:3.10-slim AS base_server

RUN apt-get update && apt-get install -y --no-install-recommends supervisor

COPY --from=builder /fba /fba
COPY --from=builder /usr/local /usr/local
COPY deploy/backend/supervisor/supervisord.conf /etc/supervisor/supervisord.conf

WORKDIR /fba/backend

# === FastAPI 服务镜像 ===
FROM base_server AS fba_server

COPY deploy/backend/supervisor/fba_server.conf /etc/supervisor/conf.d/
RUN mkdir -p /var/log/fba

EXPOSE 8001

CMD ["supervisord", "-c", "/etc/supervisor/supervisord.conf"]

# === Celery Worker 镜像 ===
FROM base_server AS fba_celery_worker

COPY deploy/backend/supervisor/fba_celery_worker.conf /etc/supervisor/conf.d/
RUN mkdir -p /var/log/fba

CMD ["supervisord", "-c", "/etc/supervisor/supervisord.conf"]

# === Celery Beat 镜像 ===
FROM base_server AS fba_celery_beat

COPY deploy/backend/supervisor/fba_celery_beat.conf /etc/supervisor/conf.d/
RUN mkdir -p /var/log/fba

CMD ["supervisord", "-c", "/etc/supervisor/supervisord.conf"]

# === Celery Flower 镜像 ===
FROM base_server AS fba_celery_flower

COPY deploy/backend/supervisor/fba_celery_flower.conf /etc/supervisor/conf.d/
RUN mkdir -p /var/log/fba

EXPOSE 8555

CMD ["supervisord", "-c", "/etc/supervisor/supervisord.conf"]

FROM ${SERVER_TYPE}
```

### 7.2 浏览器Worker Dockerfile (待扩展)

```dockerfile
# deploy/browser-worker/Dockerfile (新增)
FROM mcr.microsoft.com/playwright/python:v1.40.0-jammy

WORKDIR /app

COPY pyproject.toml uv.lock ./

RUN pip install uv && uv sync --frozen --no-default-groups --group browser

COPY backend ./backend

RUN playwright install chromium

CMD ["python", "-m", "backend.app.browser.worker"]
```

### 7.3 Docker Compose

```yaml
# docker-compose.yml (项目根目录)
services:
  fba_server:
    build:
      context: .
      dockerfile: Dockerfile
      target: fba_server
    container_name: fba_server
    restart: always
    depends_on:
      - fba_mysql
      - fba_redis
    volumes:
      - ./backend/static:/fba/backend/static
    networks:
      - fba_network
    ports:
      - "${DOCKER_API_PORT:-8001}:8001"
    env_file:
      - backend/.env

  fba_celery_worker:
    build:
      context: .
      dockerfile: Dockerfile
      target: fba_celery_worker
    container_name: fba_celery_worker
    restart: always
    depends_on:
      - fba_server
    volumes:
      - ./backend/static:/fba/backend/static
    networks:
      - fba_network
    env_file:
      - backend/.env

  fba_celery_beat:
    build:
      context: .
      dockerfile: Dockerfile
      target: fba_celery_beat
    container_name: fba_celery_beat
    restart: always
    depends_on:
      - fba_server
    networks:
      - fba_network
    env_file:
      - backend/.env

  fba_mysql:
    image: mysql:8.4
    container_name: fba_mysql
    restart: always
    volumes:
      - fba_mysql:/var/lib/mysql
    networks:
      - fba_network
    ports:
      - "${DOCKER_MYSQL_PORT:-3306}:3306"
    environment:
      MYSQL_DATABASE: ${DATABASE_SCHEMA:-fba}
      MYSQL_ROOT_PASSWORD: ${DATABASE_PASSWORD:-123456}
      TZ: Asia/Shanghai

  fba_redis:
    image: redis:7.4
    container_name: fba_redis
    restart: always
    volumes:
      - fba_redis:/data
    networks:
      - fba_network
    ports:
      - "${DOCKER_REDIS_PORT:-6379}:6379"

  fba_rabbitmq:
    image: rabbitmq:4.0-management
    container_name: fba_rabbitmq
    restart: always
    volumes:
      - fba_rabbitmq:/var/lib/rabbitmq
    networks:
      - fba_network
    ports:
      - "${DOCKER_RABBITMQ_PORT:-5672}:5672"
      - "${DOCKER_RABBITMQ_MANAGE_PORT:-15672}:15672"

  # 浏览器Worker (待扩展)
  # browser_worker:
  #   build:
  #     context: .
  #     dockerfile: deploy/browser-worker/Dockerfile
  #   deploy:
  #     replicas: 3
  #   depends_on:
  #     - fba_redis
  #   networks:
  #     - fba_network
  #   env_file:
  #     - backend/.env

volumes:
  fba_mysql:
  fba_redis:
  fba_rabbitmq:

networks:
  fba_network:
```

---

## 相关文档

- [系统架构](./01-系统架构.md)
- [桌面端设计](./02-桌面端设计.md)
- [移动端设计](./03-移动端设计.md)
- [Agent Runtime](./05-Agent-Runtime.md)
- [平台适配器](./06-平台适配器.md)
