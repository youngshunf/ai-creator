# 创流 (CreatorFlow) - 桌面端设计

> Tauri 2.0 + Python Sidecar (内嵌Python) 桌面端专属方案 | 版本: v2.5 | 更新: 2025-12-29
>
> **重要变更 (v2.5)**: LLM 调用改为云端网关模式，用户注册时自动分配 API Key，登录时自动同步到本地。详见 [云端服务设计 2.8节](./04-云端服务设计.md#28-桌面端调用方式)。
>
> **重要变更**: Python Sidecar 现使用 `agent-core` 共享包，不再重复定义 Agent 相关代码。详见 [Agent Runtime](./05-Agent-Runtime.md)。

## 1. 设计理念

### 1.1 桌面端定位

```yaml
核心定位: 完整功能 + 本地能力 + 隐私优先 + 零依赖部署

特点:
  - Python Sidecar 支持本地 Agent 执行
  - 内嵌 Python 环境，不依赖用户系统
  - Playwright 本地浏览器自动化
  - 本地凭证加密存储
  - 离线能力完整
  - 性能最优，隐私最强

目标用户:
  - 专业创作者（需要完整功能）
  - 隐私敏感用户（不愿上传凭证）
  - 重度用户（高频发布、批量操作）
  - 团队/机构用户（本地化部署需求）
```

### 1.2 核心优势

| 能力 | 描述 | 价值 |
|------|------|------|
| **内嵌 Python** | 打包完整 Python 环境 | 零依赖安装，开箱即用 |
| **本地 Agent** | Python Sidecar 运行 AI Agent | 隐私保护、响应快速 |
| **浏览器自动化** | Playwright 本地执行 | 凭证不离开本地 |
| **定时任务** | APScheduler 本地调度 | 无需云端，离线可用 |
| **数据存储** | SQLite 本地数据库 | 完全掌控数据 |
| **凭证安全** | 本地加密存储 | 最高安全等级 |
| **离线能力** | 完整功能可离线使用 | 不依赖网络 |
| **云端 LLM** | 调用云端 LLM 网关 | 统一接口、自动配额管理、零配置 |

---

## 2. 架构概述

```text
┌─────────────────────────────────────────────────────────────────────────────────┐
│                          桌面端应用 (Tauri 2.0)                                   │
│                                                                                  │
│  ┌────────────────────────────────────────────────────────────────────────────┐ │
│  │                         前端 UI (React + TypeScript)                        │ │
│  │  ┌────────────┐ ┌────────────┐ ┌────────────┐ ┌────────────┐ ┌──────────┐ │ │
│  │  │ 创作工作台 │ │  素材管理  │ │  发布中心  │ │  数据看板  │ │ 账号管理 │ │ │
│  │  │ 智能写作   │ │  想法库    │ │  定时发布  │ │  舆情分析  │ │ 凭证管理 │ │ │
│  │  │ AI配图    │ │  知识库    │ │  批量发布  │ │  数据采集  │ │ 平台绑定 │ │ │
│  │  └────────────┘ └────────────┘ └────────────┘ └────────────┘ └──────────┘ │ │
│  └──────────────────────────────────┬─────────────────────────────────────────┘ │
│                                     │ IPC (Tauri Commands)                      │
│  ┌──────────────────────────────────┴─────────────────────────────────────────┐ │
│  │                           Rust Core (Tauri 后端)                            │ │
│  │  ┌────────────┐ ┌────────────┐ ┌────────────┐ ┌────────────┐              │ │
│  │  │  文件系统  │ │  数据存储  │ │  系统托盘  │ │  进程管理  │              │ │
│  │  │  读写操作  │ │  SQLite    │ │  通知管理  │ │  Sidecar   │              │ │
│  │  └────────────┘ └────────────┘ └────────────┘ └────────────┘              │ │
│  │  ┌────────────┐ ┌────────────┐ ┌────────────┐ ┌────────────┐              │ │
│  │  │  凭证加密  │ │  窗口管理  │ │  自动更新  │ │  云端通信  │              │ │
│  │  │  Keychain  │ │  多窗口    │ │  热更新    │ │  API同步   │              │ │
│  │  └────────────┘ └────────────┘ └────────────┘ └────────────┘              │ │
│  └──────────────────────────────────┬─────────────────────────────────────────┘ │
│                                     │ JSON-RPC over stdio                       │
│  ┌──────────────────────────────────┴─────────────────────────────────────────┐ │
│  │                        Python Sidecar (独立进程)                            │ │
│  │                                                                             │ │
│  │  ┌───────────────────────────────────────────────────────────────────────┐ │ │
│  │  │                       agent-core (共享核心包)                          │ │ │
│  │  │  ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐          │ │ │
│  │  │  │  GraphLoader    │ │  GraphCompiler  │ │  ToolRegistry   │          │ │ │
│  │  │  │  Graph 加载器   │ │   Graph 编译器   │ │   工具注册表     │          │ │ │
│  │  │  └─────────────────┘ └─────────────────┘ └─────────────────┘          │ │ │
│  │  │  ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐          │ │ │
│  │  │  │ RuntimeContext  │ │ ExecutorInterface│ │ AssetResolver   │          │ │ │
│  │  │  │   运行时上下文   │ │    执行器接口    │ │   资源解析器     │          │ │ │
│  │  │  └─────────────────┘ └─────────────────┘ └─────────────────┘          │ │ │
│  │  └───────────────────────────────────────────────────────────────────────┘ │ │
│  │  ┌───────────────────────────────────────────────────────────────────────┐ │ │
│  │  │                       LocalExecutor (本地执行器)                       │ │ │
│  │  │  ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐          │ │ │
│  │  │  │  本地浏览器工具  │ │   本地凭证工具   │ │  BettaFish 工具  │          │ │ │
│  │  │  │  browser_publish│ │ credential_store│ │   hot_topic等    │          │ │ │
│  │  │  └─────────────────┘ └─────────────────┘ └─────────────────┘          │ │ │
│  │  └───────────────────────────────────────────────────────────────────────┘ │ │
│  │  ┌───────────────────────────────────────────────────────────────────────┐ │ │
│  │  │                       自动化引擎 (Automation)                          │ │ │
│  │  │  ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐          │ │ │
│  │  │  │   Playwright    │ │   APScheduler   │ │  Platform       │          │ │ │
│  │  │  │  浏览器自动化    │ │    定时任务      │ │   Adapters      │          │ │ │
│  │  │  └─────────────────┘ └─────────────────┘ └─────────────────┘          │ │ │
│  │  └───────────────────────────────────────────────────────────────────────┘ │ │
│  │  ┌───────────────────────────────────────────────────────────────────────┐ │ │
│  │  │                       内容处理 (Content)                               │ │ │
│  │  │  ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐          │ │ │
│  │  │  │  视频处理       │ │  图片处理        │ │  文档处理       │          │ │ │
│  │  │  │  FFmpeg         │ │  Pillow         │ │  Markdown       │          │ │ │
│  │  │  └─────────────────┘ └─────────────────┘ └─────────────────┘          │ │ │
│  │  └───────────────────────────────────────────────────────────────────────┘ │ │
│  │  ┌───────────────────────────────────────────────────────────────────────┐ │ │
│  │  │                       云端 LLM 调用 (Cloud LLM Gateway)               │ │ │
│  │  │  ┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐          │ │ │
│  │  │  │  API Key 同步   │ │   LLM 客户端     │ │   用量查询       │          │ │ │
│  │  │  │  登录自动获取   │ │   OpenAI 兼容    │ │   配额检查       │          │ │ │
│  │  │  └─────────────────┘ └─────────────────┘ └─────────────────┘          │ │ │
│  │  └───────────────────────────────────────────────────────────────────────┘ │ │
│  └─────────────────────────────────────────────────────────────────────────────┘ │
│                                                                                  │
│  Windows / macOS / Linux                                                         │
└─────────────────────────────────────────────────────────────────────────────────┘
```

---

## 3. 前端技术选型

### 3.1 技术栈总览

```yaml
核心框架:
  构建工具: Vite 6.x
  框架: React 19
  语言: TypeScript 5.x

UI 层:
  组件库: shadcn/ui (基于 Radix UI)
  样式方案: Tailwind CSS 4.x
  图标库: Lucide React
  动画: Framer Motion

状态管理:
  全局状态: Zustand
  服务端状态: TanStack Query v5
  表单状态: React Hook Form

路由:
  方案: TanStack Router

数据验证:
  方案: Zod

编辑器 (创作核心):
  富文本: TipTap (基于 ProseMirror)
  Markdown: @uiw/react-md-editor

图表:
  方案: Recharts / ECharts
```

### 3.2 UI 框架选型依据

| 维度 | Ant Design | Radix UI | shadcn/ui ✅ |
|------|-----------|----------|--------------|
| **包体积** | 较大 (~1MB+) | 轻量 (~50KB) | 轻量 (按需复制) |
| **样式方案** | Less/CSS-in-JS | 无样式原语 | Tailwind CSS |
| **定制性** | 中等 | 极高 | 高 |
| **设计风格** | 企业管理系统 | 无预设 | 现代简洁 |
| **Tauri 适配** | 一般 | 优秀 | 优秀 |

**选择 shadcn/ui 的理由**:

1. **轻量**: 代码复制到项目，无额外依赖，Tauri 包体积可控
2. **定制性**: 基于 Radix UI 原语，可深度定制创作类界面
3. **现代设计**: 风格更适合创作者工具，不像 Ant Design 那么"管理系统"
4. **Tailwind**: 与 Tauri 生态配合好，样式隔离清晰
5. **可扩展**: 需要复杂组件时可按需引入其他库补充

### 3.3 目录结构

```text
apps/desktop/
├── src/                              # React 前端源码
│   ├── main.tsx                      # 应用入口
│   ├── App.tsx                       # 根组件
│   ├── routes/                       # 路由配置 (TanStack Router)
│   │   ├── __root.tsx                # 根路由
│   │   ├── index.tsx                 # 首页
│   │   ├── creation/                 # 创作模块
│   │   │   ├── index.tsx
│   │   │   └── $draftId.tsx
│   │   ├── publish/                  # 发布模块
│   │   ├── analytics/                # 数据模块
│   │   └── settings/                 # 设置模块
│   │
│   ├── components/                   # 组件
│   │   ├── ui/                       # shadcn/ui 组件
│   │   │   ├── button.tsx
│   │   │   ├── dialog.tsx
│   │   │   ├── input.tsx
│   │   │   └── ...
│   │   ├── layout/                   # 布局组件
│   │   │   ├── Sidebar.tsx
│   │   │   ├── Header.tsx
│   │   │   └── MainLayout.tsx
│   │   ├── editor/                   # 编辑器组件
│   │   │   ├── TiptapEditor.tsx
│   │   │   └── EditorToolbar.tsx
│   │   └── shared/                   # 共享业务组件
│   │
│   ├── hooks/                        # 自定义 Hooks
│   │   ├── useAgent.ts               # Agent 调用
│   │   ├── useSidecar.ts             # Sidecar 通信
│   │   └── useHotTopics.ts           # 热点话题
│   │
│   ├── stores/                       # Zustand 状态
│   │   ├── useAppStore.ts            # 应用状态
│   │   ├── useDraftStore.ts          # 草稿状态
│   │   └── useAccountStore.ts        # 账号状态
│   │
│   ├── lib/                          # 工具库
│   │   ├── sidecar-client.ts         # Sidecar 客户端
│   │   ├── llm-client.ts             # LLM 客户端
│   │   ├── utils.ts                  # 通用工具
│   │   └── cn.ts                     # className 合并
│   │
│   ├── api/                          # API 层 (TanStack Query)
│   │   ├── queries/                  # 查询
│   │   └── mutations/                # 变更
│   │
│   └── styles/                       # 样式
│       └── globals.css               # 全局样式 + Tailwind
│
├── src-tauri/                        # Tauri Rust 后端
│   └── ...
│
├── components.json                   # shadcn/ui 配置
├── tailwind.config.ts                # Tailwind 配置
├── tsconfig.json                     # TypeScript 配置
├── vite.config.ts                    # Vite 配置
└── package.json
```

### 3.4 核心依赖

```json
{
  "dependencies": {
    "react": "^19.0.0",
    "react-dom": "^19.0.0",
    "@tauri-apps/api": "^2.0.0",
    "@tanstack/react-router": "^1.90.0",
    "@tanstack/react-query": "^5.60.0",
    "zustand": "^5.0.0",
    "react-hook-form": "^7.54.0",
    "@hookform/resolvers": "^3.9.0",
    "zod": "^3.24.0",
    "@tiptap/react": "^2.10.0",
    "@tiptap/starter-kit": "^2.10.0",
    "@radix-ui/react-dialog": "^1.1.0",
    "@radix-ui/react-dropdown-menu": "^2.1.0",
    "@radix-ui/react-select": "^2.1.0",
    "@radix-ui/react-tabs": "^1.1.0",
    "class-variance-authority": "^0.7.0",
    "clsx": "^2.1.0",
    "tailwind-merge": "^2.5.0",
    "lucide-react": "^0.460.0",
    "framer-motion": "^11.12.0",
    "recharts": "^2.14.0"
  },
  "devDependencies": {
    "@types/react": "^19.0.0",
    "@types/react-dom": "^19.0.0",
    "@vitejs/plugin-react": "^4.3.0",
    "typescript": "^5.7.0",
    "vite": "^6.0.0",
    "tailwindcss": "^4.0.0",
    "postcss": "^8.4.0",
    "autoprefixer": "^10.4.0"
  }
}
```

### 3.5 项目初始化

```bash
# 1. 创建 Tauri + Vite + React 项目
pnpm create tauri-app apps/desktop --template react-ts

cd apps/desktop

# 2. 安装 Tailwind CSS
pnpm add -D tailwindcss postcss autoprefixer
npx tailwindcss init -p

# 3. 初始化 shadcn/ui
pnpm dlx shadcn@latest init

# 4. 安装 shadcn/ui 常用组件
pnpm dlx shadcn@latest add button dialog input select tabs dropdown-menu \
  form toast tooltip popover command sheet avatar badge card

# 5. 安装状态管理
pnpm add zustand @tanstack/react-query

# 6. 安装路由
pnpm add @tanstack/react-router
pnpm add -D @tanstack/router-plugin @tanstack/router-devtools

# 7. 安装表单验证
pnpm add react-hook-form @hookform/resolvers zod

# 8. 安装编辑器
pnpm add @tiptap/react @tiptap/starter-kit @tiptap/extension-placeholder \
  @tiptap/extension-image @tiptap/extension-link

# 9. 安装图表
pnpm add recharts

# 10. 安装动画
pnpm add framer-motion
```

### 3.6 配置文件

#### Vite 配置

```typescript
// vite.config.ts
import { defineConfig } from 'vite';
import react from '@vitejs/plugin-react';
import { TanStackRouterVite } from '@tanstack/router-plugin/vite';
import path from 'path';

export default defineConfig({
  plugins: [
    TanStackRouterVite(),
    react(),
  ],
  resolve: {
    alias: {
      '@': path.resolve(__dirname, './src'),
    },
  },
  clearScreen: false,
  server: {
    port: 1420,
    strictPort: true,
    watch: {
      ignored: ['**/src-tauri/**'],
    },
  },
});
```

#### Tailwind 配置

```typescript
// tailwind.config.ts
import type { Config } from 'tailwindcss';

const config: Config = {
  darkMode: ['class'],
  content: ['./src/**/*.{ts,tsx}'],
  theme: {
    extend: {
      colors: {
        border: 'hsl(var(--border))',
        input: 'hsl(var(--input))',
        ring: 'hsl(var(--ring))',
        background: 'hsl(var(--background))',
        foreground: 'hsl(var(--foreground))',
        primary: {
          DEFAULT: 'hsl(var(--primary))',
          foreground: 'hsl(var(--primary-foreground))',
        },
        secondary: {
          DEFAULT: 'hsl(var(--secondary))',
          foreground: 'hsl(var(--secondary-foreground))',
        },
        destructive: {
          DEFAULT: 'hsl(var(--destructive))',
          foreground: 'hsl(var(--destructive-foreground))',
        },
        muted: {
          DEFAULT: 'hsl(var(--muted))',
          foreground: 'hsl(var(--muted-foreground))',
        },
        accent: {
          DEFAULT: 'hsl(var(--accent))',
          foreground: 'hsl(var(--accent-foreground))',
        },
      },
      borderRadius: {
        lg: 'var(--radius)',
        md: 'calc(var(--radius) - 2px)',
        sm: 'calc(var(--radius) - 4px)',
      },
    },
  },
  plugins: [require('tailwindcss-animate')],
};

export default config;
```

#### TypeScript 配置

```json
// tsconfig.json
{
  "compilerOptions": {
    "target": "ES2020",
    "useDefineForClassFields": true,
    "lib": ["ES2020", "DOM", "DOM.Iterable"],
    "module": "ESNext",
    "skipLibCheck": true,
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "jsx": "react-jsx",
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noFallthroughCasesInSwitch": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["src"],
  "references": [{ "path": "./tsconfig.node.json" }]
}
```

---

## 4. Python Sidecar 设计

> **重要**: Python Sidecar 使用 `agent-core` 共享包，不重复定义 Agent 相关代码。
> 详见 [Agent Runtime](./05-Agent-Runtime.md) 文档。

### 4.1 目录结构

```text
apps/sidecar/                     # 桌面端 Python Sidecar (Monorepo 结构)
├── pyproject.toml                # 依赖管理 (uv)，依赖 agent-core
├── src/
│   └── sidecar/
│       ├── __init__.py
│       ├── main.py               # 入口点
│       ├── server.py             # JSON-RPC 服务器
│       ├── executor.py           # LocalExecutor (继承 agent-core)
│       │
│       ├── tools/                # 🔥 本地专属工具（注册到 agent-core）
│       │   ├── __init__.py
│       │   ├── browser.py        # 本地浏览器发布工具
│       │   ├── credential.py     # 本地凭证工具
│       │   └── bettafish/        # BettaFish 本地工具
│       │       ├── __init__.py
│       │       ├── hot_topic.py
│       │       └── sentiment.py
│       │
│       ├── automation/           # 自动化模块
│       │   ├── __init__.py
│       │   ├── browser/          # 浏览器自动化
│       │   │   ├── __init__.py
│       │   │   ├── manager.py    # 浏览器实例管理
│       │   │   └── stealth.py    # 反检测
│       │   ├── scheduler.py      # 定时任务
│       │   └── task_queue.py     # 任务队列
│       │
│       ├── content/              # 内容处理
│       │   ├── __init__.py
│       │   ├── video/            # 视频处理
│       │   │   ├── __init__.py
│       │   │   └── processor.py
│       │   ├── image/            # 图片处理
│       │   │   ├── __init__.py
│       │   │   └── processor.py
│       │   └── document/         # 文档处理
│       │       ├── __init__.py
│       │       └── markdown.py
│       │
│       ├── storage/              # 存储层
│       │   ├── __init__.py
│       │   ├── credential.py     # 凭证管理
│       │   └── asset.py          # 资源管理 (LocalAssetResolver)
│       │
│       ├── llm/                  # 云端 LLM 客户端 (调用云端网关)
│       │   ├── __init__.py
│       │   ├── client.py         # LLM 客户端 (OpenAI 兼容接口)
│       │   └── token_manager.py  # API Token 管理 (登录同步)
│       │
│       └── utils/
│           ├── __init__.py
│           ├── config.py
│           ├── logger.py
│           └── crypto.py         # 凭证加密
│
└── tests/

# Graph 定义文件位于 Monorepo 根目录（端云共享）
agent-definitions/                # 🔥 共享 Graph 定义
├── content-creation.yaml
├── viral-content.yaml
├── publish-workflow.yaml
└── analytics.yaml
```

### 4.2 与 agent-core 的关系

```text
┌─────────────────────────────────────────────────────────────────────────────┐
│                          代码共享架构                                         │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  packages/agent-core/           # 🔥 共享核心包                              │
│  ├── graph/                     # Graph 加载/编译                           │
│  ├── runtime/                   # ExecutorInterface, RuntimeContext         │
│  ├── tools/                     # ToolInterface, ToolRegistry               │
│  │   ├── builtin/               # 端云共用工具 (llm_generate, web_search)   │
│  │   └── stubs/                 # 工具接口桩 (browser, credential)          │
│  ├── resource/                  # AssetURI, AssetResolver                   │
│  └── platforms/                 # 平台适配器基类                             │
│                                                                             │
│  apps/sidecar/                  # 桌面端 Sidecar                            │
│  ├── executor.py                # LocalExecutor (实现 ExecutorInterface)    │
│  └── tools/                     # 🔥 本地专属工具实现                        │
│      ├── browser.py             # 注册到 RuntimeType.LOCAL                  │
│      └── credential.py          # 注册到 RuntimeType.LOCAL                  │
│                                                                             │
│  agent-definitions/             # 🔥 共享 Graph 定义（唯一来源）              │
│  └── *.yaml                     # 端云使用同一份 Graph                       │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 4.3 pyproject.toml 配置

```toml
# apps/sidecar/pyproject.toml

[project]
name = "ai-creator-sidecar"
version = "0.1.0"
description = "AI Creator 桌面端 Python Sidecar"
requires-python = ">=3.11"

dependencies = [
    "agent-core",           # 🔥 workspace 引用，共享核心包
    "playwright>=1.40.0",   # 本地浏览器自动化
    "apscheduler>=3.10.0",  # 本地定时任务
    "uvicorn>=0.30.0",
    "loguru>=0.7.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/sidecar"]
```

### 4.4 JSON-RPC 服务器

```python
# apps/sidecar/src/sidecar/server.py
import asyncio
import json
import sys
from typing import Any, Callable
from dataclasses import dataclass
from loguru import logger

@dataclass
class RpcMethod:
    """RPC 方法定义"""
    name: str
    handler: Callable
    description: str = ""

class JsonRpcServer:
    """JSON-RPC 服务器，通过 stdio 与 Tauri 通信"""

    def __init__(self):
        self.handlers: dict[str, Callable] = {}
        self._running = False
        self._request_handlers: dict[int, asyncio.Future] = {}

    def register(self, method: str, description: str = ""):
        """装饰器：注册 RPC 方法"""
        def decorator(func: Callable):
            self.handlers[method] = func
            logger.info(f"Registered RPC method: {method}")
            return func
        return decorator

    async def handle_request(self, request: dict) -> dict:
        """处理单个请求"""
        method = request.get("method")
        params = request.get("params", {})
        request_id = request.get("id")

        if method not in self.handlers:
            return {
                "jsonrpc": "2.0",
                "error": {"code": -32601, "message": f"Method not found: {method}"},
                "id": request_id
            }

        try:
            handler = self.handlers[method]
            if asyncio.iscoroutinefunction(handler):
                result = await handler(**params)
            else:
                result = handler(**params)
            return {"jsonrpc": "2.0", "result": result, "id": request_id}
        except Exception as e:
            logger.exception(f"Error handling {method}")
            return {
                "jsonrpc": "2.0",
                "error": {"code": -32000, "message": str(e)},
                "id": request_id
            }

    async def send_notification(self, method: str, params: dict):
        """发送通知到 Tauri（无需响应）"""
        notification = {
            "jsonrpc": "2.0",
            "method": method,
            "params": params
        }
        sys.stdout.write(json.dumps(notification) + "\n")
        sys.stdout.flush()

    async def run(self):
        """主循环：从 stdin 读取，写入 stdout"""
        self._running = True
        logger.info("Python Sidecar started")

        reader = asyncio.StreamReader()
        protocol = asyncio.StreamReaderProtocol(reader)
        await asyncio.get_event_loop().connect_read_pipe(lambda: protocol, sys.stdin)

        while self._running:
            try:
                line = await reader.readline()
                if not line:
                    break

                request = json.loads(line.decode().strip())
                response = await self.handle_request(request)

                sys.stdout.write(json.dumps(response) + "\n")
                sys.stdout.flush()

            except json.JSONDecodeError as e:
                logger.error(f"Invalid JSON: {e}")
            except Exception as e:
                logger.exception("Error in main loop")

        logger.info("Python Sidecar stopped")

    def stop(self):
        """停止服务器"""
        self._running = False

# 全局服务器实例
server = JsonRpcServer()
```

### 4.5 Agent 集成（使用 agent-core）

```python
# apps/sidecar/src/sidecar/executor.py
"""
本地执行器 - 继承 agent-core 的 ExecutorInterface
详见 05-Agent-Runtime.md 中的完整实现
"""
from typing import AsyncIterator
from datetime import datetime

from agent_core.runtime.interfaces import (
    ExecutorInterface, RuntimeType, RuntimeContext,
    ExecutionRequest, ExecutionResponse, AgentEvent
)
from agent_core.graph.loader import GraphLoader
from agent_core.graph.compiler import GraphCompiler
from agent_core.tools.registry import ToolRegistry
from agent_core.resource.resolver import LocalAssetResolver

from .server import server
from .automation.browser.manager import browser_manager


class LocalExecutor(ExecutorInterface):
    """
    本地执行器 - 桌面端 Python Sidecar

    继承 agent-core 的 ExecutorInterface，实现本地专属逻辑：
    - 使用本地浏览器管理器
    - 使用本地凭证存储
    - 使用本地资源解析器
    """

    runtime_type = RuntimeType.LOCAL

    def __init__(self, config: dict):
        self.config = config
        self.graph_loader = GraphLoader(
            definitions_path=config.get('definitions_path', 'agent-definitions')
        )
        self.tool_registry = ToolRegistry(RuntimeType.LOCAL)
        self.compiler = GraphCompiler(self.tool_registry)
        self._executions: dict[str, dict] = {}

        # 注册本地专属工具
        self._register_local_tools()

    def _register_local_tools(self):
        """注册本地专属工具到 ToolRegistry"""
        # 本地工具在 sidecar/tools/ 目录下定义
        # 使用 @ToolRegistry.register("tool_name", RuntimeType.LOCAL) 装饰器
        from .tools import browser, credential, bettafish
        # 工具会在导入时自动注册

    def _create_context(self, request: ExecutionRequest) -> RuntimeContext:
        """创建运行时上下文"""
        from .llm.token_manager import token_manager

        return RuntimeContext(
            runtime_type=RuntimeType.LOCAL,
            user_id=request.user_id,
            inputs=request.inputs,
            model_default=self.config.get('default_model', 'claude-sonnet-4-20250514'),
            model_fast=self.config.get('fast_model', 'claude-3-5-haiku-20241022'),
            # 使用云端 API Token (登录时自动同步)
            cloud_api_token=token_manager.get_token_sync(),
            cloud_api_base=self.config.get('cloud_api_base', 'https://api.ai-creator.com'),
            asset_resolver=LocalAssetResolver(self.config),
            extra={
                "browser_manager": browser_manager,  # 本地浏览器管理器
            }
        )

    async def execute(self, request: ExecutionRequest) -> ExecutionResponse:
        """执行 Graph - 详见 05-Agent-Runtime.md"""
        # 实现继承自 agent-core，此处省略
        pass

    async def execute_stream(
        self, request: ExecutionRequest
    ) -> AsyncIterator[AgentEvent]:
        """流式执行 Graph，返回事件流"""
        # 实现继承自 agent-core，此处省略
        pass

    async def get_status(self, execution_id: str) -> dict:
        return self._executions.get(execution_id, {"status": "not_found"})

    async def cancel(self, execution_id: str) -> bool:
        if execution_id in self._executions:
            self._executions[execution_id]["status"] = "cancelled"
            return True
        return False

    async def health_check(self) -> bool:
        return True


# 创建执行器实例
executor: LocalExecutor = None


def init_executor(config: dict):
    """初始化执行器"""
    global executor
    executor = LocalExecutor(config)


# RPC 接口
@server.register("agent.execute_graph")
async def execute_graph(
    graph_name: str,
    inputs: dict,
    user_id: str,
    config: dict | None = None
) -> dict:
    """执行 Agent Graph"""
    request = ExecutionRequest(
        graph_name=graph_name,
        inputs=inputs,
        user_id=user_id,
    )

    # 发送事件到前端
    async for event in executor.execute_stream(request):
        await server.send_notification("agent.event", {
            "event_type": event.event_type,
            "run_id": event.run_id,
            "data": event.data,
        })

    response = await executor.execute(request)
    return {
        "success": response.success,
        "outputs": response.outputs,
        "error": response.error,
        "execution_id": response.execution_id,
        "execution_time": response.execution_time,
    }


@server.register("agent.list_graphs")
async def list_graphs() -> list[str]:
    """列出可用的 Graph"""
    return executor.graph_loader.list_graphs()


@server.register("agent.get_graph_schema")
async def get_graph_schema(graph_name: str) -> dict:
    """获取 Graph 的输入输出 Schema"""
    definition = executor.graph_loader.load(graph_name)
    return {
        "inputs": definition['spec'].get('inputs', {}),
        "outputs": definition['spec'].get('outputs', {}),
    }
```

### 4.6 本地专属工具示例

```python
# apps/sidecar/src/sidecar/tools/browser.py
"""
本地浏览器发布工具 - 仅在桌面端可用
使用 Playwright 进行本地浏览器自动化
"""
from agent_core.tools.base import ToolInterface, ToolMetadata, ToolCapability, ToolResult
from agent_core.tools.registry import ToolRegistry
from agent_core.runtime.interfaces import RuntimeType, RuntimeContext
from agent_core.platforms import get_adapter


@ToolRegistry.register("browser_publish", RuntimeType.LOCAL)
class LocalBrowserPublishTool(ToolInterface):
    """本地浏览器发布工具 - 仅端侧可用"""

    metadata = ToolMetadata(
        name="browser_publish",
        description="使用本地 Playwright 浏览器发布内容到社交平台",
        capabilities=[ToolCapability.BROWSER_AUTOMATION],
        supported_runtimes=[RuntimeType.LOCAL],  # 仅本地
    )

    async def execute(
        self,
        ctx: RuntimeContext,
        *,
        platform: str,
        account_id: str,
        content: dict,
    ) -> ToolResult:
        """使用本地 Playwright 发布"""
        try:
            # 从上下文获取浏览器管理器
            browser_manager = ctx.extra.get("browser_manager")
            if not browser_manager:
                return ToolResult(
                    success=False,
                    data=None,
                    error="Browser manager not available"
                )

            # 创建浏览器会话
            session = await browser_manager.create_session(
                session_id=f"{platform}_{account_id}",
                platform=platform,
            )

            # 加载本地保存的凭证
            await self._load_credentials(session.context, platform, account_id)

            # 使用平台适配器发布
            adapter = get_adapter(platform)
            result = await adapter.publish(session.page, content)

            # 关闭会话
            await browser_manager.close_session(session.id)

            return ToolResult(success=True, data=result)

        except Exception as e:
            return ToolResult(success=False, data=None, error=str(e))

    async def _load_credentials(self, context, platform: str, account_id: str):
        """加载本地加密的凭证"""
        from ..storage.credential import credential_manager
        credential = credential_manager.load_credential(platform, account_id)
        if credential and credential.cookies:
            await context.add_cookies(credential.cookies)

    def get_schema(self) -> dict:
        return {
            "type": "object",
            "properties": {
                "platform": {
                    "type": "string",
                    "enum": ["xiaohongshu", "douyin", "weibo", "bilibili", "wechat_mp"],
                    "description": "目标平台"
                },
                "account_id": {"type": "string", "description": "账号ID"},
                "content": {
                    "type": "object",
                    "description": "发布内容",
                    "properties": {
                        "title": {"type": "string"},
                        "text": {"type": "string"},
                        "images": {"type": "array", "items": {"type": "string"}},
                        "video": {"type": "string"},
                    }
                },
            },
            "required": ["platform", "account_id", "content"]
        }
```

### 4.7 浏览器自动化

```python
# apps/sidecar/src/sidecar/automation/browser/manager.py
import asyncio
from typing import Optional
from playwright.async_api import async_playwright, Browser, BrowserContext, Page
from dataclasses import dataclass
from loguru import logger

@dataclass
class BrowserSession:
    """浏览器会话"""
    id: str
    platform: str
    context: BrowserContext
    page: Page
    created_at: float

class BrowserManager:
    """浏览器实例管理器"""

    def __init__(self):
        self._playwright = None
        self._browser: Optional[Browser] = None
        self._sessions: dict[str, BrowserSession] = {}
        self._lock = asyncio.Lock()

    async def initialize(self):
        """初始化浏览器"""
        if self._playwright is None:
            self._playwright = await async_playwright().start()
            self._browser = await self._playwright.chromium.launch(
                headless=False,  # 桌面端默认非无头
                args=[
                    '--disable-blink-features=AutomationControlled',
                    '--disable-infobars',
                ]
            )
            logger.info("Browser initialized")

    async def create_session(
        self,
        session_id: str,
        platform: str,
        cookies: list[dict] | None = None,
        storage_state: dict | None = None,
    ) -> BrowserSession:
        """创建浏览器会话"""
        async with self._lock:
            if self._browser is None:
                await self.initialize()

            # 创建隔离的浏览器上下文
            context = await self._browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent=self._get_user_agent(platform),
                storage_state=storage_state,
            )

            # 注入反检测脚本
            await self._inject_stealth(context)

            # 设置 Cookies
            if cookies:
                await context.add_cookies(cookies)

            page = await context.new_page()

            session = BrowserSession(
                id=session_id,
                platform=platform,
                context=context,
                page=page,
                created_at=asyncio.get_event_loop().time(),
            )
            self._sessions[session_id] = session

            logger.info(f"Created browser session: {session_id} for {platform}")
            return session

    async def get_session(self, session_id: str) -> Optional[BrowserSession]:
        """获取会话"""
        return self._sessions.get(session_id)

    async def close_session(self, session_id: str):
        """关闭会话"""
        if session_id in self._sessions:
            session = self._sessions.pop(session_id)
            await session.context.close()
            logger.info(f"Closed browser session: {session_id}")

    async def export_cookies(self, session_id: str) -> list[dict]:
        """导出会话的 Cookies"""
        session = self._sessions.get(session_id)
        if session:
            return await session.context.cookies()
        return []

    async def export_storage_state(self, session_id: str) -> dict:
        """导出完整的存储状态（Cookies + LocalStorage）"""
        session = self._sessions.get(session_id)
        if session:
            return await session.context.storage_state()
        return {}

    def _get_user_agent(self, platform: str) -> str:
        """获取平台对应的 User-Agent"""
        user_agents = {
            "xiaohongshu": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
            "douyin": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "weibo": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "bilibili": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
        }
        return user_agents.get(platform, user_agents["xiaohongshu"])

    async def _inject_stealth(self, context: BrowserContext):
        """注入反检测脚本"""
        await context.add_init_script("""
            // 隐藏 webdriver 标记
            Object.defineProperty(navigator, 'webdriver', { get: () => undefined });

            // 修改 plugins
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5]
            });

            // 修改 languages
            Object.defineProperty(navigator, 'languages', {
                get: () => ['zh-CN', 'zh', 'en']
            });
        """)

# 全局管理器
browser_manager = BrowserManager()
```

### 4.8 云端 LLM 集成

> **重要**: 桌面端不再实现本地 LLM 网关，所有 LLM 调用通过云端网关进行。
> 详细接口设计参见 [云端服务设计 2.8节](./04-云端服务设计.md#28-桌面端调用方式)

#### 4.8.1 调用架构

```text
┌─────────────────────────────────────────────────────────────────────────┐
│                     桌面端 LLM 调用架构                                    │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  ┌─────────────┐     ┌─────────────────┐     ┌─────────────────────┐   │
│  │  桌面端 UI   │────▶│  Python Sidecar │────▶│  云端 LLM 网关      │   │
│  │  (Tauri)    │     │  (LocalExecutor) │     │  (OpenAI 兼容)      │   │
│  └─────────────┘     └─────────────────┘     └─────────────────────┘   │
│                              │                        │                │
│                              │                        │                │
│                              ▼                        ▼                │
│                      ┌─────────────────┐     ┌─────────────────────┐   │
│                      │  agent-core     │     │ Anthropic/OpenAI    │   │
│                      │  (LLM统一接口)  │     │ 等多供应商          │   │
│                      └─────────────────┘     └─────────────────────┘   │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

#### 4.8.2 API Key 自动分配与同步

**核心特点**:
- 用户注册时云端自动生成 API Key
- 用户登录时自动同步到本地
- 用户无需手动配置任何 LLM 相关设置

**Token 格式**: `sk-cf-{user_id_hash}_{random_suffix}`

**同步流程**:

```text
┌─────────────────────────────────────────────────────────────────────────┐
│                     API Key 自动同步流程                                  │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  1. 用户在桌面端登录 (OAuth2/手机号/邮箱)                                 │
│                          │                                              │
│                          ▼                                              │
│  2. 云端验证用户身份，返回用户 JWT Token                                  │
│                          │                                              │
│                          ▼                                              │
│  3. 桌面端调用 /api/v1/auth/llm-token 获取 LLM API Token                │
│                          │                                              │
│                          ▼                                              │
│  4. 云端为该用户生成/返回独立的 API Token (sk-cf-xxx)                     │
│                          │                                              │
│                          ▼                                              │
│  5. 桌面端自动保存 Token 到本地配置文件                                   │
│                          │                                              │
│                          ▼                                              │
│  6. 后续 LLM 调用自动携带 Token，无需用户干预                             │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

#### 4.8.3 LLM 客户端实现

```python
# apps/sidecar/src/sidecar/llm/client.py
"""
云端 LLM 客户端 - 调用云端 OpenAI 兼容接口
"""
import aiohttp
from typing import AsyncIterator, Optional
from dataclasses import dataclass
from loguru import logger

from .token_manager import token_manager


@dataclass
class LLMResponse:
    """LLM 响应"""
    content: str
    model: str
    usage: dict


class CloudLLMClient:
    """
    云端 LLM 客户端

    - 调用云端 OpenAI 兼容接口
    - 自动携带 API Token
    - 支持流式响应
    """

    def __init__(self, base_url: str = "https://api.ai-creator.com"):
        self.base_url = base_url
        self._session: Optional[aiohttp.ClientSession] = None

    async def _get_session(self) -> aiohttp.ClientSession:
        if self._session is None or self._session.closed:
            self._session = aiohttp.ClientSession()
        return self._session

    async def chat(
        self,
        messages: list[dict],
        model: str = "claude-sonnet-4-20250514",
        max_tokens: int = 4096,
        temperature: float = 0.7,
        stream: bool = False,
    ) -> LLMResponse | AsyncIterator[str]:
        """
        发送聊天请求
        """
        api_token = await token_manager.get_token()
        if not api_token:
            raise ValueError("未登录或 API Token 不可用")

        session = await self._get_session()

        headers = {
            "Authorization": f"Bearer {api_token}",
            "Content-Type": "application/json",
        }

        payload = {
            "model": model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature,
            "stream": stream,
        }

        async with session.post(
            f"{self.base_url}/v1/chat/completions",
            headers=headers,
            json=payload,
        ) as response:
            if response.status != 200:
                error = await response.text()
                raise Exception(f"LLM 调用失败: {error}")

            if stream:
                return self._stream_response(response)

            data = await response.json()
            return LLMResponse(
                content=data["choices"][0]["message"]["content"],
                model=data["model"],
                usage=data.get("usage", {}),
            )

    async def _stream_response(self, response) -> AsyncIterator[str]:
        """流式响应"""
        async for line in response.content:
            line = line.decode().strip()
            if line.startswith("data: "):
                data = line[6:]
                if data == "[DONE]":
                    break
                import json
                chunk = json.loads(data)
                if chunk["choices"][0]["delta"].get("content"):
                    yield chunk["choices"][0]["delta"]["content"]

    async def close(self):
        if self._session:
            await self._session.close()


# 全局客户端实例
llm_client = CloudLLMClient()
```

#### 4.8.4 Token 管理器

```python
# apps/sidecar/src/sidecar/llm/token_manager.py
"""
API Token 管理器 - 登录时自动同步
"""
import json
import os
from pathlib import Path
from typing import Optional
from loguru import logger


class TokenManager:
    """
    API Token 管理器

    - 登录时从云端获取 Token
    - 本地加密存储
    - 登出时自动清除
    """

    def __init__(self):
        self._token: Optional[str] = None
        self._config_path = Path.home() / ".ai-creator" / "llm-config.json"

    async def sync_token(self, jwt_token: str, api_base: str) -> str:
        """
        登录后同步 API Token

        Args:
            jwt_token: 用户 JWT Token
            api_base: 云端 API 地址

        Returns:
            API Token
        """
        import aiohttp

        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"{api_base}/api/v1/auth/llm-token",
                headers={"Authorization": f"Bearer {jwt_token}"},
            ) as response:
                if response.status != 200:
                    raise Exception("获取 API Token 失败")

                data = await response.json()
                api_token = data["api_token"]

        # 保存到本地
        await self._save_token(api_token)
        self._token = api_token

        logger.info("API Token 同步成功")
        return api_token

    async def get_token(self) -> Optional[str]:
        """获取 API Token"""
        if self._token:
            return self._token

        # 从本地配置加载
        if self._config_path.exists():
            try:
                with open(self._config_path) as f:
                    config = json.load(f)
                    self._token = config.get("production", {}).get("api_token")
            except Exception as e:
                logger.error(f"加载 Token 失败: {e}")

        return self._token

    async def _save_token(self, token: str):
        """保存 Token 到本地"""
        self._config_path.parent.mkdir(parents=True, exist_ok=True)

        config = {"production": {"api_token": token}}

        with open(self._config_path, "w") as f:
            json.dump(config, f, indent=2)

    async def clear_token(self):
        """清除 Token (登出时调用)"""
        self._token = None
        if self._config_path.exists():
            self._config_path.unlink()
        logger.info("API Token 已清除")


# 全局管理器实例
token_manager = TokenManager()
```

### 4.9 定时任务调度

```python
# apps/sidecar/src/sidecar/automation/scheduler.py
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.date import DateTrigger
from datetime import datetime
from typing import Optional
from dataclasses import dataclass
from loguru import logger

from ..server import server

@dataclass
class ScheduledTask:
    """定时任务"""
    id: str
    task_type: str
    params: dict
    trigger_type: str  # "date" | "cron"
    trigger_config: str
    created_at: datetime
    next_run: Optional[datetime] = None
    last_run: Optional[datetime] = None
    status: str = "active"

class TaskScheduler:
    """定时任务调度器"""

    def __init__(self):
        self.scheduler = AsyncIOScheduler()
        self._tasks: dict[str, ScheduledTask] = {}

    def start(self):
        """启动调度器"""
        self.scheduler.start()
        logger.info("Task scheduler started")

    def stop(self):
        """停止调度器"""
        self.scheduler.shutdown()
        logger.info("Task scheduler stopped")

    async def add_publish_task(
        self,
        task_id: str,
        platform: str,
        content: dict,
        schedule_time: datetime
    ) -> ScheduledTask:
        """添加定时发布任务"""
        task = ScheduledTask(
            id=task_id,
            task_type="publish",
            params={"platform": platform, "content": content},
            trigger_type="date",
            trigger_config=schedule_time.isoformat(),
            created_at=datetime.now(),
            next_run=schedule_time,
        )

        self.scheduler.add_job(
            self._execute_publish,
            trigger=DateTrigger(run_date=schedule_time),
            id=task_id,
            kwargs={"task": task},
            replace_existing=True,
        )

        self._tasks[task_id] = task
        logger.info(f"Added publish task: {task_id} scheduled for {schedule_time}")
        return task

    async def add_analytics_task(
        self,
        task_id: str,
        platform: str,
        post_id: str,
        cron: str
    ) -> ScheduledTask:
        """添加定时数据采集任务"""
        task = ScheduledTask(
            id=task_id,
            task_type="analytics",
            params={"platform": platform, "post_id": post_id},
            trigger_type="cron",
            trigger_config=cron,
            created_at=datetime.now(),
        )

        self.scheduler.add_job(
            self._execute_analytics,
            trigger=CronTrigger.from_crontab(cron),
            id=task_id,
            kwargs={"task": task},
            replace_existing=True,
        )

        self._tasks[task_id] = task
        logger.info(f"Added analytics task: {task_id} with cron {cron}")
        return task

    async def remove_task(self, task_id: str):
        """移除任务"""
        if task_id in self._tasks:
            self.scheduler.remove_job(task_id)
            del self._tasks[task_id]
            logger.info(f"Removed task: {task_id}")

    async def list_tasks(self) -> list[dict]:
        """列出所有任务"""
        return [
            {
                "id": task.id,
                "task_type": task.task_type,
                "params": task.params,
                "trigger_type": task.trigger_type,
                "trigger_config": task.trigger_config,
                "next_run": task.next_run.isoformat() if task.next_run else None,
                "last_run": task.last_run.isoformat() if task.last_run else None,
                "status": task.status,
            }
            for task in self._tasks.values()
        ]

    async def _execute_publish(self, task: ScheduledTask):
        """执行发布任务"""
        logger.info(f"Executing publish task: {task.id}")
        try:
            from .browser.platforms import get_adapter

            platform = task.params["platform"]
            content = task.params["content"]

            adapter = get_adapter(platform)
            result = await adapter.publish(**content)

            task.last_run = datetime.now()
            task.status = "completed"

            # 通知前端
            await server.send_notification("scheduler.task_completed", {
                "task_id": task.id,
                "task_type": "publish",
                "result": result,
            })

        except Exception as e:
            logger.exception(f"Publish task failed: {task.id}")
            task.status = "failed"
            await server.send_notification("scheduler.task_failed", {
                "task_id": task.id,
                "error": str(e),
            })

    async def _execute_analytics(self, task: ScheduledTask):
        """执行数据采集任务"""
        logger.info(f"Executing analytics task: {task.id}")
        try:
            from .browser.platforms import get_adapter

            platform = task.params["platform"]
            post_id = task.params["post_id"]

            adapter = get_adapter(platform)
            data = await adapter.fetch_analytics(post_id)

            task.last_run = datetime.now()

            # 通知前端
            await server.send_notification("scheduler.analytics_updated", {
                "task_id": task.id,
                "platform": platform,
                "post_id": post_id,
                "data": data,
            })

        except Exception as e:
            logger.exception(f"Analytics task failed: {task.id}")
            await server.send_notification("scheduler.task_failed", {
                "task_id": task.id,
                "error": str(e),
            })

# 全局调度器
task_scheduler = TaskScheduler()

# RPC 接口
@server.register("scheduler.add_publish")
async def add_publish_task(
    task_id: str,
    platform: str,
    content: dict,
    schedule_time: str
) -> dict:
    """添加定时发布任务"""
    dt = datetime.fromisoformat(schedule_time)
    task = await task_scheduler.add_publish_task(task_id, platform, content, dt)
    return {"success": True, "task_id": task.id}

@server.register("scheduler.add_analytics")
async def add_analytics_task(
    task_id: str,
    platform: str,
    post_id: str,
    cron: str
) -> dict:
    """添加定时数据采集任务"""
    task = await task_scheduler.add_analytics_task(task_id, platform, post_id, cron)
    return {"success": True, "task_id": task.id}

@server.register("scheduler.remove")
async def remove_task(task_id: str) -> dict:
    """移除任务"""
    await task_scheduler.remove_task(task_id)
    return {"success": True}

@server.register("scheduler.list")
async def list_tasks() -> list[dict]:
    """列出所有任务"""
    return await task_scheduler.list_tasks()
```

---

## 5. Rust Core (Tauri 后端)

### 5.1 Sidecar 管理器

```rust
// src-tauri/src/sidecar/manager.rs
use tauri::api::process::{Command, CommandChild, CommandEvent};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::{Mutex, oneshot, mpsc};
use log::{info, error, warn};

#[derive(Debug, Serialize, Deserialize)]
struct JsonRpcRequest {
    jsonrpc: String,
    method: String,
    params: serde_json::Value,
    id: u64,
}

#[derive(Debug, Serialize, Deserialize)]
struct JsonRpcResponse {
    jsonrpc: String,
    result: Option<serde_json::Value>,
    error: Option<JsonRpcError>,
    id: u64,
}

#[derive(Debug, Serialize, Deserialize)]
struct JsonRpcError {
    code: i32,
    message: String,
}

#[derive(Debug, Serialize, Deserialize)]
struct JsonRpcNotification {
    jsonrpc: String,
    method: String,
    params: serde_json::Value,
}

pub struct PythonSidecar {
    child: Option<CommandChild>,
    request_id: Arc<Mutex<u64>>,
    pending: Arc<Mutex<HashMap<u64, oneshot::Sender<Result<serde_json::Value, String>>>>>,
    notification_tx: Option<mpsc::UnboundedSender<JsonRpcNotification>>,
}

impl PythonSidecar {
    pub fn new() -> Self {
        Self {
            child: None,
            request_id: Arc::new(Mutex::new(0)),
            pending: Arc::new(Mutex::new(HashMap::new())),
            notification_tx: None,
        }
    }

    pub async fn start(
        &mut self,
        notification_tx: mpsc::UnboundedSender<JsonRpcNotification>,
    ) -> Result<(), String> {
        self.notification_tx = Some(notification_tx);

        let (mut rx, child) = Command::new_sidecar("python-sidecar")
            .map_err(|e| format!("Failed to create sidecar command: {}", e))?
            .spawn()
            .map_err(|e| format!("Failed to spawn sidecar: {}", e))?;

        self.child = Some(child);
        let pending = Arc::clone(&self.pending);
        let notification_tx = self.notification_tx.clone();

        // 处理 Sidecar 输出
        tokio::spawn(async move {
            while let Some(event) = rx.recv().await {
                match event {
                    CommandEvent::Stdout(line) => {
                        // 尝试解析为响应
                        if let Ok(response) = serde_json::from_str::<JsonRpcResponse>(&line) {
                            let mut pending_guard = pending.lock().await;
                            if let Some(tx) = pending_guard.remove(&response.id) {
                                let result = if let Some(error) = response.error {
                                    Err(error.message)
                                } else {
                                    Ok(response.result.unwrap_or(serde_json::Value::Null))
                                };
                                let _ = tx.send(result);
                            }
                        }
                        // 尝试解析为通知
                        else if let Ok(notification) = serde_json::from_str::<JsonRpcNotification>(&line) {
                            if let Some(tx) = &notification_tx {
                                let _ = tx.send(notification);
                            }
                        }
                    }
                    CommandEvent::Stderr(line) => {
                        warn!("Python stderr: {}", line);
                    }
                    CommandEvent::Error(error) => {
                        error!("Sidecar error: {}", error);
                    }
                    CommandEvent::Terminated(payload) => {
                        info!("Sidecar terminated: {:?}", payload);
                        break;
                    }
                    _ => {}
                }
            }
        });

        info!("Python Sidecar started");
        Ok(())
    }

    pub async fn call(
        &self,
        method: &str,
        params: serde_json::Value,
    ) -> Result<serde_json::Value, String> {
        let child = self.child.as_ref().ok_or("Sidecar not started")?;

        // 生成请求 ID
        let request_id = {
            let mut id = self.request_id.lock().await;
            *id += 1;
            *id
        };

        let request = JsonRpcRequest {
            jsonrpc: "2.0".to_string(),
            method: method.to_string(),
            params,
            id: request_id,
        };

        // 创建响应通道
        let (tx, rx) = oneshot::channel();
        {
            let mut pending = self.pending.lock().await;
            pending.insert(request_id, tx);
        }

        // 发送请求
        let request_str = serde_json::to_string(&request)
            .map_err(|e| format!("Failed to serialize request: {}", e))?;

        child.write((request_str + "\n").as_bytes())
            .map_err(|e| format!("Failed to write to sidecar: {}", e))?;

        // 等待响应
        rx.await.map_err(|_| "Response channel closed".to_string())?
    }

    pub async fn stop(&mut self) -> Result<(), String> {
        if let Some(child) = self.child.take() {
            child.kill().map_err(|e| format!("Failed to kill sidecar: {}", e))?;
        }
        info!("Python Sidecar stopped");
        Ok(())
    }
}
```

### 5.2 Tauri 命令

```rust
// src-tauri/src/commands/agent.rs
use tauri::State;
use std::sync::Arc;
use tokio::sync::Mutex;
use crate::sidecar::PythonSidecar;

/// 执行 Agent Graph
#[tauri::command]
pub async fn execute_agent_graph(
    state: State<'_, Arc<Mutex<PythonSidecar>>>,
    graph_name: String,
    inputs: serde_json::Value,
    user_id: String,
    config: Option<serde_json::Value>,
) -> Result<serde_json::Value, String> {
    let sidecar = state.lock().await;
    sidecar.call("agent.execute_graph", serde_json::json!({
        "graph_name": graph_name,
        "inputs": inputs,
        "user_id": user_id,
        "config": config
    })).await
}

/// 创建文章
#[tauri::command]
pub async fn create_article(
    state: State<'_, Arc<Mutex<PythonSidecar>>>,
    topic: String,
    style: String,
    platform: String,
) -> Result<serde_json::Value, String> {
    let sidecar = state.lock().await;
    sidecar.call("agent.execute_graph", serde_json::json!({
        "graph_name": "content_creation",
        "inputs": {
            "topic": topic,
            "style": style,
            "platform": platform
        },
        "user_id": "local_user",
        "config": {}
    })).await
}

/// 创建爆款内容（使用 BettaFish）
#[tauri::command]
pub async fn create_viral_content(
    state: State<'_, Arc<Mutex<PythonSidecar>>>,
    niche: String,
    platform: String,
    content_type: String,
) -> Result<serde_json::Value, String> {
    let sidecar = state.lock().await;
    sidecar.call("agent.execute_graph", serde_json::json!({
        "graph_name": "viral_content",
        "inputs": {
            "niche": niche,
            "target_platform": platform,
            "content_type": content_type
        },
        "user_id": "local_user",
        "config": {}
    })).await
}

/// 发布内容
#[tauri::command]
pub async fn publish_content(
    state: State<'_, Arc<Mutex<PythonSidecar>>>,
    platform: String,
    content: serde_json::Value,
) -> Result<serde_json::Value, String> {
    let sidecar = state.lock().await;
    sidecar.call(&format!("platform.{}.publish", platform), content).await
}

/// 定时发布
#[tauri::command]
pub async fn schedule_publish(
    state: State<'_, Arc<Mutex<PythonSidecar>>>,
    task_id: String,
    platform: String,
    content: serde_json::Value,
    schedule_time: String,
) -> Result<serde_json::Value, String> {
    let sidecar = state.lock().await;
    sidecar.call("scheduler.add_publish", serde_json::json!({
        "task_id": task_id,
        "platform": platform,
        "content": content,
        "schedule_time": schedule_time
    })).await
}

/// 获取热点话题（BettaFish）
#[tauri::command]
pub async fn get_hot_topics(
    state: State<'_, Arc<Mutex<PythonSidecar>>>,
    platform: String,
    category: Option<String>,
    limit: Option<i32>,
) -> Result<serde_json::Value, String> {
    let sidecar = state.lock().await;
    sidecar.call("bettafish.hot_topic_discovery", serde_json::json!({
        "platform": platform,
        "category": category,
        "time_range": "24h",
        "limit": limit.unwrap_or(20)
    })).await
}
```

### 5.3 凭证管理

```rust
// src-tauri/src/storage/credential.rs
use keyring::Entry;
use serde::{Deserialize, Serialize};
use aes_gcm::{
    aead::{Aead, KeyInit, OsRng},
    Aes256Gcm, Nonce,
};
use base64::{engine::general_purpose::STANDARD as BASE64, Engine};
use rand::RngCore;

const SERVICE_NAME: &str = "ai-creator";

#[derive(Debug, Serialize, Deserialize)]
pub struct PlatformCredential {
    pub platform: String,
    pub account_id: String,
    pub cookies: Vec<CookieData>,
    pub storage_state: Option<String>,
    pub created_at: i64,
    pub updated_at: i64,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct CookieData {
    pub name: String,
    pub value: String,
    pub domain: String,
    pub path: String,
    pub expires: Option<f64>,
    pub http_only: bool,
    pub secure: bool,
}

pub struct CredentialManager {
    encryption_key: [u8; 32],
}

impl CredentialManager {
    pub fn new() -> Result<Self, String> {
        // 从系统密钥环获取或创建主密钥
        let entry = Entry::new(SERVICE_NAME, "master_key")
            .map_err(|e| format!("Failed to access keyring: {}", e))?;

        let key = match entry.get_password() {
            Ok(key_b64) => {
                let key_bytes = BASE64.decode(&key_b64)
                    .map_err(|e| format!("Failed to decode key: {}", e))?;
                let mut key = [0u8; 32];
                key.copy_from_slice(&key_bytes);
                key
            }
            Err(_) => {
                // 生成新密钥
                let mut key = [0u8; 32];
                OsRng.fill_bytes(&mut key);
                let key_b64 = BASE64.encode(&key);
                entry.set_password(&key_b64)
                    .map_err(|e| format!("Failed to store key: {}", e))?;
                key
            }
        };

        Ok(Self { encryption_key: key })
    }

    pub fn encrypt(&self, plaintext: &str) -> Result<String, String> {
        let cipher = Aes256Gcm::new_from_slice(&self.encryption_key)
            .map_err(|e| format!("Failed to create cipher: {}", e))?;

        let mut nonce_bytes = [0u8; 12];
        OsRng.fill_bytes(&mut nonce_bytes);
        let nonce = Nonce::from_slice(&nonce_bytes);

        let ciphertext = cipher.encrypt(nonce, plaintext.as_bytes())
            .map_err(|e| format!("Encryption failed: {}", e))?;

        // 格式: base64(nonce || ciphertext)
        let mut combined = nonce_bytes.to_vec();
        combined.extend(ciphertext);
        Ok(BASE64.encode(&combined))
    }

    pub fn decrypt(&self, encrypted: &str) -> Result<String, String> {
        let combined = BASE64.decode(encrypted)
            .map_err(|e| format!("Failed to decode: {}", e))?;

        if combined.len() < 12 {
            return Err("Invalid encrypted data".to_string());
        }

        let (nonce_bytes, ciphertext) = combined.split_at(12);
        let nonce = Nonce::from_slice(nonce_bytes);

        let cipher = Aes256Gcm::new_from_slice(&self.encryption_key)
            .map_err(|e| format!("Failed to create cipher: {}", e))?;

        let plaintext = cipher.decrypt(nonce, ciphertext)
            .map_err(|e| format!("Decryption failed: {}", e))?;

        String::from_utf8(plaintext)
            .map_err(|e| format!("Invalid UTF-8: {}", e))
    }

    pub fn save_credential(&self, credential: &PlatformCredential) -> Result<(), String> {
        let json = serde_json::to_string(credential)
            .map_err(|e| format!("Failed to serialize: {}", e))?;

        let encrypted = self.encrypt(&json)?;

        let key = format!("{}_{}", credential.platform, credential.account_id);
        let entry = Entry::new(SERVICE_NAME, &key)
            .map_err(|e| format!("Failed to access keyring: {}", e))?;

        entry.set_password(&encrypted)
            .map_err(|e| format!("Failed to store credential: {}", e))
    }

    pub fn load_credential(
        &self,
        platform: &str,
        account_id: &str,
    ) -> Result<Option<PlatformCredential>, String> {
        let key = format!("{}_{}", platform, account_id);
        let entry = Entry::new(SERVICE_NAME, &key)
            .map_err(|e| format!("Failed to access keyring: {}", e))?;

        match entry.get_password() {
            Ok(encrypted) => {
                let json = self.decrypt(&encrypted)?;
                let credential = serde_json::from_str(&json)
                    .map_err(|e| format!("Failed to deserialize: {}", e))?;
                Ok(Some(credential))
            }
            Err(_) => Ok(None),
        }
    }

    pub fn delete_credential(&self, platform: &str, account_id: &str) -> Result<(), String> {
        let key = format!("{}_{}", platform, account_id);
        let entry = Entry::new(SERVICE_NAME, &key)
            .map_err(|e| format!("Failed to access keyring: {}", e))?;

        entry.delete_password()
            .map_err(|e| format!("Failed to delete credential: {}", e))
    }
}

// Tauri 命令
#[tauri::command]
pub fn save_platform_credential(
    credential: PlatformCredential,
) -> Result<(), String> {
    let manager = CredentialManager::new()?;
    manager.save_credential(&credential)
}

#[tauri::command]
pub fn load_platform_credential(
    platform: String,
    account_id: String,
) -> Result<Option<PlatformCredential>, String> {
    let manager = CredentialManager::new()?;
    manager.load_credential(&platform, &account_id)
}

#[tauri::command]
pub fn delete_platform_credential(
    platform: String,
    account_id: String,
) -> Result<(), String> {
    let manager = CredentialManager::new()?;
    manager.delete_credential(&platform, &account_id)
}
```

---

## 6. 前端集成

### 6.1 TypeScript 客户端

```typescript
// src/lib/sidecar-client.ts
import { invoke } from '@tauri-apps/api/core';
import { listen, UnlistenFn } from '@tauri-apps/api/event';

export interface AgentEvent {
  event_type: string;
  node_name: string;
  data: any;
}

export interface AgentResult<T = any> {
  success: boolean;
  data: T;
  error?: string;
  execution_time_ms: number;
}

export class SidecarClient {
  private eventListeners: Map<string, UnlistenFn> = new Map();

  /**
   * 执行 Agent Graph
   */
  async executeGraph<T = any>(
    graphName: string,
    inputs: Record<string, any>,
    onEvent?: (event: AgentEvent) => void
  ): Promise<AgentResult<T>> {
    // 监听事件
    if (onEvent) {
      const unlisten = await listen<AgentEvent>('agent-event', (event) => {
        onEvent(event.payload);
      });
      this.eventListeners.set(graphName, unlisten);
    }

    try {
      const startTime = Date.now();
      const result = await invoke<T>('execute_agent_graph', {
        graphName,
        inputs,
        userId: 'local_user',
        config: {},
      });

      return {
        success: true,
        data: result,
        execution_time_ms: Date.now() - startTime,
      };
    } catch (error) {
      return {
        success: false,
        data: null as T,
        error: String(error),
        execution_time_ms: 0,
      };
    } finally {
      // 清理事件监听
      const unlisten = this.eventListeners.get(graphName);
      if (unlisten) {
        unlisten();
        this.eventListeners.delete(graphName);
      }
    }
  }

  /**
   * 创建文章
   */
  async createArticle(topic: string, style: string, platform: string) {
    return invoke<{ content: string; images: string[] }>('create_article', {
      topic,
      style,
      platform,
    });
  }

  /**
   * 创建爆款内容
   */
  async createViralContent(niche: string, platform: string, contentType: string) {
    return invoke('create_viral_content', {
      niche,
      platform,
      contentType,
    });
  }

  /**
   * 获取热点话题
   */
  async getHotTopics(platform: string, category?: string, limit?: number) {
    return invoke('get_hot_topics', {
      platform,
      category,
      limit,
    });
  }

  /**
   * 发布内容
   */
  async publishContent(platform: string, content: any) {
    return invoke('publish_content', { platform, content });
  }

  /**
   * 定时发布
   */
  async schedulePublish(
    platform: string,
    content: any,
    scheduleTime: Date
  ) {
    return invoke('schedule_publish', {
      taskId: crypto.randomUUID(),
      platform,
      content,
      scheduleTime: scheduleTime.toISOString(),
    });
  }
}

export const sidecarClient = new SidecarClient();
```

### 6.2 React Hooks

```typescript
// src/hooks/useAgent.ts
import { useState, useCallback } from 'react';
import { sidecarClient, AgentEvent, AgentResult } from '@/lib/sidecar-client';

export function useAgent<T = any>(graphName: string) {
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [data, setData] = useState<T | null>(null);
  const [events, setEvents] = useState<AgentEvent[]>([]);

  const execute = useCallback(async (inputs: Record<string, any>) => {
    setLoading(true);
    setError(null);
    setEvents([]);

    const result = await sidecarClient.executeGraph<T>(
      graphName,
      inputs,
      (event) => {
        setEvents((prev) => [...prev, event]);
      }
    );

    setLoading(false);

    if (result.success) {
      setData(result.data);
    } else {
      setError(result.error || 'Unknown error');
    }

    return result;
  }, [graphName]);

  return { execute, loading, error, data, events };
}

// src/hooks/useHotTopics.ts
import { useState, useCallback } from 'react';
import { sidecarClient } from '@/lib/sidecar-client';

export interface HotTopic {
  topic: string;
  heat_score: number;
  trend: 'rising' | 'stable' | 'declining';
  sentiment: {
    positive: number;
    neutral: number;
    negative: number;
  };
  platforms: string[];
}

export function useHotTopics() {
  const [loading, setLoading] = useState(false);
  const [topics, setTopics] = useState<HotTopic[]>([]);
  const [error, setError] = useState<string | null>(null);

  const fetchTopics = useCallback(async (
    platform: string = 'all',
    category?: string,
    limit: number = 20
  ) => {
    setLoading(true);
    setError(null);

    try {
      const result = await sidecarClient.getHotTopics(platform, category, limit);
      setTopics(result.topics);
    } catch (err) {
      setError(String(err));
    } finally {
      setLoading(false);
    }
  }, []);

  return { fetchTopics, loading, topics, error };
}
```

### 6.3 使用示例

```tsx
// src/pages/ContentCreation.tsx
import { useAgent } from '@/hooks/useAgent';
import { useHotTopics } from '@/hooks/useHotTopics';

function ContentCreation() {
  const { execute, loading, data, events } = useAgent('viral_content');
  const { fetchTopics, topics, loading: topicsLoading } = useHotTopics();

  // 获取热点
  const handleFetchHotTopics = async () => {
    await fetchTopics('xiaohongshu', '美妆', 10);
  };

  // 创建爆款内容
  const handleCreateContent = async (topic: string) => {
    const result = await execute({
      niche: '美妆',
      target_platform: 'xiaohongshu',
      content_type: 'note',
      selected_topic: topic,
    });

    if (result.success) {
      console.log('创建成功:', result.data);
    }
  };

  return (
    <div className="content-creation">
      <section className="hot-topics">
        <h2>热点话题</h2>
        <button onClick={handleFetchHotTopics} disabled={topicsLoading}>
          {topicsLoading ? '加载中...' : '获取热点'}
        </button>
        <ul>
          {topics.map((topic) => (
            <li key={topic.topic}>
              <span>{topic.topic}</span>
              <span>热度: {topic.heat_score}</span>
              <button onClick={() => handleCreateContent(topic.topic)}>
                创作
              </button>
            </li>
          ))}
        </ul>
      </section>

      <section className="creation-progress">
        <h2>创作进度</h2>
        {loading && (
          <div className="events">
            {events.map((event, i) => (
              <div key={i} className="event">
                <span className="node">{event.node_name}</span>
                <span className="type">{event.event_type}</span>
              </div>
            ))}
          </div>
        )}
        {data && (
          <div className="result">
            <h3>创作完成</h3>
            <pre>{JSON.stringify(data, null, 2)}</pre>
          </div>
        )}
      </section>
    </div>
  );
}
```

---

## 7. 本地存储

### 7.1 SQLite 数据库

桌面端使用 SQLite 存储本地数据：

```sql
-- 草稿表
CREATE TABLE drafts (
    id TEXT PRIMARY KEY,
    title TEXT,
    content TEXT,
    platform TEXT,
    status TEXT DEFAULT 'draft',
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- 发布历史
CREATE TABLE publish_history (
    id TEXT PRIMARY KEY,
    draft_id TEXT,
    platform TEXT,
    account_id TEXT,
    post_id TEXT,
    post_url TEXT,
    status TEXT,
    published_at DATETIME,
    FOREIGN KEY (draft_id) REFERENCES drafts(id)
);

-- 数据采集记录
CREATE TABLE analytics_records (
    id TEXT PRIMARY KEY,
    platform TEXT,
    post_id TEXT,
    views INTEGER,
    likes INTEGER,
    comments INTEGER,
    shares INTEGER,
    collected_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- 定时任务
CREATE TABLE scheduled_tasks (
    id TEXT PRIMARY KEY,
    task_type TEXT,
    params TEXT,
    trigger_type TEXT,
    trigger_config TEXT,
    status TEXT DEFAULT 'active',
    next_run DATETIME,
    last_run DATETIME,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- 账号信息（仅存储元数据，凭证在 Keychain）
CREATE TABLE accounts (
    id TEXT PRIMARY KEY,
    platform TEXT,
    account_name TEXT,
    avatar_url TEXT,
    status TEXT DEFAULT 'active',
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    last_used_at DATETIME
);
```

### 7.2 数据同步（可选）

```typescript
// src/lib/data-sync.ts

/**
 * 桌面端数据同步是可选的
 * 用户可以选择将数据同步到云端，也可以完全本地使用
 */
export class DataSyncManager {
  private syncEnabled: boolean = false;

  async enableSync(userId: string, token: string) {
    this.syncEnabled = true;
    // 配置同步...
  }

  async disableSync() {
    this.syncEnabled = false;
  }

  async syncDrafts() {
    if (!this.syncEnabled) return;
    // 同步草稿到云端...
  }

  async syncPublishHistory() {
    if (!this.syncEnabled) return;
    // 同步发布历史...
  }
}
```

---

## 8. 打包与分发

### 8.1 构建配置

```json
// src-tauri/tauri.conf.json
{
  "build": {
    "beforeBuildCommand": "pnpm build",
    "beforeDevCommand": "pnpm dev",
    "frontendDist": "../dist",
    "devUrl": "http://localhost:5173"
  },
  "bundle": {
    "active": true,
    "targets": ["msi", "dmg", "deb", "appimage"],
    "identifier": "com.creatorflow.desktop",
    "icon": [
      "icons/32x32.png",
      "icons/128x128.png",
      "icons/128x128@2x.png",
      "icons/icon.icns",
      "icons/icon.ico"
    ],
    "externalBin": ["python-sidecar"],
    "resources": ["graphs/*"]
  },
  "plugins": {
    "updater": {
      "active": true,
      "endpoints": ["https://releases.creatorflow.com/{{target}}/{{arch}}/{{current_version}}"],
      "pubkey": "..."
    }
  }
}
```

### 8.2 Python Sidecar 打包

**打包策略**: 内嵌完整 Python 环境，不依赖用户系统

```yaml
打包原则:
  - 零依赖: 用户无需安装 Python
  - 跨平台: 分别为 Windows/macOS/Linux 打包
  - 体积优化: 精简不必要的标准库
  - 启动优化: 预编译 .pyc 文件

预估体积:
  - Python 运行时: ~40MB (精简后)
  - 依赖包: ~30-50MB (含 Playwright 浏览器除外)
  - Sidecar 代码: ~5MB
  - 总计: ~80-100MB (不含浏览器)

浏览器策略:
  - Playwright 浏览器单独下载（首次运行时）
  - 或预置 Chromium (~150MB)
```

**方案一: PyInstaller (推荐)**

```bash
# 使用 PyInstaller 打包 Python Sidecar
cd apps/sidecar

# 生成 spec 文件并自定义
pyinstaller --name python-sidecar \
  --onedir \
  --add-data "../../agent-definitions:agent-definitions" \
  --hidden-import playwright \
  --hidden-import apscheduler \
  --hidden-import anthropic \
  --hidden-import langgraph \
  --collect-all agent_core \
  --exclude-module tkinter \
  --exclude-module test \
  src/sidecar/main.py

# 输出目录: dist/python-sidecar/
```

**方案二: Nuitka (更好性能)**

```bash
# 使用 Nuitka 编译为原生代码
cd apps/sidecar
nuitka --standalone \
  --onefile \
  --output-filename=python-sidecar \
  --include-package=agent_core \
  --include-package=playwright \
  --include-package=apscheduler \
  --include-package=anthropic \
  --include-data-dir=../../agent-definitions=agent-definitions \
  --remove-output \
  src/sidecar/main.py

# Nuitka 优势: 启动更快，体积更小，代码保护
```

**方案三: PyOxidizer (Rust 集成)**

```toml
# pyoxidizer.bzl - 与 Tauri Rust 后端更好集成
[[embedded_python_config]]
raw_allocator = "system"

[[packaging_rule]]
type = "stdlib-extensions-policy"
policy = "minimal"

[[packaging_rule]]
type = "pip-install-simple"
package = "agent-core"
```

**平台特定打包脚本**:

```bash
# scripts/build-sidecar.sh

#!/bin/bash
set -e

PLATFORM=$(uname -s | tr '[:upper:]' '[:lower:]')
ARCH=$(uname -m)

case $PLATFORM in
  darwin)
    # macOS: 支持 x64 和 arm64
    pyinstaller --target-arch universal2 ...
    ;;
  linux)
    # Linux: AppImage 或直接二进制
    pyinstaller --strip ...
    ;;
  mingw*|cygwin*|msys*)
    # Windows: 使用 MSVC 编译
    pyinstaller --windowed ...
    ;;
esac

# 复制到 Tauri sidecar 目录
cp -r dist/python-sidecar/* ../apps/desktop/src-tauri/sidecar/
```

### 8.3 平台特定配置

```toml
# src-tauri/Cargo.toml

[target.'cfg(target_os = "macos")'.dependencies]
keyring = { version = "2", features = ["apple-native"] }

[target.'cfg(target_os = "windows")'.dependencies]
keyring = { version = "2", features = ["windows-native"] }

[target.'cfg(target_os = "linux")'.dependencies]
keyring = { version = "2", features = ["linux-native"] }
```

---

## 9. LLM 管理模块

### 9.1 模块概述

桌面端 LLM 管理模块提供本地化的大语言模型管理能力，支持多供应商、多模型的统一管理和调用。

```yaml
核心功能:
  - 供应商管理: 配置多个 LLM 供应商（OpenAI、Claude、国内厂商等）
  - 模型配置: 管理各供应商的模型参数、成本、能力
  - 模型组: 将多个模型组合，支持故障转移和负载均衡
  - 速率限制: 配置 Token 用量限制、请求频率限制
  - API Key 管理: 本地加密存储 API Key
  - 用量统计: 追踪 Token 消耗、成本统计
  - LLM 网关: 统一的模型调用入口，支持熔断、重试

设计原则:
  - 本地优先: 所有配置和 API Key 本地加密存储
  - 隐私保护: API Key 不上传云端
  - 成本可控: 实时用量统计和预算告警
  - 高可用: 模型组支持故障转移
```

### 9.2 数据模型

```python
# python-sidecar/src/llm/models.py
from dataclasses import dataclass, field
from typing import Optional
from enum import Enum
from datetime import datetime

class ModelType(str, Enum):
    """模型类型"""
    TEXT = "TEXT"           # 文本生成
    REASONING = "REASONING" # 推理
    VISION = "VISION"       # 视觉
    IMAGE = "IMAGE"         # 图像生成
    VIDEO = "VIDEO"         # 视频生成
    EMBEDDING = "EMBEDDING" # 嵌入
    TTS = "TTS"             # 语音合成
    STT = "STT"             # 语音识别

@dataclass
class LlmProvider:
    """LLM 供应商"""
    id: str
    name: str
    api_base_url: Optional[str] = None
    api_key_encrypted: Optional[str] = None  # 加密存储
    global_rpm_limit: int = 60
    global_tpm_limit: int = 100000
    enabled: bool = True
    is_domestic: bool = False
    description: Optional[str] = None

@dataclass
class LlmModelConfig:
    """模型配置"""
    id: str
    provider_id: str
    model_name: str
    display_name: Optional[str] = None
    model_type: ModelType = ModelType.TEXT
    max_tokens: int = 4096
    max_context_length: int = 8192
    supports_streaming: bool = True
    supports_tools: bool = False
    supports_vision: bool = False
    input_cost_per_1k: float = 0.0
    output_cost_per_1k: float = 0.0
    rpm_limit: Optional[int] = None
    tpm_limit: Optional[int] = None
    priority: int = 0
    enabled: bool = True

@dataclass
class LlmModelGroup:
    """模型组"""
    id: str
    name: str
    model_type: ModelType
    model_ids: list[str] = field(default_factory=list)
    fallback_enabled: bool = True
    retry_count: int = 3
    timeout_seconds: int = 60
    enabled: bool = True
    description: Optional[str] = None

@dataclass
class LlmRateLimitConfig:
    """速率限制配置"""
    id: str
    name: str
    daily_token_limit: int = 100000
    weekly_token_limit: Optional[int] = None
    monthly_token_limit: int = 1000000
    rpm_limit: int = 60
    tpm_limit: int = 100000
    enabled: bool = True
    description: Optional[str] = None

@dataclass
class LlmUsageLog:
    """用量日志"""
    id: str
    model_name: str
    input_tokens: int
    output_tokens: int
    total_tokens: int
    total_cost: float
    latency_ms: int
    status: str  # success | error
    is_streaming: bool
    created_time: datetime
```

### 9.3 LLM 网关

```python
# python-sidecar/src/llm/gateway.py
from typing import AsyncIterator, Optional
from dataclasses import dataclass
import asyncio
import time
from loguru import logger

from .models import LlmProvider, LlmModelConfig, LlmModelGroup
from .rate_limiter import RateLimiter
from .usage_tracker import UsageTracker
from ..storage.credential import CredentialManager

@dataclass
class LlmRequest:
    """LLM 请求"""
    model: str
    messages: list[dict]
    temperature: float = 0.7
    max_tokens: Optional[int] = None
    stream: bool = False
    tools: Optional[list[dict]] = None

@dataclass
class LlmResponse:
    """LLM 响应"""
    content: str
    model: str
    input_tokens: int
    output_tokens: int
    total_tokens: int
    latency_ms: int
    cost: float

class LlmGateway:
    """LLM 统一网关"""

    def __init__(
        self,
        credential_manager: CredentialManager,
        rate_limiter: RateLimiter,
        usage_tracker: UsageTracker,
    ):
        self.credential_manager = credential_manager
        self.rate_limiter = rate_limiter
        self.usage_tracker = usage_tracker
        self._providers: dict[str, LlmProvider] = {}
        self._models: dict[str, LlmModelConfig] = {}
        self._groups: dict[str, LlmModelGroup] = {}

    def register_provider(self, provider: LlmProvider):
        """注册供应商"""
        self._providers[provider.id] = provider

    def register_model(self, model: LlmModelConfig):
        """注册模型"""
        self._models[model.id] = model

    def register_group(self, group: LlmModelGroup):
        """注册模型组"""
        self._groups[group.id] = group

    async def chat(self, request: LlmRequest) -> LlmResponse:
        """发送聊天请求"""
        start_time = time.time()

        # 解析模型（可能是模型名或模型组名）
        model_config = self._resolve_model(request.model)
        if not model_config:
            raise ValueError(f"Model not found: {request.model}")

        # 检查速率限制
        await self.rate_limiter.check(model_config.id)

        # 获取供应商和 API Key
        provider = self._providers.get(model_config.provider_id)
        if not provider:
            raise ValueError(f"Provider not found: {model_config.provider_id}")

        api_key = self.credential_manager.decrypt(provider.api_key_encrypted)

        # 调用 LLM
        try:
            response = await self._call_llm(
                provider=provider,
                model=model_config,
                request=request,
                api_key=api_key,
            )

            latency_ms = int((time.time() - start_time) * 1000)

            # 计算成本
            cost = self._calculate_cost(
                model_config,
                response.input_tokens,
                response.output_tokens,
            )

            # 记录用量
            await self.usage_tracker.log(
                model_name=model_config.model_name,
                input_tokens=response.input_tokens,
                output_tokens=response.output_tokens,
                cost=cost,
                latency_ms=latency_ms,
                status="success",
            )

            return LlmResponse(
                content=response.content,
                model=model_config.model_name,
                input_tokens=response.input_tokens,
                output_tokens=response.output_tokens,
                total_tokens=response.input_tokens + response.output_tokens,
                latency_ms=latency_ms,
                cost=cost,
            )

        except Exception as e:
            latency_ms = int((time.time() - start_time) * 1000)
            await self.usage_tracker.log(
                model_name=model_config.model_name,
                input_tokens=0,
                output_tokens=0,
                cost=0,
                latency_ms=latency_ms,
                status="error",
                error=str(e),
            )
            raise

    async def chat_stream(
        self, request: LlmRequest
    ) -> AsyncIterator[str]:
        """流式聊天"""
        request.stream = True
        model_config = self._resolve_model(request.model)
        provider = self._providers.get(model_config.provider_id)
        api_key = self.credential_manager.decrypt(provider.api_key_encrypted)

        async for chunk in self._call_llm_stream(
            provider=provider,
            model=model_config,
            request=request,
            api_key=api_key,
        ):
            yield chunk

    def _resolve_model(self, model_name: str) -> Optional[LlmModelConfig]:
        """解析模型名称"""
        # 先查找模型组
        if model_name in self._groups:
            group = self._groups[model_name]
            if group.enabled and group.model_ids:
                # 返回优先级最高的可用模型
                for model_id in group.model_ids:
                    model = self._models.get(model_id)
                    if model and model.enabled:
                        return model

        # 直接查找模型
        for model in self._models.values():
            if model.model_name == model_name and model.enabled:
                return model

        return None

    def _calculate_cost(
        self,
        model: LlmModelConfig,
        input_tokens: int,
        output_tokens: int,
    ) -> float:
        """计算成本"""
        input_cost = (input_tokens / 1000) * model.input_cost_per_1k
        output_cost = (output_tokens / 1000) * model.output_cost_per_1k
        return input_cost + output_cost

    async def _call_llm(
        self,
        provider: LlmProvider,
        model: LlmModelConfig,
        request: LlmRequest,
        api_key: str,
    ):
        """调用 LLM API（根据供应商选择不同的客户端）"""
        # 实现具体的 API 调用逻辑
        pass

    async def _call_llm_stream(
        self,
        provider: LlmProvider,
        model: LlmModelConfig,
        request: LlmRequest,
        api_key: str,
    ) -> AsyncIterator[str]:
        """流式调用 LLM API"""
        # 实现具体的流式 API 调用逻辑
        pass
```

### 9.4 RPC 接口

```python
# python-sidecar/src/llm/rpc.py
from ..server import server
from .gateway import LlmGateway, LlmRequest
from .models import LlmProvider, LlmModelConfig, LlmModelGroup

# 全局网关实例
gateway: LlmGateway = None

@server.register("llm.chat")
async def llm_chat(
    model: str,
    messages: list[dict],
    temperature: float = 0.7,
    max_tokens: int | None = None,
    stream: bool = False,
) -> dict:
    """LLM 聊天"""
    request = LlmRequest(
        model=model,
        messages=messages,
        temperature=temperature,
        max_tokens=max_tokens,
        stream=stream,
    )
    response = await gateway.chat(request)
    return {
        "content": response.content,
        "model": response.model,
        "input_tokens": response.input_tokens,
        "output_tokens": response.output_tokens,
        "total_tokens": response.total_tokens,
        "latency_ms": response.latency_ms,
        "cost": response.cost,
    }

@server.register("llm.provider.list")
async def list_providers() -> list[dict]:
    """列出所有供应商"""
    return [
        {
            "id": p.id,
            "name": p.name,
            "api_base_url": p.api_base_url,
            "enabled": p.enabled,
            "is_domestic": p.is_domestic,
            "has_api_key": p.api_key_encrypted is not None,
        }
        for p in gateway._providers.values()
    ]

@server.register("llm.provider.add")
async def add_provider(
    name: str,
    api_base_url: str | None = None,
    api_key: str | None = None,
    is_domestic: bool = False,
) -> dict:
    """添加供应商"""
    # 实现添加逻辑
    pass

@server.register("llm.model.list")
async def list_models(provider_id: str | None = None) -> list[dict]:
    """列出模型"""
    models = gateway._models.values()
    if provider_id:
        models = [m for m in models if m.provider_id == provider_id]
    return [
        {
            "id": m.id,
            "provider_id": m.provider_id,
            "model_name": m.model_name,
            "display_name": m.display_name,
            "model_type": m.model_type.value,
            "enabled": m.enabled,
        }
        for m in models
    ]

@server.register("llm.usage.summary")
async def get_usage_summary(days: int = 30) -> dict:
    """获取用量统计"""
    return await gateway.usage_tracker.get_summary(days)

@server.register("llm.usage.daily")
async def get_daily_usage(days: int = 30) -> list[dict]:
    """获取每日用量"""
    return await gateway.usage_tracker.get_daily_usage(days)
```

### 9.5 前端集成

```typescript
// src/lib/llm-client.ts
import { invoke } from '@tauri-apps/api/core';

export interface LlmChatRequest {
  model: string;
  messages: Array<{ role: string; content: string }>;
  temperature?: number;
  maxTokens?: number;
  stream?: boolean;
}

export interface LlmChatResponse {
  content: string;
  model: string;
  input_tokens: number;
  output_tokens: number;
  total_tokens: number;
  latency_ms: number;
  cost: number;
}

export interface LlmProvider {
  id: string;
  name: string;
  api_base_url: string | null;
  enabled: boolean;
  is_domestic: boolean;
  has_api_key: boolean;
}

export interface LlmUsageSummary {
  total_requests: number;
  success_requests: number;
  error_requests: number;
  total_tokens: number;
  total_cost: number;
  avg_latency_ms: number;
}

export class LlmClient {
  /**
   * 发送聊天请求
   */
  async chat(request: LlmChatRequest): Promise<LlmChatResponse> {
    return invoke('llm_chat', {
      model: request.model,
      messages: request.messages,
      temperature: request.temperature ?? 0.7,
      maxTokens: request.maxTokens,
      stream: request.stream ?? false,
    });
  }

  /**
   * 获取供应商列表
   */
  async listProviders(): Promise<LlmProvider[]> {
    return invoke('llm_provider_list');
  }

  /**
   * 添加供应商
   */
  async addProvider(
    name: string,
    apiBaseUrl?: string,
    apiKey?: string,
    isDomestic?: boolean
  ): Promise<{ id: string }> {
    return invoke('llm_provider_add', {
      name,
      apiBaseUrl,
      apiKey,
      isDomestic,
    });
  }

  /**
   * 获取用量统计
   */
  async getUsageSummary(days: number = 30): Promise<LlmUsageSummary> {
    return invoke('llm_usage_summary', { days });
  }

  /**
   * 获取每日用量
   */
  async getDailyUsage(days: number = 30): Promise<Array<{
    date: string;
    requests: number;
    tokens: number;
    cost: number;
  }>> {
    return invoke('llm_usage_daily', { days });
  }
}

export const llmClient = new LlmClient();
```

---

## 相关文档

- [系统架构](./01-系统架构.md)
- [云端服务设计](./04-云端服务设计.md)
- [Agent Runtime](./05-Agent-Runtime.md)
- [平台适配器](./06-平台适配器.md)
- [BettaFish 舆情分析集成](./08-BettaFish舆情分析集成.md)
