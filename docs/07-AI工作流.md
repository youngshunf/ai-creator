# AI Creator - AI工作流

> 基于 LangGraph 的智能工作流引擎

## 1. 设计理念

### 1.1 核心目标

**构建可编排、可追踪、可扩展的AI Agent工作流系统**

- **状态驱动**: 基于状态机的工作流管理
- **可观测性**: 完整的执行追踪和调试能力
- **人机协作**: 支持人工介入和审批节点
- **容错恢复**: 支持断点续传和错误恢复

### 1.2 技术选型

```yaml
核心框架:
  LangGraph: 工作流编排引擎
  LangChain: LLM抽象层

客户端架构:
  - 客户端通过统一API调用云端模型网关
  - 云端负责模型选择、故障转移、配额管理
  - 客户端只需关注业务逻辑

辅助工具:
  LangSmith: 可观测性平台（可选）
  Pydantic: 状态模型定义
```

### 1.3 架构概览

```text
┌─────────────────────────────────────────────────────────────────────────────┐
│                           AI工作流引擎 (客户端)                               │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌───────────────────────────────────────────────────────────────────────┐  │
│  │                        工作流定义层                                    │  │
│  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐ ┌─────────────┐     │  │
│  │  │ 内容创作    │ │ 智能发布    │ │ 数据分析    │ │ 选题推荐    │     │  │
│  │  │ Workflow    │ │ Workflow    │ │ Workflow    │ │ Workflow    │     │  │
│  │  └─────────────┘ └─────────────┘ └─────────────┘ └─────────────┘     │  │
│  └───────────────────────────────────────────────────────────────────────┘  │
│                                      │                                      │
│                                      ▼                                      │
│  ┌───────────────────────────────────────────────────────────────────────┐  │
│  │                        LangGraph 编排层                                │  │
│  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐                │  │
│  │  │  StateGraph  │  │   Nodes      │  │   Edges      │                │  │
│  │  │  状态图      │  │   节点定义   │  │   边/路由    │                │  │
│  │  └──────────────┘  └──────────────┘  └──────────────┘                │  │
│  └───────────────────────────────────────────────────────────────────────┘  │
│                                      │                                      │
│                                      ▼                                      │
│  ┌───────────────────────────────────────────────────────────────────────┐  │
│  │                        云端API调用层                                   │  │
│  │  ┌────────────────────────────────────────────────────────────────┐   │  │
│  │  │  LLMClient  →  云端模型网关API  →  多模型供应商                  │   │  │
│  │  └────────────────────────────────────────────────────────────────┘   │  │
│  └───────────────────────────────────────────────────────────────────────┘  │
│                                      │                                      │
│                                      ▼                                      │
│  ┌───────────────────────────────────────────────────────────────────────┐  │
│  │                        工具与能力层                                    │  │
│  │  ┌────────────┐ ┌────────────┐ ┌────────────┐ ┌────────────┐         │  │
│  │  │ 网络搜索   │ │ 图像生成   │ │ 内容分析   │ │ 视频生成   │         │  │
│  │  └────────────┘ └────────────┘ └────────────┘ └────────────┘         │  │
│  │  ┌────────────┐ ┌────────────┐ ┌────────────┐ ┌────────────┐         │  │
│  │  │ 素材检索   │ │ 知识库     │ │ 发布适配   │ │ 数据采集   │         │  │
│  │  └────────────┘ └────────────┘ └────────────┘ └────────────┘         │  │
│  └───────────────────────────────────────────────────────────────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 2. 基础设施

### 2.1 LLM客户端 (调用云端API)

```python
# agent-core/src/llm/client.py
from typing import Optional, List, AsyncGenerator
from dataclasses import dataclass
from enum import Enum
import httpx

class ModelType(str, Enum):
    """模型类型"""
    TEXT = "text"           # 文本生成
    REASONING = "reasoning"  # 推理模型
    VISION = "vision"        # 视觉理解
    IMAGE = "image"          # 图像生成

@dataclass
class LLMResponse:
    """LLM响应"""
    content: str
    model: str
    usage: dict

class LLMClient:
    """
    LLM客户端 - 调用云端模型网关API

    云端负责:
    - 模型选择和故障转移
    - 配额检查和用量统计
    - 成本追踪
    - 熔断保护
    """

    def __init__(
        self,
        api_base: str,
        api_key: str,
        timeout: int = 30,
    ):
        self.api_base = api_base.rstrip("/")
        self.api_key = api_key
        self.timeout = timeout

    async def generate(
        self,
        prompt: str,
        system: Optional[str] = None,
        model_type: ModelType = ModelType.TEXT,
        max_tokens: int = 4096,
        temperature: float = 0.7,
        stream: bool = False,
    ) -> str | AsyncGenerator[str, None]:
        """
        生成文本内容

        Args:
            prompt: 用户提示
            system: 系统提示
            model_type: 模型类型 (云端自动选择具体模型)
            max_tokens: 最大输出tokens
            temperature: 温度参数
            stream: 是否流式输出
        """
        messages = [{"role": "user", "content": prompt}]
        if system:
            messages.insert(0, {"role": "system", "content": system})

        if stream:
            return self._stream_generate(messages, model_type, max_tokens, temperature)

        async with httpx.AsyncClient(timeout=self.timeout) as client:
            response = await client.post(
                f"{self.api_base}/api/v1/models/chat",
                headers={"Authorization": f"Bearer {self.api_key}"},
                json={
                    "messages": messages,
                    "model_type": model_type.value,
                    "max_tokens": max_tokens,
                    "temperature": temperature,
                }
            )
            response.raise_for_status()
            data = response.json()
            return data["content"]

    async def _stream_generate(
        self,
        messages: List[dict],
        model_type: ModelType,
        max_tokens: int,
        temperature: float,
    ) -> AsyncGenerator[str, None]:
        """流式生成"""
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            async with client.stream(
                "POST",
                f"{self.api_base}/api/v1/models/chat",
                headers={"Authorization": f"Bearer {self.api_key}"},
                json={
                    "messages": messages,
                    "model_type": model_type.value,
                    "max_tokens": max_tokens,
                    "temperature": temperature,
                    "stream": True,
                }
            ) as response:
                async for line in response.aiter_lines():
                    if line.startswith("data: "):
                        content = line[6:]
                        if content != "[DONE]":
                            yield content

    async def chat(
        self,
        messages: List[dict],
        model_type: ModelType = ModelType.TEXT,
        max_tokens: int = 4096,
        temperature: float = 0.7,
    ) -> LLMResponse:
        """
        多轮对话
        """
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            response = await client.post(
                f"{self.api_base}/api/v1/models/chat",
                headers={"Authorization": f"Bearer {self.api_key}"},
                json={
                    "messages": messages,
                    "model_type": model_type.value,
                    "max_tokens": max_tokens,
                    "temperature": temperature,
                }
            )
            response.raise_for_status()
            data = response.json()

            return LLMResponse(
                content=data["content"],
                model=data["model"],
                usage=data.get("usage", {}),
            )

    async def get_quota(self) -> dict:
        """获取当前用户配额"""
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            response = await client.get(
                f"{self.api_base}/api/v1/models/quota",
                headers={"Authorization": f"Bearer {self.api_key}"},
            )
            response.raise_for_status()
            return response.json()

    async def get_usage(self, period: str = "month") -> dict:
        """获取用量统计"""
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            response = await client.get(
                f"{self.api_base}/api/v1/models/usage",
                headers={"Authorization": f"Bearer {self.api_key}"},
                params={"period": period},
            )
            response.raise_for_status()
            return response.json()
```

### 2.2 工具定义框架

```python
# agent-core/src/tools/base.py
from abc import ABC, abstractmethod
from typing import Any, Optional
from pydantic import BaseModel
from dataclasses import dataclass

@dataclass
class ToolResult:
    """工具执行结果"""
    success: bool
    data: Any
    error: Optional[str] = None

class BaseTool(ABC):
    """工具基类"""

    name: str
    description: str

    @abstractmethod
    async def execute(self, **kwargs) -> ToolResult:
        """执行工具"""
        pass

    def to_claude_tool(self) -> dict:
        """转换为Claude Tool格式"""
        return {
            "name": self.name,
            "description": self.description,
            "input_schema": self.get_input_schema(),
        }

    @abstractmethod
    def get_input_schema(self) -> dict:
        """获取输入参数Schema"""
        pass
```

### 2.7 常用工具实现

```python
# agent-core/src/tools/web_search.py
from .base import BaseTool, ToolResult
import httpx

class WebSearchTool(BaseTool):
    """网络搜索工具"""

    name = "web_search"
    description = "搜索互联网获取最新信息，支持新闻、文章、趋势等内容"

    def __init__(self, api_key: str):
        self.api_key = api_key  # 搜索API密钥（如Serper、Tavily）

    async def execute(self, query: str, num_results: int = 5) -> ToolResult:
        """执行搜索"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "https://api.serper.dev/search",
                    headers={"X-API-KEY": self.api_key},
                    json={"q": query, "num": num_results}
                )
                data = response.json()

                results = []
                for item in data.get("organic", []):
                    results.append({
                        "title": item.get("title"),
                        "snippet": item.get("snippet"),
                        "url": item.get("link"),
                    })

                return ToolResult(success=True, data=results)

        except Exception as e:
            return ToolResult(success=False, data=None, error=str(e))

    def get_input_schema(self) -> dict:
        return {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "搜索查询词"
                },
                "num_results": {
                    "type": "integer",
                    "description": "返回结果数量",
                    "default": 5
                }
            },
            "required": ["query"]
        }


# agent-core/src/tools/image_gen.py
class ImageGenerationTool(BaseTool):
    """图像生成工具"""

    name = "generate_image"
    description = "根据文字描述生成图片，适用于文章配图、封面等"

    def __init__(self, comfyui_url: str):
        self.comfyui_url = comfyui_url

    async def execute(
        self,
        prompt: str,
        negative_prompt: str = "",
        width: int = 1024,
        height: int = 1024,
        style: str = "realistic"
    ) -> ToolResult:
        """生成图像"""
        try:
            async with httpx.AsyncClient() as client:
                # 调用ComfyUI API
                response = await client.post(
                    f"{self.comfyui_url}/api/generate",
                    json={
                        "prompt": prompt,
                        "negative_prompt": negative_prompt,
                        "width": width,
                        "height": height,
                        "style": style,
                    },
                    timeout=120.0  # 图像生成可能需要较长时间
                )

                data = response.json()
                image_url = data.get("image_url")

                return ToolResult(
                    success=True,
                    data={"image_url": image_url}
                )

        except Exception as e:
            return ToolResult(success=False, data=None, error=str(e))

    def get_input_schema(self) -> dict:
        return {
            "type": "object",
            "properties": {
                "prompt": {"type": "string", "description": "图像描述"},
                "negative_prompt": {"type": "string", "description": "不希望出现的元素"},
                "width": {"type": "integer", "default": 1024},
                "height": {"type": "integer", "default": 1024},
                "style": {"type": "string", "enum": ["realistic", "anime", "illustration"]}
            },
            "required": ["prompt"]
        }
```

---

## 3. 内容创作工作流

### 3.1 状态定义

```python
# agent-core/src/workflows/content_creation/state.py
from typing import TypedDict, Optional, List, Annotated
from enum import Enum
import operator

class CreationStage(Enum):
    """创作阶段"""
    INIT = "init"
    RESEARCH = "research"
    OUTLINE = "outline"
    DRAFT = "draft"
    POLISH = "polish"
    IMAGE = "image"
    REVIEW = "review"
    COMPLETE = "complete"

class ContentState(TypedDict):
    """内容创作状态"""

    # 输入参数
    topic: str                              # 创作主题
    platform: str                           # 目标平台
    style: str                              # 写作风格
    keywords: Optional[List[str]]           # 关键词

    # 中间状态
    stage: CreationStage                    # 当前阶段
    research_results: Optional[List[dict]]  # 研究结果
    outline: Optional[str]                  # 大纲
    draft: Optional[str]                    # 草稿
    polished_content: Optional[str]         # 润色后内容
    images: Optional[List[str]]             # 生成的图片

    # 消息历史（用于Annotated追加）
    messages: Annotated[List[dict], operator.add]

    # 输出
    final_content: Optional[str]            # 最终内容
    final_title: Optional[str]              # 最终标题
    error: Optional[str]                    # 错误信息
```

### 3.2 工作流图定义

```python
# agent-core/src/workflows/content_creation/graph.py
from langgraph.graph import StateGraph, END
from .state import ContentState, CreationStage
from .nodes import (
    research_node,
    outline_node,
    draft_node,
    polish_node,
    image_node,
    review_node,
)

def create_content_workflow() -> StateGraph:
    """创建内容创作工作流"""

    # 创建状态图
    workflow = StateGraph(ContentState)

    # 添加节点
    workflow.add_node("research", research_node)
    workflow.add_node("outline", outline_node)
    workflow.add_node("draft", draft_node)
    workflow.add_node("polish", polish_node)
    workflow.add_node("generate_images", image_node)
    workflow.add_node("review", review_node)

    # 设置入口点
    workflow.set_entry_point("research")

    # 添加边
    workflow.add_edge("research", "outline")
    workflow.add_edge("outline", "draft")
    workflow.add_edge("draft", "polish")
    workflow.add_edge("polish", "generate_images")
    workflow.add_edge("generate_images", "review")

    # 条件路由：审核通过则结束，否则返回润色
    workflow.add_conditional_edges(
        "review",
        should_continue,
        {
            "complete": END,
            "revise": "polish",
        }
    )

    return workflow.compile()

def should_continue(state: ContentState) -> str:
    """决定是否继续修改"""
    if state.get("review_passed", False):
        return "complete"
    if state.get("revision_count", 0) >= 3:
        # 最多修改3次
        return "complete"
    return "revise"
```

### 3.3 节点实现

```python
# agent-core/src/workflows/content_creation/nodes.py
from .state import ContentState, CreationStage
from ...llm.client import LLMClient, Message
from ...tools.web_search import WebSearchTool
from ...tools.image_gen import ImageGenerationTool

async def research_node(state: ContentState) -> dict:
    """研究节点：搜索相关资料"""

    topic = state["topic"]
    platform = state["platform"]

    # 使用搜索工具
    search_tool = WebSearchTool(api_key="...")
    result = await search_tool.execute(
        query=f"{topic} {platform} 热门内容 最新趋势",
        num_results=10
    )

    if not result.success:
        return {
            "error": f"研究阶段失败: {result.error}",
            "stage": CreationStage.RESEARCH,
        }

    return {
        "research_results": result.data,
        "stage": CreationStage.RESEARCH,
        "messages": [{
            "role": "system",
            "content": f"已收集{len(result.data)}条相关资料"
        }]
    }

async def outline_node(state: ContentState) -> dict:
    """大纲节点：生成内容大纲"""

    llm = LLMClient(api_key="...")

    # 构建提示词
    research_summary = "\n".join([
        f"- {r['title']}: {r['snippet']}"
        for r in state["research_results"][:5]
    ])

    prompt = f"""基于以下研究资料，为主题「{state['topic']}」创建内容大纲。

目标平台: {state['platform']}
写作风格: {state['style']}

研究资料:
{research_summary}

请生成包含以下部分的大纲:
1. 吸引人的开头
2. 3-5个核心观点
3. 有力的结尾

输出格式为Markdown大纲。"""

    response = await llm.generate(
        prompt=prompt,
        system="你是一个专业的自媒体内容策划师，擅长创作吸引用户的内容大纲。"
    )

    return {
        "outline": response,
        "stage": CreationStage.OUTLINE,
        "messages": [{
            "role": "assistant",
            "content": f"大纲已生成:\n{response[:200]}..."
        }]
    }

async def draft_node(state: ContentState) -> dict:
    """草稿节点：撰写初稿"""

    llm = LLMClient(api_key="...")

    # 平台特定指导
    platform_guides = {
        "xiaohongshu": "使用轻松活泼的语气，多用emoji，段落简短，适合手机阅读。",
        "zhihu": "使用专业严谨的语气，逻辑清晰，适当引用数据和来源。",
        "weibo": "简洁有力，突出重点，适合快速阅读。",
        "wechat_mp": "深度内容，可以较长，注重阅读体验和信息量。",
    }

    platform_guide = platform_guides.get(
        state["platform"],
        "根据平台特点调整内容风格。"
    )

    prompt = f"""根据以下大纲撰写完整内容。

主题: {state['topic']}
平台: {state['platform']}
风格: {state['style']}

大纲:
{state['outline']}

平台指南:
{platform_guide}

请撰写完整的内容，包括引人入胜的标题。"""

    response = await llm.generate(
        prompt=prompt,
        system="你是一个资深自媒体写手，擅长创作高互动、高转化的内容。",
        max_tokens=8192,
    )

    return {
        "draft": response,
        "stage": CreationStage.DRAFT,
        "messages": [{
            "role": "assistant",
            "content": f"初稿已完成，共{len(response)}字"
        }]
    }

async def polish_node(state: ContentState) -> dict:
    """润色节点：优化内容"""

    llm = LLMClient(api_key="...")

    draft = state.get("polished_content") or state["draft"]

    prompt = f"""请润色以下内容，使其更加吸引人。

优化方向:
1. 增强开头的吸引力
2. 优化语言表达，使其更流畅
3. 加强观点的说服力
4. 确保结尾有引导互动的元素
5. 添加适当的emoji（如果平台适合）

原内容:
{draft}

请输出润色后的完整内容。"""

    response = await llm.generate(
        prompt=prompt,
        system="你是一个内容优化专家，擅长将普通内容变成爆款。",
        max_tokens=8192,
    )

    return {
        "polished_content": response,
        "stage": CreationStage.POLISH,
        "messages": [{
            "role": "assistant",
            "content": "内容已润色优化"
        }]
    }

async def image_node(state: ContentState) -> dict:
    """图像节点：生成配图"""

    llm = LLMClient(api_key="...")
    image_tool = ImageGenerationTool(comfyui_url="...")

    # 让LLM生成图像提示词
    prompt = f"""基于以下内容，生成3个适合作为配图的图像描述。

内容摘要:
{state['polished_content'][:500]}

平台: {state['platform']}

要求:
1. 图像要能吸引目标用户点击
2. 风格要与内容调性一致
3. 每个描述用英文，便于AI图像生成

请输出3个图像描述，每行一个。"""

    image_prompts = await llm.generate(prompt=prompt)
    prompts = [p.strip() for p in image_prompts.split('\n') if p.strip()]

    # 生成图像
    images = []
    for prompt in prompts[:3]:
        result = await image_tool.execute(prompt=prompt)
        if result.success:
            images.append(result.data["image_url"])

    return {
        "images": images,
        "stage": CreationStage.IMAGE,
        "messages": [{
            "role": "assistant",
            "content": f"已生成{len(images)}张配图"
        }]
    }

async def review_node(state: ContentState) -> dict:
    """审核节点：检查内容质量"""

    llm = LLMClient(api_key="...")

    prompt = f"""请审核以下自媒体内容的质量。

内容:
{state['polished_content']}

审核标准:
1. 标题是否吸引人 (1-10分)
2. 内容是否有价值 (1-10分)
3. 语言是否流畅 (1-10分)
4. 是否符合平台调性 (1-10分)
5. 是否有敏感/违规内容

请输出JSON格式的审核结果:
{{
    "title_score": 8,
    "value_score": 7,
    "language_score": 8,
    "platform_fit_score": 9,
    "has_sensitive_content": false,
    "suggestions": ["建议1", "建议2"],
    "overall_passed": true
}}"""

    response = await llm.generate(
        prompt=prompt,
        system="你是一个严格的内容审核专家。"
    )

    import json
    try:
        review_result = json.loads(response)
    except json.JSONDecodeError:
        review_result = {"overall_passed": True, "suggestions": []}

    revision_count = state.get("revision_count", 0) + 1

    if review_result.get("overall_passed", True):
        return {
            "stage": CreationStage.COMPLETE,
            "review_passed": True,
            "final_content": state["polished_content"],
            "final_title": extract_title(state["polished_content"]),
            "messages": [{
                "role": "assistant",
                "content": "内容审核通过！"
            }]
        }
    else:
        return {
            "stage": CreationStage.REVIEW,
            "review_passed": False,
            "revision_count": revision_count,
            "messages": [{
                "role": "assistant",
                "content": f"需要修改: {', '.join(review_result.get('suggestions', []))}"
            }]
        }

def extract_title(content: str) -> str:
    """从内容中提取标题"""
    lines = content.strip().split('\n')
    for line in lines:
        line = line.strip()
        if line and not line.startswith('#'):
            return line
        if line.startswith('#'):
            return line.lstrip('#').strip()
    return "未命名"
```

### 3.4 工作流调用

```python
# agent-core/src/workflows/content_creation/runner.py
from .graph import create_content_workflow
from .state import ContentState, CreationStage

class ContentCreationWorkflow:
    """内容创作工作流执行器"""

    def __init__(self):
        self.workflow = create_content_workflow()

    async def run(
        self,
        topic: str,
        platform: str,
        style: str,
        keywords: list[str] | None = None,
    ) -> dict:
        """执行内容创作工作流"""

        # 初始状态
        initial_state: ContentState = {
            "topic": topic,
            "platform": platform,
            "style": style,
            "keywords": keywords or [],
            "stage": CreationStage.INIT,
            "research_results": None,
            "outline": None,
            "draft": None,
            "polished_content": None,
            "images": None,
            "messages": [],
            "final_content": None,
            "final_title": None,
            "error": None,
        }

        # 执行工作流
        final_state = await self.workflow.ainvoke(initial_state)

        return {
            "success": final_state["error"] is None,
            "title": final_state.get("final_title"),
            "content": final_state.get("final_content"),
            "images": final_state.get("images", []),
            "error": final_state.get("error"),
            "messages": final_state.get("messages", []),
        }

    async def run_with_stream(
        self,
        topic: str,
        platform: str,
        style: str,
        **kwargs
    ):
        """流式执行，实时返回进度"""

        initial_state = {
            "topic": topic,
            "platform": platform,
            "style": style,
            "stage": CreationStage.INIT,
            "messages": [],
            **kwargs
        }

        async for event in self.workflow.astream(initial_state):
            # event包含当前节点和状态
            yield event
```

---

## 4. 智能发布工作流

### 4.1 多平台发布编排

```python
# agent-core/src/workflows/publish/graph.py
from langgraph.graph import StateGraph, END
from typing import TypedDict, List, Optional

class PublishState(TypedDict):
    """发布状态"""
    content: dict                           # 待发布内容
    platforms: List[str]                    # 目标平台列表
    current_platform: Optional[str]         # 当前处理平台
    results: dict                           # 发布结果 {platform: result}
    errors: dict                            # 错误信息 {platform: error}

def create_publish_workflow() -> StateGraph:
    """创建发布工作流"""

    workflow = StateGraph(PublishState)

    # 节点
    workflow.add_node("prepare", prepare_content_node)
    workflow.add_node("adapt_content", adapt_for_platform_node)
    workflow.add_node("publish", publish_to_platform_node)
    workflow.add_node("verify", verify_publish_node)
    workflow.add_node("aggregate", aggregate_results_node)

    # 入口
    workflow.set_entry_point("prepare")

    # 边
    workflow.add_edge("prepare", "adapt_content")
    workflow.add_edge("adapt_content", "publish")
    workflow.add_edge("publish", "verify")

    # 条件边：处理下一个平台或结束
    workflow.add_conditional_edges(
        "verify",
        has_more_platforms,
        {
            "next": "adapt_content",
            "done": "aggregate",
        }
    )

    workflow.add_edge("aggregate", END)

    return workflow.compile()

async def adapt_for_platform_node(state: PublishState) -> dict:
    """适配内容到目标平台"""

    remaining = [p for p in state["platforms"] if p not in state["results"]]
    if not remaining:
        return state

    platform = remaining[0]

    # 根据平台调整内容
    adapted_content = await adapt_content(
        state["content"],
        platform
    )

    return {
        "current_platform": platform,
        "adapted_content": adapted_content,
    }

async def publish_to_platform_node(state: PublishState) -> dict:
    """发布到平台"""
    from ...platforms import get_adapter

    platform = state["current_platform"]
    adapter = get_adapter(platform)

    try:
        result = await adapter.publish(
            page=...,  # 从浏览器池获取
            content=state["adapted_content"]
        )

        return {
            "results": {
                **state["results"],
                platform: result
            }
        }

    except Exception as e:
        return {
            "errors": {
                **state["errors"],
                platform: str(e)
            }
        }

def has_more_platforms(state: PublishState) -> str:
    """检查是否还有未处理的平台"""
    processed = set(state["results"].keys()) | set(state["errors"].keys())
    if len(processed) < len(state["platforms"]):
        return "next"
    return "done"
```

---

## 5. 数据分析工作流

### 5.1 智能选题推荐

```python
# agent-core/src/workflows/analytics/topic_recommend.py
from langgraph.graph import StateGraph, END
from typing import TypedDict, List

class TopicRecommendState(TypedDict):
    """选题推荐状态"""
    user_id: str
    platform: str
    history_posts: List[dict]       # 历史发布数据
    trending_topics: List[dict]     # 热门话题
    user_niche: str                 # 用户领域
    recommendations: List[dict]     # 推荐选题

async def analyze_history_node(state: TopicRecommendState) -> dict:
    """分析历史数据"""
    llm = LLMClient(api_key="...")

    # 分析历史表现最好的内容特征
    history_summary = "\n".join([
        f"- {p['title']}: {p['views']}阅读, {p['likes']}点赞"
        for p in state["history_posts"][:20]
    ])

    prompt = f"""分析以下内容的表现数据，找出成功内容的共同特征。

历史内容:
{history_summary}

请分析:
1. 表现最好的内容主题
2. 最受欢迎的内容风格
3. 发布时间规律
4. 标题特征

输出JSON格式。"""

    analysis = await llm.generate(prompt)

    return {
        "history_analysis": analysis
    }

async def fetch_trending_node(state: TopicRecommendState) -> dict:
    """获取热门话题"""
    search_tool = WebSearchTool(api_key="...")

    result = await search_tool.execute(
        query=f"{state['user_niche']} {state['platform']} 热门话题 今日",
        num_results=20
    )

    return {
        "trending_topics": result.data if result.success else []
    }

async def generate_recommendations_node(state: TopicRecommendState) -> dict:
    """生成选题推荐"""
    llm = LLMClient(api_key="...")

    prompt = f"""基于用户历史数据和当前热点，推荐5个选题。

用户领域: {state['user_niche']}
目标平台: {state['platform']}

历史分析:
{state.get('history_analysis', 'N/A')}

当前热点:
{state.get('trending_topics', [])}

请推荐5个选题，每个包含:
1. 标题建议
2. 内容方向
3. 预估热度 (1-10)
4. 推荐理由

输出JSON数组格式。"""

    recommendations = await llm.generate(prompt)

    return {
        "recommendations": recommendations
    }

def create_topic_recommend_workflow():
    """创建选题推荐工作流"""

    workflow = StateGraph(TopicRecommendState)

    workflow.add_node("analyze_history", analyze_history_node)
    workflow.add_node("fetch_trending", fetch_trending_node)
    workflow.add_node("generate_recommendations", generate_recommendations_node)

    workflow.set_entry_point("analyze_history")

    # 并行执行历史分析和热点获取
    workflow.add_edge("analyze_history", "fetch_trending")
    workflow.add_edge("fetch_trending", "generate_recommendations")
    workflow.add_edge("generate_recommendations", END)

    return workflow.compile()
```

---

## 6. 人机协作模式

### 6.1 审批节点

```python
# agent-core/src/workflows/human_in_loop.py
from langgraph.graph import StateGraph
from langgraph.checkpoint.memory import MemorySaver

def create_workflow_with_approval():
    """创建带人工审批的工作流"""

    workflow = StateGraph(ContentState)

    # ... 其他节点 ...

    # 添加人工审批节点
    workflow.add_node("human_approval", human_approval_node)

    # 在发布前需要人工审批
    workflow.add_edge("review", "human_approval")

    workflow.add_conditional_edges(
        "human_approval",
        check_approval,
        {
            "approved": "publish",
            "rejected": "revise",
            "pending": "human_approval",  # 等待审批
        }
    )

    # 使用检查点保存状态
    checkpointer = MemorySaver()

    return workflow.compile(checkpointer=checkpointer)

async def human_approval_node(state: ContentState) -> dict:
    """人工审批节点 - 暂停等待用户操作"""
    # 这个节点会暂停工作流执行
    # 等待用户通过API提交审批结果
    return {
        "awaiting_approval": True,
        "approval_request": {
            "content": state["polished_content"],
            "images": state.get("images", []),
            "platform": state["platform"],
        }
    }

def check_approval(state: ContentState) -> str:
    """检查审批状态"""
    if state.get("approved") is True:
        return "approved"
    if state.get("approved") is False:
        return "rejected"
    return "pending"
```

### 6.2 审批API

```python
# backend/app/api/v1/workflow.py
from fastapi import APIRouter, Depends

router = APIRouter()

@router.post("/workflow/{thread_id}/approve")
async def approve_workflow(
    thread_id: str,
    approved: bool,
    feedback: str | None = None,
):
    """审批工作流"""

    # 获取工作流实例
    workflow = get_workflow_instance(thread_id)

    # 更新状态并继续执行
    await workflow.update_state(
        thread_id,
        {
            "approved": approved,
            "approval_feedback": feedback,
            "awaiting_approval": False,
        }
    )

    # 继续执行工作流
    result = await workflow.ainvoke(
        None,  # 使用保存的状态
        config={"configurable": {"thread_id": thread_id}}
    )

    return {"success": True, "result": result}
```

---

## 7. 监控与追踪

### 7.1 工作流追踪

```python
# agent-core/src/workflows/tracing.py
from datetime import datetime
from typing import Any
import json

class WorkflowTracer:
    """工作流追踪器"""

    def __init__(self, workflow_id: str):
        self.workflow_id = workflow_id
        self.events = []

    def log_event(
        self,
        event_type: str,
        node: str,
        data: Any,
    ):
        """记录事件"""
        self.events.append({
            "timestamp": datetime.utcnow().isoformat(),
            "workflow_id": self.workflow_id,
            "event_type": event_type,
            "node": node,
            "data": data,
        })

    def get_trace(self) -> list:
        """获取追踪记录"""
        return self.events

    async def save_to_db(self, db):
        """保存到数据库"""
        # 保存追踪记录
        pass

# 使用装饰器添加追踪
def with_tracing(func):
    async def wrapper(state, *args, **kwargs):
        tracer = state.get("_tracer")
        node_name = func.__name__

        if tracer:
            tracer.log_event("node_start", node_name, {"input": state})

        try:
            result = await func(state, *args, **kwargs)

            if tracer:
                tracer.log_event("node_end", node_name, {"output": result})

            return result

        except Exception as e:
            if tracer:
                tracer.log_event("node_error", node_name, {"error": str(e)})
            raise

    return wrapper
```

---

## 相关文档

- [Agent Runtime](./05-Agent-Runtime.md)
- [平台适配器](./06-平台适配器.md)
- [数据模型](./08-数据模型.md)
